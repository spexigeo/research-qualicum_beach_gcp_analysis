{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualicum Beach Orthomosaic Processing with GCPs\n",
    "\n",
    "This notebook processes drone imagery to create orthomosaics using Agisoft Metashape, comparing results with and without ground control points (GCPs).\n",
    "\n",
    "## Workflow:\n",
    "1. Load GCPs from KMZ file\n",
    "2. Download drone imagery from S3 (all 12 cells)\n",
    "3. Process orthomosaic WITHOUT GCPs\n",
    "4. Process orthomosaic WITH GCPs\n",
    "5. Compare both orthomosaics against ESRI and OpenStreetMap basemaps\n",
    "6. Generate comprehensive quality report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Add package to path\n",
    "package_dir = Path.cwd()\n",
    "sys.path.insert(0, str(package_dir))\n",
    "\n",
    "from qualicum_beach_gcp_analysis import (\n",
    "    load_gcps_from_kmz,\n",
    "    download_basemap,\n",
    "    visualize_gcps_on_basemap,\n",
    "    calculate_gcp_bbox,\n",
    "    download_all_images_from_input_dir,\n",
    "    export_to_metashape_csv,\n",
    "    export_to_metashape_xml,\n",
    "    process_orthomosaic,\n",
    "    PhotoMatchQuality,\n",
    "    DepthMapQuality,\n",
    "    compare_orthomosaic_to_basemap,\n",
    "    generate_comparison_report,\n",
    "    generate_markdown_report,\n",
    ")\n",
    "\n",
    "print(\"‚úì Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Ground Control Points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GCPs from: /Users/mauriciohessflores/Documents/Code/Data/Qualicum Beach GCPs/Spexi_Survey_Points/Spexi_Drone_Survey/QualicumBeach_AOI.kmz\n",
      "Found 1 KML file(s) in KMZ\n",
      "Attempting to fix namespace issues...\n",
      "‚úì Fixed namespace issues in KML file\n",
      "Found 12 placemarks in KMZ file (namespace: http://www.opengis.net/kml/2.2)\n",
      "Successfully parsed 12 GCPs from KMZ file\n",
      "\n",
      "‚úì Loaded 12 ground control points\n",
      "\n",
      "GCPs:\n",
      "   1. 8928d89ac03ffff     : (49.352544, -124.407904, z=0.00)\n",
      "   2. 8928d89ac0bffff     : (49.354342, -124.404136, z=0.00)\n",
      "   3. 8928d89ac1bffff     : (49.351585, -124.403857, z=0.00)\n",
      "   4. 8928d89ac43ffff     : (49.355182, -124.396319, z=0.00)\n",
      "   5. 8928d89ac47ffff     : (49.356141, -124.400367, z=0.00)\n",
      "   6. 8928d89ac53ffff     : (49.352425, -124.396040, z=0.00)\n",
      "   7. 8928d89ac57ffff     : (49.353384, -124.400088, z=0.00)\n",
      "   8. 8928d89ac5bffff     : (49.354224, -124.392271, z=0.00)\n",
      "   9. 8928d89ac73ffff     : (49.357100, -124.404415, z=0.00)\n",
      "  10. 8928d89acc7ffff     : (49.348828, -124.403577, z=0.00)\n",
      "  11. 8928d89accbffff     : (49.349668, -124.395761, z=0.00)\n",
      "  12. 8928d89accfffff     : (49.350626, -124.399809, z=0.00)\n"
     ]
    }
   ],
   "source": [
    "# Path to the KMZ file\n",
    "kmz_path = \"/Users/mauriciohessflores/Documents/Code/Data/Qualicum Beach GCPs/Spexi_Survey_Points/Spexi_Drone_Survey/QualicumBeach_AOI.kmz\"\n",
    "\n",
    "# Load GCPs\n",
    "gcps = load_gcps_from_kmz(kmz_path)\n",
    "\n",
    "print(f\"\\n‚úì Loaded {len(gcps)} ground control points\")\n",
    "\n",
    "# Display all GCPs\n",
    "if gcps:\n",
    "    print(\"\\nGCPs:\")\n",
    "    for i, gcp in enumerate(gcps):\n",
    "        print(f\"  {i+1:2d}. {gcp.get('id', 'Unknown'):20s}: ({gcp['lat']:.6f}, {gcp['lon']:.6f}, z={gcp.get('z', 0):.2f})\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GCPs found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Bounding Box and Download Reference Basemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box:\n",
      "  Latitude: 49.338828 to 49.367100\n",
      "  Longitude: -124.417904 to -124.382271\n",
      "\n",
      "============================================================\n",
      "Step 2a: Download current basemaps and check resolution\n",
      "============================================================\n",
      "\n",
      "‚úì ESRI basemap (low res) already exists: outputs/qualicum_beach_basemap_esri_lowres.tif\n",
      "  REUSING existing file (skipping download)\n",
      "  Dimensions: 207 x 253 pixels\n",
      "  Resolution: 12.46 meters per pixel\n",
      "\n",
      "‚úì OpenStreetMap basemap (low res) already exists: outputs/qualicum_beach_basemap_osm_lowres.tif\n",
      "  REUSING existing file (skipping download)\n",
      "  Dimensions: 207 x 253 pixels\n",
      "  Resolution: 12.46 meters per pixel\n",
      "\n",
      "============================================================\n",
      "Current Basemap Resolution Summary:\n",
      "============================================================\n",
      "ESRI World Imagery:     12.46 m/pixel\n",
      "OpenStreetMap:          12.46 m/pixel\n",
      "\n",
      "‚ö†Ô∏è  These resolutions are too low for detailed analysis!\n",
      "\n",
      "Target resolution: 0.5 m/pixel\n",
      "Calculated zoom level: 19\n",
      "Expected resolution at zoom 19: 0.19 m/pixel\n",
      "\n",
      "============================================================\n",
      "Step 2b: Download HIGH RESOLUTION basemaps\n",
      "============================================================\n",
      "\n",
      "‚úì ESRI basemap (HIGH RES) already exists: outputs/qualicum_beach_basemap_esri.tif\n",
      "  REUSING existing file (skipping download)\n",
      "  Dimensions: 13285 x 16181 pixels\n",
      "  Resolution: 0.19 meters per pixel\n",
      "  Improvement: 64.1x higher resolution\n",
      "\n",
      "‚úì OpenStreetMap basemap (HIGH RES) already exists: outputs/qualicum_beach_basemap_osm.tif\n",
      "  REUSING existing file (skipping download)\n",
      "  Dimensions: 13285 x 16181 pixels\n",
      "  Resolution: 0.19 meters per pixel\n",
      "  Improvement: 64.1x higher resolution\n",
      "\n",
      "‚úì Google Satellite basemap (HIGH RES) already exists: outputs/qualicum_beach_basemap_google.tif\n",
      "  REUSING existing file (skipping download)\n",
      "  Dimensions: 13285 x 16181 pixels\n",
      "  Resolution: 0.19 meters per pixel\n",
      "\n",
      "============================================================\n",
      "Final Basemap Resolution Summary:\n",
      "============================================================\n",
      "ESRI World Imagery (HIGH RES):     0.19 m/pixel\n",
      "OpenStreetMap (HIGH RES):          0.19 m/pixel\n",
      "Google Satellite (HIGH RES):      0.19 m/pixel\n",
      "\n",
      "‚úì High resolution basemaps are ready for analysis!\n",
      "\n",
      "Note: Google Satellite tiles may be subject to Terms of Service restrictions.\n",
      "      For production use, consider Google Earth Engine API with authentication.\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Calculate bounding box\n",
    "bbox = calculate_gcp_bbox(gcps, padding=0.01)\n",
    "min_lat, min_lon, max_lat, max_lon = bbox\n",
    "\n",
    "print(f\"Bounding box:\")\n",
    "print(f\"  Latitude: {min_lat:.6f} to {max_lat:.6f}\")\n",
    "print(f\"  Longitude: {min_lon:.6f} to {max_lon:.6f}\")\n",
    "\n",
    "# Calculate center latitude for resolution calculation\n",
    "center_lat = (min_lat + max_lat) / 2.0\n",
    "\n",
    "# Import math and rasterio for resolution calculations\n",
    "import math\n",
    "import rasterio\n",
    "\n",
    "# Function to calculate resolution in meters per pixel for a given zoom level\n",
    "def calculate_resolution_meters_per_pixel(zoom: int, latitude: float) -> float:\n",
    "    \"\"\"Calculate resolution in meters per pixel for a given zoom level and latitude.\"\"\"\n",
    "    # Earth's circumference at equator in meters\n",
    "    earth_circumference = 40075017.0  # meters\n",
    "    # Resolution at equator for given zoom level\n",
    "    resolution_equator = earth_circumference / (256 * (2 ** zoom))\n",
    "    # Adjust for latitude (pixels get smaller as you move away from equator)\n",
    "    resolution = resolution_equator * math.cos(math.radians(latitude))\n",
    "    return resolution\n",
    "\n",
    "# Download current basemaps at default zoom to check resolution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2a: Download current basemaps and check resolution\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "basemap_esri_path_low = str(output_dir / \"qualicum_beach_basemap_esri_lowres.tif\")\n",
    "if Path(basemap_esri_path_low).exists():\n",
    "    print(f\"\\n‚úì ESRI basemap (low res) already exists: {basemap_esri_path_low}\")\n",
    "    print(\"  REUSING existing file (skipping download)\")\n",
    "else:\n",
    "    print(\"\\nDownloading ESRI World Imagery basemap (low resolution for comparison)...\")\n",
    "    basemap_esri_path_low = download_basemap(\n",
    "        bbox=bbox,\n",
    "        output_path=basemap_esri_path_low,\n",
    "        source=\"esri_world_imagery\",\n",
    "        zoom=None  # Will use default zoom (typically 13)\n",
    "    )\n",
    "\n",
    "# Get actual zoom level used and calculate resolution\n",
    "with rasterio.open(basemap_esri_path_low) as src:\n",
    "    esri_width = src.width\n",
    "    esri_height = src.height\n",
    "    esri_bounds = src.bounds\n",
    "    # Calculate resolution from actual bounds and dimensions\n",
    "    width_meters = (esri_bounds.right - esri_bounds.left) * 111320 * math.cos(math.radians(center_lat))\n",
    "    height_meters = (esri_bounds.top - esri_bounds.bottom) * 111320\n",
    "    esri_resolution_x = width_meters / esri_width\n",
    "    esri_resolution_y = height_meters / esri_height\n",
    "    esri_resolution = (esri_resolution_x + esri_resolution_y) / 2.0\n",
    "\n",
    "print(f\"  Dimensions: {esri_width} x {esri_height} pixels\")\n",
    "print(f\"  Resolution: {esri_resolution:.2f} meters per pixel\")\n",
    "\n",
    "basemap_osm_path_low = str(output_dir / \"qualicum_beach_basemap_osm_lowres.tif\")\n",
    "if Path(basemap_osm_path_low).exists():\n",
    "    print(f\"\\n‚úì OpenStreetMap basemap (low res) already exists: {basemap_osm_path_low}\")\n",
    "    print(\"  REUSING existing file (skipping download)\")\n",
    "else:\n",
    "    print(\"\\nDownloading OpenStreetMap basemap (low resolution for comparison)...\")\n",
    "    basemap_osm_path_low = download_basemap(\n",
    "        bbox=bbox,\n",
    "        output_path=basemap_osm_path_low,\n",
    "        source=\"openstreetmap\",\n",
    "        zoom=None  # Will use default zoom (typically 13)\n",
    "    )\n",
    "\n",
    "with rasterio.open(basemap_osm_path_low) as src:\n",
    "    osm_width = src.width\n",
    "    osm_height = src.height\n",
    "    osm_bounds = src.bounds\n",
    "    width_meters = (osm_bounds.right - osm_bounds.left) * 111320 * math.cos(math.radians(center_lat))\n",
    "    height_meters = (osm_bounds.top - osm_bounds.bottom) * 111320\n",
    "    osm_resolution_x = width_meters / osm_width\n",
    "    osm_resolution_y = height_meters / osm_height\n",
    "    osm_resolution = (osm_resolution_x + osm_resolution_y) / 2.0\n",
    "\n",
    "print(f\"  Dimensions: {osm_width} x {osm_height} pixels\")\n",
    "print(f\"  Resolution: {osm_resolution:.2f} meters per pixel\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Current Basemap Resolution Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ESRI World Imagery:     {esri_resolution:.2f} m/pixel\")\n",
    "print(f\"OpenStreetMap:          {osm_resolution:.2f} m/pixel\")\n",
    "print(f\"\\n‚ö†Ô∏è  These resolutions are too low for detailed analysis!\")\n",
    "\n",
    "# Calculate target zoom level for higher resolution\n",
    "# Target: ~0.5-1.0 meters per pixel (suitable for detailed comparison)\n",
    "target_resolution = 0.5  # meters per pixel\n",
    "target_zoom = None\n",
    "for zoom in range(19, 12, -1):\n",
    "    res = calculate_resolution_meters_per_pixel(zoom, center_lat)\n",
    "    if res <= target_resolution:\n",
    "        target_zoom = zoom\n",
    "        break\n",
    "\n",
    "if target_zoom is None:\n",
    "    target_zoom = 18  # Fallback to zoom 18\n",
    "\n",
    "print(f\"\\nTarget resolution: {target_resolution} m/pixel\")\n",
    "print(f\"Calculated zoom level: {target_zoom}\")\n",
    "print(f\"Expected resolution at zoom {target_zoom}: {calculate_resolution_meters_per_pixel(target_zoom, center_lat):.2f} m/pixel\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2b: Download HIGH RESOLUTION basemaps\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Download HIGH RESOLUTION ESRI World Imagery basemap\n",
    "basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "if Path(basemap_esri_path).exists():\n",
    "    print(f\"\\n‚úì ESRI basemap (HIGH RES) already exists: {basemap_esri_path}\")\n",
    "    print(\"  REUSING existing file (skipping download)\")\n",
    "else:\n",
    "    print(f\"\\nDownloading HIGH RESOLUTION ESRI World Imagery basemap (zoom {target_zoom})...\")\n",
    "    basemap_esri_path = download_basemap(\n",
    "        bbox=bbox,\n",
    "        output_path=basemap_esri_path,\n",
    "        source=\"esri_world_imagery\",\n",
    "        zoom=target_zoom  # Use high zoom for better resolution\n",
    "    )\n",
    "\n",
    "with rasterio.open(basemap_esri_path) as src:\n",
    "    esri_hr_width = src.width\n",
    "    esri_hr_height = src.height\n",
    "    esri_hr_bounds = src.bounds\n",
    "    width_meters = (esri_hr_bounds.right - esri_hr_bounds.left) * 111320 * math.cos(math.radians(center_lat))\n",
    "    height_meters = (esri_hr_bounds.top - esri_hr_bounds.bottom) * 111320\n",
    "    esri_hr_resolution = ((width_meters / esri_hr_width) + (height_meters / esri_hr_height)) / 2.0\n",
    "\n",
    "print(f\"  Dimensions: {esri_hr_width} x {esri_hr_height} pixels\")\n",
    "print(f\"  Resolution: {esri_hr_resolution:.2f} meters per pixel\")\n",
    "if not Path(basemap_esri_path).exists() or Path(basemap_esri_path).stat().st_mtime > Path(basemap_esri_path_low).stat().st_mtime:\n",
    "    print(f\"  Improvement: {esri_resolution/esri_hr_resolution:.1f}x higher resolution\")\n",
    "\n",
    "# Download HIGH RESOLUTION OpenStreetMap basemap\n",
    "basemap_osm_path = str(output_dir / \"qualicum_beach_basemap_osm.tif\")\n",
    "if Path(basemap_osm_path).exists():\n",
    "    print(f\"\\n‚úì OpenStreetMap basemap (HIGH RES) already exists: {basemap_osm_path}\")\n",
    "    print(\"  REUSING existing file (skipping download)\")\n",
    "else:\n",
    "    print(f\"\\nDownloading HIGH RESOLUTION OpenStreetMap basemap (zoom {target_zoom})...\")\n",
    "    basemap_osm_path = download_basemap(\n",
    "        bbox=bbox,\n",
    "        output_path=basemap_osm_path,\n",
    "        source=\"openstreetmap\",\n",
    "        zoom=target_zoom  # Use high zoom for better resolution\n",
    "    )\n",
    "\n",
    "with rasterio.open(basemap_osm_path) as src:\n",
    "    osm_hr_width = src.width\n",
    "    osm_hr_height = src.height\n",
    "    osm_hr_bounds = src.bounds\n",
    "    width_meters = (osm_hr_bounds.right - osm_hr_bounds.left) * 111320 * math.cos(math.radians(center_lat))\n",
    "    height_meters = (osm_hr_bounds.top - osm_hr_bounds.bottom) * 111320\n",
    "    osm_hr_resolution = ((width_meters / osm_hr_width) + (height_meters / osm_hr_height)) / 2.0\n",
    "\n",
    "print(f\"  Dimensions: {osm_hr_width} x {osm_hr_height} pixels\")\n",
    "print(f\"  Resolution: {osm_hr_resolution:.2f} meters per pixel\")\n",
    "if not Path(basemap_osm_path).exists() or Path(basemap_osm_path).stat().st_mtime > Path(basemap_osm_path_low).stat().st_mtime:\n",
    "    print(f\"  Improvement: {osm_resolution/osm_hr_resolution:.1f}x higher resolution\")\n",
    "\n",
    "# Optionally download Google Satellite basemap (high resolution)\n",
    "# Note: Google tiles may be subject to Terms of Service restrictions\n",
    "# For production use, consider Google Earth Engine API with authentication\n",
    "basemap_google_path = str(output_dir / \"qualicum_beach_basemap_google.tif\")\n",
    "google_downloaded = False\n",
    "google_hr_resolution = None\n",
    "\n",
    "if Path(basemap_google_path).exists():\n",
    "    print(f\"\\n‚úì Google Satellite basemap (HIGH RES) already exists: {basemap_google_path}\")\n",
    "    print(\"  REUSING existing file (skipping download)\")\n",
    "    try:\n",
    "        with rasterio.open(basemap_google_path) as src:\n",
    "            google_hr_width = src.width\n",
    "            google_hr_height = src.height\n",
    "            google_hr_bounds = src.bounds\n",
    "            width_meters = (google_hr_bounds.right - google_hr_bounds.left) * 111320 * math.cos(math.radians(center_lat))\n",
    "            height_meters = (google_hr_bounds.top - google_hr_bounds.bottom) * 111320\n",
    "            google_hr_resolution = ((width_meters / google_hr_width) + (height_meters / google_hr_height)) / 2.0\n",
    "        print(f\"  Dimensions: {google_hr_width} x {google_hr_height} pixels\")\n",
    "        print(f\"  Resolution: {google_hr_resolution:.2f} meters per pixel\")\n",
    "        google_downloaded = True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Error reading existing Google basemap: {e}\")\n",
    "        google_downloaded = False\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\nDownloading HIGH RESOLUTION Google Satellite basemap (zoom {target_zoom})...\")\n",
    "        print(\"  Note: Google tile access may be subject to Terms of Service.\")\n",
    "        print(\"  For production use, consider Google Earth Engine API.\")\n",
    "        basemap_google_path = download_basemap(\n",
    "            bbox=bbox,\n",
    "            output_path=basemap_google_path,\n",
    "            source=\"google_satellite\",\n",
    "            zoom=target_zoom\n",
    "        )\n",
    "        \n",
    "        with rasterio.open(basemap_google_path) as src:\n",
    "            google_hr_width = src.width\n",
    "            google_hr_height = src.height\n",
    "            google_hr_bounds = src.bounds\n",
    "            width_meters = (google_hr_bounds.right - google_hr_bounds.left) * 111320 * math.cos(math.radians(center_lat))\n",
    "            height_meters = (google_hr_bounds.top - google_hr_bounds.bottom) * 111320\n",
    "            google_hr_resolution = ((width_meters / google_hr_width) + (height_meters / google_hr_height)) / 2.0\n",
    "        \n",
    "        print(f\"‚úì Google Satellite basemap (HIGH RES) saved: {basemap_google_path}\")\n",
    "        print(f\"  Dimensions: {google_hr_width} x {google_hr_height} pixels\")\n",
    "        print(f\"  Resolution: {google_hr_resolution:.2f} meters per pixel\")\n",
    "        google_downloaded = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not download Google Satellite basemap: {e}\")\n",
    "        print(\"  Continuing with ESRI and OpenStreetMap basemaps only...\")\n",
    "        basemap_google_path = None\n",
    "        google_downloaded = False\n",
    "        google_hr_resolution = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Basemap Resolution Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ESRI World Imagery (HIGH RES):     {esri_hr_resolution:.2f} m/pixel\")\n",
    "print(f\"OpenStreetMap (HIGH RES):          {osm_hr_resolution:.2f} m/pixel\")\n",
    "if google_downloaded and google_hr_resolution:\n",
    "    print(f\"Google Satellite (HIGH RES):      {google_hr_resolution:.2f} m/pixel\")\n",
    "print(f\"\\n‚úì High resolution basemaps are ready for analysis!\")\n",
    "if google_downloaded:\n",
    "    print(f\"\\nNote: Google Satellite tiles may be subject to Terms of Service restrictions.\")\n",
    "    print(f\"      For production use, consider Google Earth Engine API with authentication.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Drone Imagery from S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 14:12:05,512 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Found 12 manifest files\n",
      "2025-12-09 14:12:05,615 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172543.txt\n",
      "2025-12-09 14:12:05,615 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,615 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac53ffff/172543/\n",
      "2025-12-09 14:12:05,615 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 152\n",
      "2025-12-09 14:12:05,617 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 152 skipped, 0 failed\n",
      "2025-12-09 14:12:05,621 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172547.txt\n",
      "2025-12-09 14:12:05,621 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,621 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89accbffff/172547/\n",
      "2025-12-09 14:12:05,622 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 151\n",
      "2025-12-09 14:12:05,623 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 151 skipped, 0 failed\n",
      "2025-12-09 14:12:05,627 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172550.txt\n",
      "2025-12-09 14:12:05,627 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,627 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac57ffff/172550/\n",
      "2025-12-09 14:12:05,627 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 155\n",
      "2025-12-09 14:12:05,629 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 155 skipped, 0 failed\n",
      "2025-12-09 14:12:05,632 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172553.txt\n",
      "2025-12-09 14:12:05,632 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,633 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89accfffff/172553/\n",
      "2025-12-09 14:12:05,633 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 153\n",
      "2025-12-09 14:12:05,634 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 153 skipped, 0 failed\n",
      "2025-12-09 14:12:05,638 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172555.txt\n",
      "2025-12-09 14:12:05,638 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,638 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac0bffff/172555/\n",
      "2025-12-09 14:12:05,638 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-09 14:12:05,640 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-09 14:12:05,643 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172562.txt\n",
      "2025-12-09 14:12:05,644 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,644 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac73ffff/172562/\n",
      "2025-12-09 14:12:05,644 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-09 14:12:05,645 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-09 14:12:05,649 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172565.txt\n",
      "2025-12-09 14:12:05,649 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,650 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac47ffff/172565/\n",
      "2025-12-09 14:12:05,650 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 152\n",
      "2025-12-09 14:12:05,651 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 152 skipped, 0 failed\n",
      "2025-12-09 14:12:05,655 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172568.txt\n",
      "2025-12-09 14:12:05,656 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,656 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac43ffff/172568/\n",
      "2025-12-09 14:12:05,656 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 152\n",
      "2025-12-09 14:12:05,658 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 152 skipped, 0 failed\n",
      "2025-12-09 14:12:05,661 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172571.txt\n",
      "2025-12-09 14:12:05,661 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,662 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac5bffff/172571/\n",
      "2025-12-09 14:12:05,662 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-09 14:12:05,663 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-09 14:12:05,667 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_183538.txt\n",
      "2025-12-09 14:12:05,668 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,668 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89acc7ffff/183538/\n",
      "2025-12-09 14:12:05,668 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 155\n",
      "2025-12-09 14:12:05,670 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 155 skipped, 0 failed\n",
      "2025-12-09 14:12:05,673 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_183544.txt\n",
      "2025-12-09 14:12:05,673 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,674 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac1bffff/183544/\n",
      "2025-12-09 14:12:05,674 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 155\n",
      "2025-12-09 14:12:05,675 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 155 skipped, 0 failed\n",
      "2025-12-09 14:12:05,682 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_183548.txt\n",
      "2025-12-09 14:12:05,682 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-09 14:12:05,682 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac03ffff/183548/\n",
      "2025-12-09 14:12:05,682 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-09 14:12:05,684 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-09 14:12:05,684 - qualicum_beach_gcp_analysis.s3_downloader - INFO - \n",
      "============================================================\n",
      "2025-12-09 14:12:05,684 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Download Summary\n",
      "2025-12-09 14:12:05,684 - qualicum_beach_gcp_analysis.s3_downloader - INFO - ============================================================\n",
      "2025-12-09 14:12:05,685 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Total manifest files: 12\n",
      "2025-12-09 14:12:05,685 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Total images: 1841\n",
      "2025-12-09 14:12:05,685 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Downloaded: 0\n",
      "2025-12-09 14:12:05,685 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Skipped (already exist): 1841\n",
      "2025-12-09 14:12:05,685 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Failed: 0\n",
      "2025-12-09 14:12:05,685 - qualicum_beach_gcp_analysis.s3_downloader - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images from S3...\n",
      "============================================================\n",
      "============================================================\n",
      "‚úì Image download complete\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "input_dir = Path(\"input\")\n",
    "photos_dir = Path(\"input/images\")\n",
    "\n",
    "# Download all images from input manifest files\n",
    "print(\"Downloading images from S3...\")\n",
    "print(\"=\" * 60)\n",
    "download_stats = download_all_images_from_input_dir(\n",
    "    input_dir=input_dir,\n",
    "    photos_dir=photos_dir,\n",
    "    skip_existing=True  # Don't re-download if images already exist\n",
    ")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úì Image download complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Export GCPs for MetaShape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 12 GCPs to MetaShape XML: outputs/gcps_metashape.xml\n",
      "‚úì GCPs exported to XML: outputs/gcps_metashape.xml\n",
      "Exported 12 GCPs to MetaShape CSV: outputs/gcps_metashape.csv\n",
      "‚úì GCPs also exported to CSV: outputs/gcps_metashape.csv\n"
     ]
    }
   ],
   "source": [
    "# Export GCPs to MetaShape XML format (preferred by MetaShape)\n",
    "gcp_xml_path = output_dir / \"gcps_metashape.xml\"\n",
    "export_to_metashape_xml(gcps, str(gcp_xml_path))\n",
    "print(f\"‚úì GCPs exported to XML: {gcp_xml_path}\")\n",
    "\n",
    "# Also export CSV for reference\n",
    "gcp_csv_path = output_dir / \"gcps_metashape.csv\"\n",
    "export_to_metashape_csv(gcps, str(gcp_csv_path))\n",
    "print(f\"‚úì GCPs also exported to CSV: {gcp_csv_path}\")\n",
    "\n",
    "# Use XML file for processing (MetaShape's native format)\n",
    "gcp_file_path = gcp_xml_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Process Orthomosaic WITHOUT GCPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 14:12:05,697 - qualicum_beach_gcp_analysis.metashape_processor - INFO - üìù MetaShape verbose output will be saved to: outputs/intermediate/logs/orthomosaic_no_gcps_metashape.log\n",
      "2025-12-09 14:12:05,697 - qualicum_beach_gcp_analysis.metashape_processor - INFO - üìÇ Loading existing project: outputs/intermediate/orthomosaic_no_gcps.psx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing orthomosaic WITHOUT GCPs...\n",
      "============================================================\n",
      "LoadProject: path = outputs/intermediate/orthomosaic_no_gcps.psx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document.open(): The document is opened in read-only mode because it is already in use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded project in 0.002127 sec\n",
      "SaveProject: path = outputs/intermediate/orthomosaic_no_gcps.psx\n",
      "saved project in 0.138536 sec\n",
      "LoadProject: path = outputs/intermediate/orthomosaic_no_gcps.psx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 14:12:06,818 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   ‚úì Project opened in writable mode\n",
      "2025-12-09 14:12:06,819 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Found existing chunk with 1841 cameras\n",
      "2025-12-09 14:12:06,820 - qualicum_beach_gcp_analysis.metashape_processor - INFO - Processing status:\n",
      "2025-12-09 14:12:06,820 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Photos added: True\n",
      "2025-12-09 14:12:06,820 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Photos matched: False\n",
      "2025-12-09 14:12:06,821 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Cameras aligned: False\n",
      "2025-12-09 14:12:06,821 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Depth maps built: False\n",
      "2025-12-09 14:12:06,822 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Model built: False\n",
      "2025-12-09 14:12:06,822 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Orthomosaic built: False\n",
      "2025-12-09 14:12:06,823 - qualicum_beach_gcp_analysis.metashape_processor - INFO - ‚úì Photos already added (1841 cameras)\n",
      "2025-12-09 14:12:06,824 - qualicum_beach_gcp_analysis.metashape_processor - INFO - üîç Matching photos (this may take a while)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded project in 0.132732 sec\n",
      "MatchPhotos: accuracy = Medium, preselection = generic, reference, keypoint limit = 40000, keypoint limit per mpx = 1000, tiepoint limit = 10000, apply masks = 0, filter tie points = 1, filter stationary points = 1, guided matching = 0\n",
      "SaveProject: path = outputs/intermediate/orthomosaic_no_gcps.psx\n",
      "saved project in 0.001151 sec\n",
      "LoadProject: path = outputs/intermediate/orthomosaic_no_gcps.psx\n",
      "loaded project in 0.178588 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 14:12:07,435 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   ‚úì Photo matching complete\n",
      "2025-12-09 14:12:07,436 - qualicum_beach_gcp_analysis.metashape_processor - INFO - üìê Aligning cameras...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlignCameras: adaptive fitting = 0\n",
      "processing matches... done in 0.901395 sec\n",
      "selecting camera groups... \n",
      "groups: 168, 153, 88, 114, 123, 74, 79, 68, 139, 92, 58, 61, 57, 56, 66, 64, 121, 73, 60, 65, 53, 2\n",
      "n groups: 22, total: 1834, minmax: [2, 168]\n",
      "done in 0.224935 sec\n",
      "scheduled 22 alignment groups\n",
      "saved camera partition in 0.000197 sec\n",
      "loaded camera partition in 2.8e-05 sec\n",
      "processing block: 168 photos\n",
      "pair 99 and 100: 3870 robust from 3878\n",
      "pair 100 and 101: 3768 robust from 3780\n",
      "pair 9 and 10: 599 robust from 4682\n",
      "pair 118 and 119: 4431 robust from 4439\n",
      "pair 98 and 99: 3896 robust from 3901\n",
      "pair 132 and 133: 3866 robust from 3874\n",
      "pair 130 and 132: 3754 robust from 3758\n",
      "pair 19 and 121: 4063 robust from 4076\n",
      "pair 119 and 120: 3795 robust from 3801\n",
      "pair 166 and 167: 5 robust from 4373\n",
      "pair 133 and 134: 73 robust from 4461\n",
      "pair 94 and 95: 0 robust from 5155\n",
      "evaluating initial pair...\n",
      "initial pair evaluated in 0.425277 sec.\n",
      "initial pair unstable, considering additional pairs...\n",
      "pair 163 and 164: 3740 robust from 3753\n",
      "pair 155 and 156: 3629 robust from 3636\n",
      "pair 164 and 165: 3487 robust from 3493\n",
      "pair 78 and 79: 3593 robust from 3606\n",
      "pair 75 and 76: 3476 robust from 3492\n",
      "pair 130 and 131: 3486 robust from 3488\n",
      "pair 145 and 146: 3485 robust from 3500\n",
      "pair 82 and 83: 3446 robust from 3461\n",
      "pair 120 and 121: 3493 robust from 3504\n",
      "pair 22 and 23: 3595 robust from 3607\n",
      "pair 142 and 143: 3587 robust from 3602\n",
      "pair 94 and 95: 0 robust from 5155\n",
      "pair 156 and 157: 3412 robust from 3423\n",
      "pair 162 and 163: 3421 robust from 3429\n",
      "pair 144 and 145: 3434 robust from 3443\n",
      "pair 54 and 55: 3384 robust from 3403\n",
      "pair 165 and 166: 3389 robust from 3401\n",
      "pair 101 and 102: 3385 robust from 3393\n",
      "pair 125 and 126: 3369 robust from 3379\n",
      "pair 74 and 75: 3317 robust from 3329\n",
      "pair 141 and 142: 3379 robust from 3394\n",
      "pair 17 and 18: 3346 robust from 3351\n",
      "pair 148 and 149: 3272 robust from 3286\n",
      "pair 81 and 82: 3261 robust from 3274\n",
      "pair 21 and 22: 3285 robust from 3288\n",
      "pair 157 and 158: 3251 robust from 3264\n",
      "pair 103 and 104: 3231 robust from 3245\n",
      "pair 117 and 118: 3404 robust from 3413\n",
      "pair 154 and 155: 3227 robust from 3238\n",
      "pair 139 and 140: 3222 robust from 3227\n",
      "pair 153 and 154: 3196 robust from 3207\n",
      "pair 84 and 85: 3249 robust from 3259\n",
      "pair 102 and 103: 3212 robust from 3222\n",
      "pair 35 and 36: 3174 robust from 3182\n",
      "pair 124 and 125: 3173 robust from 3182\n",
      "pair 76 and 77: 3160 robust from 3187\n",
      "pair 116 and 117: 3303 robust from 3307\n",
      "pair 137 and 138: 3168 robust from 3175\n",
      "pair 123 and 124: 3144 robust from 3151\n",
      "pair 97 and 98: 3142 robust from 3146\n",
      "pair 115 and 116: 3147 robust from 3153\n",
      "pair 140 and 141: 3128 robust from 3136\n",
      "pair 89 and 90: 3106 robust from 3120\n",
      "pair 73 and 74: 3103 robust from 3123\n",
      "pair 85 and 86: 3100 robust from 3111\n",
      "pair 143 and 144: 3100 robust from 3108\n",
      "pair 158 and 160: 3063 robust from 3075\n",
      "pair 161 and 162: 3091 robust from 3100\n",
      "pair 83 and 84: 3194 robust from 3210\n",
      "pair 23 and 24: 3101 robust from 3105\n",
      "pair 138 and 139: 3080 robust from 3083\n",
      "pair 36 and 37: 3039 robust from 3047\n",
      "pair 136 and 137: 3088 robust from 3091\n",
      "pair 15 and 16: 3048 robust from 3054\n",
      "pair 146 and 147: 3159 robust from 3173\n",
      "pair 38 and 39: 2994 robust from 2999\n",
      "pair 108 and 109: 3033 robust from 3044\n",
      "pair 18 and 95: 3038 robust from 3045\n",
      "pair 126 and 127: 2981 robust from 2990\n",
      "pair 159 and 160: 3037 robust from 3050\n",
      "pair 88 and 89: 2987 robust from 2998\n",
      "pair 113 and 114: 2959 robust from 2974\n",
      "pair 77 and 78: 2995 robust from 3010\n",
      "pair 129 and 131: 2970 robust from 2978\n",
      "pair 111 and 112: 2953 robust from 2960\n",
      "pair 100 and 117: 1586 robust from 2964\n",
      "pair 90 and 91: 3018 robust from 3030\n",
      "pair 33 and 34: 2889 robust from 2899\n",
      "pair 112 and 113: 2948 robust from 2957\n",
      "pair 72 and 73: 2922 robust from 2929\n",
      "pair 20 and 21: 2889 robust from 2898\n",
      "pair 114 and 115: 2791 robust from 2800\n",
      "pair 132 and 134: 2827 robust from 2835\n",
      "pair 104 and 105: 2934 robust from 2943\n",
      "pair 24 and 25: 2862 robust from 2865\n",
      "pair 1 and 2: 2814 robust from 2834\n",
      "pair 19 and 120: 2781 robust from 2784\n",
      "pair 34 and 35: 2868 robust from 2876\n",
      "pair 91 and 92: 2762 robust from 2772\n",
      "pair 19 and 133: 270 robust from 2757\n",
      "pair 14 and 15: 2755 robust from 2768\n",
      "pair 16 and 17: 2738 robust from 2746\n",
      "pair 99 and 118: 2745 robust from 2756\n",
      "pair 105 and 106: 2740 robust from 2755\n",
      "pair 119 and 130: 2705 robust from 2728\n",
      "pair 147 and 148: 2970 robust from 2981\n",
      "pair 67 and 68: 2698 robust from 2713\n",
      "pair 19 and 20: 2769 robust from 2776\n",
      "pair 159 and 161: 2811 robust from 2819\n",
      "pair 37 and 38: 2691 robust from 2695\n",
      "pair 71 and 72: 2708 robust from 2726\n",
      "pair 32 and 33: 2684 robust from 2688\n",
      "pair 96 and 97: 2681 robust from 2690\n",
      "pair 19 and 134: 2673 robust from 2684\n",
      "pair 8 and 10: 2629 robust from 2649\n",
      "pair 86 and 87: 2657 robust from 2664\n",
      "pair 101 and 116: 2749 robust from 2769\n",
      "pair 127 and 128: 2631 robust from 2639\n",
      "pair 128 and 129: 2615 robust from 2619\n",
      "pair 57 and 58: 2563 robust from 2585\n",
      "pair 120 and 132: 2583 robust from 2597\n",
      "pair 0 and 1: 2607 robust from 2617\n",
      "pair 80 and 81: 2554 robust from 2563\n",
      "pair 18 and 96: 2560 robust from 2565\n",
      "pair 101 and 117: 2654 robust from 2669\n",
      "pair 49 and 50: 2555 robust from 2577\n",
      "pair 98 and 119: 2616 robust from 2631\n",
      "pair 31 and 32: 2551 robust from 2557\n",
      "pair 151 and 153: 2577 robust from 2589\n",
      "pair 15 and 23: 2600 robust from 2621\n",
      "pair 16 and 22: 2559 robust from 2578\n",
      "additional pairs considered in 0.371333 sec.\n",
      "optimizing initial pair...\n",
      "********************x*******************************************************************************\n",
      "default pair score: n_aligned: 3, n_points_tier: 1, accuracy_tier: 1, reprojection_error: 0.744954, accuracy: 0.0124824, n_points: 2108, ids: [118, 119]\n",
      "optimal pair score: n_aligned: 3, n_points_tier: 1, accuracy_tier: 1, reprojection_error: 0.493434, accuracy: 0.00348246, n_points: 2360, ids: [19, 121]\n",
      "initial pair optimized in 2.22847 sec.\n",
      "pair 19 and 121: 4063 robust\n",
      "adding 4074 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.211946 -> 0.209584\n",
      "adding 0 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.009724 seconds\n",
      "adding camera 120 (3 of 168), 2342 of 2360 used\n",
      "adding camera 133 (4 of 168), 1738 of 1758 used\n",
      "adding camera 134 (5 of 168), 1700 of 1722 used\n",
      "adding camera 20 (6 of 168), 1615 of 1666 used\n",
      "adding camera 132 (7 of 168), 1519 of 1572 used\n",
      "adding camera 97 (8 of 168), 1448 of 1584 used\n",
      "adding camera 119 (9 of 168), 1352 of 1492 used\n",
      "adding camera 96 (10 of 168), 1271 of 1410 used\n",
      "adding 11738 points, 7 far ((-, -) threshold), 306 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.567286 -> 0.290691\n",
      "adding 310 points, 0 far ((-, -) threshold), 323 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.065161 seconds\n",
      "adding camera 130 (11 of 168), 3219 of 3259 used\n",
      "adding camera 98 (12 of 168), 2885 of 2920 used\n",
      "adding camera 118 (13 of 168), 2687 of 2715 used\n",
      "adding camera 18 (14 of 168), 2412 of 2440 used\n",
      "adding camera 39 (15 of 168), 2067 of 2129 used\n",
      "adding camera 99 (16 of 168), 1900 of 1936 used\n",
      "adding camera 17 (17 of 168), 1720 of 1757 used\n",
      "adding camera 21 (18 of 168), 1713 of 1753 used\n",
      "adding camera 131 (19 of 168), 1703 of 1743 used\n",
      "adding camera 137 (20 of 168), 1597 of 1690 used\n",
      "adding camera 136 (21 of 168), 1519 of 1623 used\n",
      "adding camera 95 (22 of 168), 1513 of 1544 used\n",
      "adding camera 94 (23 of 168), 1453 of 1488 used\n",
      "adding camera 117 (24 of 168), 1182 of 1223 used\n",
      "adding camera 92 (25 of 168), 1160 of 1190 used\n",
      "adding camera 100 (26 of 168), 1103 of 1135 used\n",
      "adding camera 93 (27 of 168), 1101 of 1132 used\n",
      "adding camera 138 (28 of 168), 1092 of 1151 used\n",
      "adding camera 135 (29 of 168), 1091 of 1164 used\n",
      "adding camera 38 (30 of 168), 1038 of 1079 used\n",
      "adding 29762 points, 81 far ((-, -) threshold), 2797 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.456147 -> 0.377785\n",
      "adding 2838 points, 0 far ((-, -) threshold), 2748 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.382626 -> 0.25424\n",
      "adding 2749 points, 0 far ((-, -) threshold), 2705 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.255385 -> 0.2552\n",
      "adding 2705 points, 0 far ((-, -) threshold), 2707 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 1.08631 seconds\n",
      "adding camera 101 (31 of 168), 3033 of 3062 used\n",
      "adding camera 129 (32 of 168), 2743 of 2772 used\n",
      "adding camera 91 (33 of 168), 2623 of 2646 used\n",
      "adding camera 16 (34 of 168), 2475 of 2499 used\n",
      "adding camera 22 (35 of 168), 2406 of 2432 used\n",
      "adding camera 116 (36 of 168), 2300 of 2326 used\n",
      "adding camera 90 (37 of 168), 2260 of 2287 used\n",
      "adding camera 37 (38 of 168), 2113 of 2138 used\n",
      "adding camera 139 (39 of 168), 2091 of 2120 used\n",
      "adding camera 164 (40 of 168), 2055 of 2089 used\n",
      "adding camera 40 (41 of 168), 1893 of 1926 used\n",
      "adding camera 163 (42 of 168), 1874 of 1905 used\n",
      "adding camera 165 (43 of 168), 1770 of 1812 used\n",
      "adding camera 89 (44 of 168), 1761 of 1777 used\n",
      "adding camera 102 (45 of 168), 1578 of 1598 used\n",
      "adding camera 162 (46 of 168), 1454 of 1487 used\n",
      "adding camera 23 (47 of 168), 1318 of 1340 used\n",
      "adding camera 15 (48 of 168), 1305 of 1320 used\n",
      "adding camera 167 (49 of 168), 1297 of 1328 used\n",
      "adding camera 128 (50 of 168), 1294 of 1321 used\n",
      "adding camera 166 (51 of 168), 1290 of 1322 used\n",
      "adding camera 65 (52 of 168), 1260 of 1292 used\n",
      "adding camera 36 (53 of 168), 1202 of 1226 used\n",
      "adding camera 66 (54 of 168), 1168 of 1189 used\n",
      "adding camera 115 (55 of 168), 1138 of 1165 used\n",
      "adding camera 140 (56 of 168), 1137 of 1167 used\n",
      "adding camera 88 (57 of 168), 1060 of 1076 used\n",
      "adding 41801 points, 61 far ((-, -) threshold), 2709 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.313211 -> 0.255768\n",
      "adding 2722 points, 4 far ((-, -) threshold), 2755 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.615813 seconds\n",
      "adding camera 161 (58 of 168), 2750 of 2780 used\n",
      "adding camera 103 (59 of 168), 2717 of 2756 used\n",
      "adding camera 24 (60 of 168), 2443 of 2462 used\n",
      "adding camera 35 (61 of 168), 2429 of 2461 used\n",
      "adding camera 67 (62 of 168), 2388 of 2437 used\n",
      "adding camera 14 (63 of 168), 2333 of 2351 used\n",
      "adding camera 68 (64 of 168), 2136 of 2180 used\n",
      "adding camera 141 (65 of 168), 2114 of 2148 used\n",
      "adding camera 87 (66 of 168), 2037 of 2072 used\n",
      "adding camera 127 (67 of 168), 1981 of 2006 used\n",
      "adding camera 114 (68 of 168), 1981 of 2005 used\n",
      "adding camera 159 (69 of 168), 1819 of 1833 used\n",
      "adding camera 69 (70 of 168), 1780 of 1818 used\n",
      "adding camera 104 (71 of 168), 1403 of 1431 used\n",
      "adding camera 64 (72 of 168), 1341 of 1371 used\n",
      "adding camera 160 (73 of 168), 1163 of 1175 used\n",
      "adding camera 34 (74 of 168), 1154 of 1185 used\n",
      "adding camera 142 (75 of 168), 1140 of 1169 used\n",
      "adding camera 126 (76 of 168), 1106 of 1136 used\n",
      "adding camera 13 (77 of 168), 1072 of 1092 used\n",
      "adding camera 25 (78 of 168), 1057 of 1071 used\n",
      "adding 31398 points, 67 far ((-, -) threshold), 2738 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.280056 -> 0.2536\n",
      "adding 2763 points, 4 far ((-, -) threshold), 2744 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.255445 -> 0.255219\n",
      "adding 2747 points, 1 far ((-, -) threshold), 2740 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.255871 -> 0.255731\n",
      "adding 2741 points, 3 far ((-, -) threshold), 2744 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 2.1382 seconds\n",
      "adding camera 158 (79 of 168), 2803 of 2836 used\n",
      "adding camera 143 (80 of 168), 2558 of 2590 used\n",
      "adding camera 113 (81 of 168), 2370 of 2404 used\n",
      "adding camera 86 (82 of 168), 2198 of 2228 used\n",
      "adding camera 125 (83 of 168), 2086 of 2111 used\n",
      "adding camera 105 (84 of 168), 1917 of 1933 used\n",
      "adding camera 33 (85 of 168), 1883 of 1899 used\n",
      "adding camera 26 (86 of 168), 1804 of 1821 used\n",
      "adding camera 70 (87 of 168), 1748 of 1770 used\n",
      "adding camera 12 (88 of 168), 1654 of 1670 used\n",
      "adding camera 157 (89 of 168), 1542 of 1570 used\n",
      "adding camera 85 (90 of 168), 1372 of 1397 used\n",
      "adding camera 144 (91 of 168), 1312 of 1339 used\n",
      "adding camera 112 (92 of 168), 1203 of 1224 used\n",
      "adding camera 124 (93 of 168), 1006 of 1023 used\n",
      "adding 24442 points, 31 far ((-, -) threshold), 2740 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.270503 -> 0.255526\n",
      "adding 2748 points, 4 far ((-, -) threshold), 2745 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.944039 seconds\n",
      "adding camera 156 (94 of 168), 2809 of 2848 used\n",
      "adding camera 145 (95 of 168), 2511 of 2538 used\n",
      "adding camera 84 (96 of 168), 2296 of 2312 used\n",
      "adding camera 123 (97 of 168), 2153 of 2168 used\n",
      "adding camera 106 (98 of 168), 2145 of 2163 used\n",
      "adding camera 111 (99 of 168), 1999 of 2015 used\n",
      "adding camera 71 (100 of 168), 1943 of 1986 used\n",
      "adding camera 72 (101 of 168), 1886 of 1916 used\n",
      "adding camera 32 (102 of 168), 1764 of 1779 used\n",
      "adding camera 27 (103 of 168), 1724 of 1742 used\n",
      "adding camera 155 (104 of 168), 1715 of 1756 used\n",
      "adding camera 11 (105 of 168), 1463 of 1483 used\n",
      "adding camera 146 (106 of 168), 1417 of 1437 used\n",
      "adding camera 73 (107 of 168), 1384 of 1417 used\n",
      "adding camera 83 (108 of 168), 1109 of 1123 used\n",
      "adding camera 107 (109 of 168), 1100 of 1104 used\n",
      "adding 25983 points, 26 far ((-, -) threshold), 2740 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.269951 -> 0.256908\n",
      "adding 2750 points, 5 far ((-, -) threshold), 2746 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 1.03323 seconds\n",
      "adding camera 74 (110 of 168), 2786 of 2844 used\n",
      "adding camera 154 (111 of 168), 2574 of 2620 used\n",
      "adding camera 147 (112 of 168), 2224 of 2257 used\n",
      "adding camera 82 (113 of 168), 2060 of 2089 used\n",
      "adding camera 122 (114 of 168), 1797 of 1809 used\n",
      "adding camera 110 (115 of 168), 1670 of 1682 used\n",
      "adding camera 75 (116 of 168), 1659 of 1702 used\n",
      "adding camera 31 (117 of 168), 1475 of 1489 used\n",
      "adding camera 108 (118 of 168), 1448 of 1457 used\n",
      "adding camera 10 (119 of 168), 1429 of 1453 used\n",
      "adding camera 153 (120 of 168), 1411 of 1443 used\n",
      "adding camera 9 (121 of 168), 1385 of 1403 used\n",
      "adding camera 28 (122 of 168), 1174 of 1189 used\n",
      "adding camera 148 (123 of 168), 1165 of 1176 used\n",
      "adding camera 41 (124 of 168), 1024 of 1039 used\n",
      "adding camera 76 (125 of 168), 1008 of 1036 used\n",
      "adding camera 81 (126 of 168), 1005 of 1025 used\n",
      "adding 27329 points, 39 far ((-, -) threshold), 2747 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.271266 -> 0.257943\n",
      "adding 2764 points, 7 far ((-, -) threshold), 2747 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.257621 -> 0.257452\n",
      "adding 2753 points, 0 far ((-, -) threshold), 2742 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.259028 -> 0.258917\n",
      "adding 2742 points, 6 far ((-, -) threshold), 2747 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 3.15342 seconds\n",
      "adding camera 77 (127 of 168), 2193 of 2220 used\n",
      "adding camera 8 (128 of 168), 2185 of 2358 used\n",
      "adding camera 151 (129 of 168), 2078 of 2113 used\n",
      "adding camera 109 (130 of 168), 2030 of 2048 used\n",
      "adding camera 149 (131 of 168), 1938 of 1962 used\n",
      "adding camera 80 (132 of 168), 1826 of 1855 used\n",
      "adding camera 42 (133 of 168), 1577 of 1586 used\n",
      "adding camera 58 (134 of 168), 1336 of 1406 used\n",
      "adding camera 59 (135 of 168), 1303 of 1366 used\n",
      "adding camera 60 (136 of 168), 1234 of 1311 used\n",
      "adding camera 30 (137 of 168), 1214 of 1222 used\n",
      "adding camera 61 (138 of 168), 1100 of 1168 used\n",
      "adding camera 78 (139 of 168), 1083 of 1110 used\n",
      "adding camera 57 (140 of 168), 1036 of 1074 used\n",
      "adding camera 43 (141 of 168), 1002 of 1013 used\n",
      "adding 21860 points, 43 far ((-, -) threshold), 2742 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.278541 -> 0.262028\n",
      "adding 2766 points, 8 far ((-, -) threshold), 2746 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.261734 -> 0.261593\n",
      "adding 2753 points, 1 far ((-, -) threshold), 2742 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.263031 -> 0.26292\n",
      "adding 2743 points, 7 far ((-, -) threshold), 2746 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 2.97954 seconds\n",
      "adding camera 79 (142 of 168), 2104 of 2132 used\n",
      "adding camera 56 (143 of 168), 1908 of 1968 used\n",
      "adding camera 7 (144 of 168), 1558 of 1641 used\n",
      "adding camera 62 (145 of 168), 1550 of 1595 used\n",
      "adding camera 44 (146 of 168), 1445 of 1454 used\n",
      "adding camera 152 (147 of 168), 1413 of 1447 used\n",
      "adding camera 50 (148 of 168), 1265 of 1367 used\n",
      "adding camera 51 (149 of 168), 1175 of 1277 used\n",
      "adding camera 49 (150 of 168), 1165 of 1246 used\n",
      "adding camera 63 (151 of 168), 1093 of 1160 used\n",
      "adding camera 29 (152 of 168), 1008 of 1012 used\n",
      "adding 16088 points, 68 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.277892 -> 0.266959\n",
      "adding 2770 points, 9 far ((-, -) threshold), 2746 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.2667 -> 0.266641\n",
      "adding 2757 points, 0 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.268411 -> 0.268299\n",
      "adding 2743 points, 9 far ((-, -) threshold), 2746 inaccurate, 2 invisible, 0 weak\n",
      "optimized in 3.0981 seconds\n",
      "adding camera 48 (153 of 168), 1872 of 1949 used\n",
      "adding camera 52 (154 of 168), 1767 of 1850 used\n",
      "adding camera 47 (155 of 168), 1263 of 1332 used\n",
      "adding camera 6 (156 of 168), 1212 of 1270 used\n",
      "adding camera 53 (157 of 168), 1145 of 1249 used\n",
      "adding camera 45 (158 of 168), 1140 of 1144 used\n",
      "adding camera 0 (159 of 168), 1068 of 1207 used\n",
      "adding 10841 points, 70 far ((-, -) threshold), 2741 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.280717 -> 0.272277\n",
      "adding 2781 points, 9 far ((-, -) threshold), 2746 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.272103 -> 0.272016\n",
      "adding 2755 points, 0 far ((-, -) threshold), 2741 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.273572 -> 0.273472\n",
      "adding 2742 points, 8 far ((-, -) threshold), 2746 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 3.52123 seconds\n",
      "adding camera 1 (160 of 168), 1519 of 1583 used\n",
      "adding camera 46 (161 of 168), 1407 of 1443 used\n",
      "adding camera 54 (162 of 168), 1303 of 1395 used\n",
      "adding camera 2 (163 of 168), 1220 of 1287 used\n",
      "adding camera 5 (164 of 168), 1159 of 1191 used\n",
      "adding camera 55 (165 of 168), 870 of 950 used\n",
      "adding 11787 points, 40 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.283742 -> 0.276506\n",
      "adding 2763 points, 7 far ((-, -) threshold), 2747 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.276135 -> 0.276047\n",
      "adding 2756 points, 0 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.277411 -> 0.277318\n",
      "adding 2743 points, 7 far ((-, -) threshold), 2747 inaccurate, 2 invisible, 0 weak\n",
      "optimized in 3.55159 seconds\n",
      "adding camera 3 (166 of 168), 1757 of 1786 used\n",
      "adding 3908 points, 1 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.278617 -> 0.277684\n",
      "adding 2744 points, 7 far ((-, -) threshold), 2747 inaccurate, 2 invisible, 0 weak\n",
      "optimized in 1.11471 seconds\n",
      "adding camera 4 (167 of 168), 1251 of 1274 used\n",
      "adding 3774 points, 2 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.278386 -> 0.277765\n",
      "adding 2743 points, 7 far ((-, -) threshold), 2747 inaccurate, 2 invisible, 0 weak\n",
      "optimized in 1.00195 seconds\n",
      "adding camera 150 (168 of 168), 537 of 564 used\n",
      "adding 3537 points, 1 far ((-, -) threshold), 2741 inaccurate, 2 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.278179 -> 0.277714\n",
      "adding 2743 points, 7 far ((-, -) threshold), 2747 inaccurate, 2 invisible, 0 weak\n",
      "optimized in 1.10812 seconds\n",
      "3 sigma filtering...\n",
      "adjusting: xxxxxxxx 0.276431 -> 0.276425\n",
      "point variance: (0.299926, -) threshold: (0.899778, -)\n",
      "adding 2743 points, 5121 far ((0.899778, -) threshold), 2739 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxxxxxxxxxxxx 0.207083 -> 0.193474\n",
      "point variance: (0.209061, -) threshold: (0.627182, -)\n",
      "adding 2982 points, 5374 far ((0.627182, -) threshold), 2781 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.179955 -> 0.179841\n",
      "point variance: (0.193226, -) threshold: (0.579678, -)\n",
      "adding 2836 points, 2259 far ((0.579678, -) threshold), 2777 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.176099 -> 0.176062\n",
      "point variance: (0.188603, -) threshold: (0.56581, -)\n",
      "adding 3019 points, 816 far ((0.56581, -) threshold), 2780 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.175157 -> 0.175132\n",
      "point variance: (0.187469, -) threshold: (0.562406, -)\n",
      "adding 3009 points, 471 far ((0.562406, -) threshold), 2775 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 8.78942 seconds\n",
      "f 2773.5, cx -7.18187, cy -1.41773, k1 0.0886884, k2 -0.152008, k3 0.10375\n",
      "finished sfm in 39.5423 seconds\n",
      "loaded projections in 0.01966 sec\n",
      "tracks initialized in 0.127912 sec\n",
      "adding 234685 points, 0 far ((-, -) threshold), 2806 inaccurate, 2 invisible, 0 weak\n",
      "adding camera 280 (169 of 499), 2301 of 2363 used\n",
      "adding camera 207 (170 of 499), 2259 of 2361 used\n",
      "adding camera 357 (171 of 499), 2192 of 2314 used\n",
      "adding camera 281 (172 of 499), 1925 of 2008 used\n",
      "adding camera 374 (173 of 499), 1773 of 1805 used\n",
      "adding camera 394 (174 of 499), 1747 of 1786 used\n",
      "adding camera 395 (175 of 499), 1739 of 1776 used\n",
      "adding camera 282 (176 of 499), 1734 of 1762 used\n",
      "adding camera 358 (177 of 499), 1733 of 1791 used\n",
      "adding camera 283 (178 of 499), 1732 of 1795 used\n",
      "adding camera 393 (179 of 499), 1632 of 1660 used\n",
      "adding camera 194 (180 of 499), 1548 of 1594 used\n",
      "adding camera 206 (181 of 499), 1489 of 1513 used\n",
      "adding camera 252 (182 of 499), 1449 of 1481 used\n",
      "adding camera 208 (183 of 499), 1432 of 1563 used\n",
      "adding camera 268 (184 of 499), 1429 of 1451 used\n",
      "adding camera 301 (185 of 499), 1421 of 1493 used\n",
      "adding camera 426 (186 of 499), 1312 of 1357 used\n",
      "adding camera 392 (187 of 499), 1284 of 1319 used\n",
      "adding camera 253 (188 of 499), 1269 of 1303 used\n",
      "adding camera 193 (189 of 499), 1254 of 1308 used\n",
      "adding camera 427 (190 of 499), 1234 of 1273 used\n",
      "adding camera 425 (191 of 499), 1233 of 1268 used\n",
      "adding camera 375 (192 of 499), 1223 of 1247 used\n",
      "adding camera 396 (193 of 499), 1169 of 1206 used\n",
      "adding camera 403 (194 of 499), 1159 of 1219 used\n",
      "adding camera 355 (195 of 499), 1097 of 1137 used\n",
      "adding camera 293 (196 of 499), 1096 of 1108 used\n",
      "adding camera 294 (197 of 499), 1092 of 1112 used\n",
      "adding camera 404 (198 of 499), 1090 of 1142 used\n",
      "adding camera 359 (199 of 499), 1090 of 1160 used\n",
      "adding camera 402 (200 of 499), 1071 of 1139 used\n",
      "adding camera 480 (201 of 499), 1029 of 1113 used\n",
      "adding camera 175 (202 of 499), 1018 of 1080 used\n",
      "adding camera 405 (203 of 499), 1003 of 1043 used\n",
      "adding 47151 points, 198 far ((-, -) threshold), 2670 inaccurate, 2 invisible, 1 weak\n",
      "adding camera 428 (204 of 499), 3528 of 3571 used\n",
      "adding camera 424 (205 of 499), 3331 of 3377 used\n",
      "adding camera 391 (206 of 499), 2476 of 2556 used\n",
      "adding camera 300 (207 of 499), 2476 of 2545 used\n",
      "adding camera 192 (208 of 499), 2063 of 2139 used\n",
      "adding camera 429 (209 of 499), 1969 of 2040 used\n",
      "adding camera 292 (210 of 499), 1894 of 1913 used\n",
      "adding camera 376 (211 of 499), 1868 of 1909 used\n",
      "adding camera 390 (212 of 499), 1855 of 1993 used\n",
      "adding camera 308 (213 of 499), 1850 of 1900 used\n",
      "adding camera 295 (214 of 499), 1767 of 1796 used\n",
      "adding camera 401 (215 of 499), 1648 of 1720 used\n",
      "adding camera 307 (216 of 499), 1643 of 1687 used\n",
      "adding camera 309 (217 of 499), 1565 of 1605 used\n",
      "adding camera 423 (218 of 499), 1504 of 1539 used\n",
      "adding camera 406 (219 of 499), 1501 of 1570 used\n",
      "adding camera 209 (220 of 499), 1495 of 1592 used\n",
      "adding camera 299 (221 of 499), 1483 of 1557 used\n",
      "adding camera 360 (222 of 499), 1429 of 1512 used\n",
      "adding camera 416 (223 of 499), 1379 of 1440 used\n",
      "adding camera 356 (224 of 499), 1376 of 1482 used\n",
      "adding camera 397 (225 of 499), 1372 of 1424 used\n",
      "adding camera 254 (226 of 499), 1370 of 1409 used\n",
      "adding camera 267 (227 of 499), 1368 of 1408 used\n",
      "adding camera 205 (228 of 499), 1345 of 1393 used\n",
      "adding camera 195 (229 of 499), 1289 of 1317 used\n",
      "adding camera 373 (230 of 499), 1276 of 1320 used\n",
      "adding camera 415 (231 of 499), 1266 of 1325 used\n",
      "adding camera 361 (232 of 499), 1249 of 1337 used\n",
      "adding camera 417 (233 of 499), 1245 of 1310 used\n",
      "adding camera 296 (234 of 499), 1201 of 1239 used\n",
      "adding camera 176 (235 of 499), 1195 of 1250 used\n",
      "adding camera 400 (236 of 499), 1112 of 1169 used\n",
      "adding camera 354 (237 of 499), 1085 of 1161 used\n",
      "adding camera 191 (238 of 499), 1084 of 1179 used\n",
      "adding camera 284 (239 of 499), 1038 of 1046 used\n",
      "adding camera 430 (240 of 499), 1033 of 1098 used\n",
      "adding camera 306 (241 of 499), 1026 of 1057 used\n",
      "adding camera 210 (242 of 499), 1010 of 1051 used\n",
      "adding camera 414 (243 of 499), 1001 of 1054 used\n",
      "adding 55232 points, 216 far ((-, -) threshold), 2661 inaccurate, 4 invisible, 0 weak\n",
      "loaded camera partition in 8.1e-05 sec\n",
      "processing block: 153 photos\n",
      "pair 141 and 142: 3137 robust from 3150\n",
      "pair 57 and 58: 3522 robust from 3545\n",
      "pair 72 and 73: 3091 robust from 3118\n",
      "pair 102 and 103: 3039 robust from 3049\n",
      "pair 143 and 144: 3083 robust from 3085\n",
      "pair 142 and 143: 3312 robust from 3314\n",
      "pair 124 and 125: 3112 robust from 3122\n",
      "pair 75 and 76: 391 robust from 5841\n",
      "pair 37 and 38: 1100 robust from 5150\n",
      "pair 89 and 90: 3737 robust from 3744\n",
      "pair 90 and 91: 4763 robust from 4770\n",
      "pair 103 and 104: 2171 robust from 5228\n",
      "evaluating initial pair...\n",
      "initial pair evaluated in 0.331531 sec.\n",
      "initial pair score: n_aligned: 3, n_points_tier: 1, accuracy_tier: 1, reprojection_error: 0.462886, accuracy: 0.0130229, n_points: 2478, ids: [90, 91]\n",
      "initial pair stable\n",
      "pair 90 and 91: 4763 robust\n",
      "adding 4769 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxx 0.195551 -> 0.193716\n",
      "adding 0 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.007795 seconds\n",
      "adding camera 89 (3 of 153), 2463 of 2479 used\n",
      "adding camera 124 (4 of 153), 1411 of 1428 used\n",
      "adding camera 92 (5 of 153), 1363 of 1553 used\n",
      "adding camera 60 (6 of 153), 1183 of 1238 used\n",
      "adding camera 125 (7 of 153), 1089 of 1113 used\n",
      "adding camera 62 (8 of 153), 1015 of 1073 used\n",
      "adding 7460 points, 10 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.623527 -> 0.289035\n",
      "adding 8 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxx 0.289492 -> 0.289474\n",
      "adding 0 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.076266 seconds\n",
      "adding camera 88 (9 of 153), 1894 of 1916 used\n",
      "adding camera 59 (10 of 153), 1655 of 1681 used\n",
      "adding camera 93 (11 of 153), 1635 of 1662 used\n",
      "adding camera 61 (12 of 153), 1380 of 1386 used\n",
      "adding camera 126 (13 of 153), 1337 of 1358 used\n",
      "adding camera 55 (14 of 153), 1307 of 1318 used\n",
      "adding camera 142 (15 of 153), 1206 of 1235 used\n",
      "adding camera 143 (16 of 153), 1162 of 1191 used\n",
      "adding camera 54 (17 of 153), 1076 of 1096 used\n",
      "adding camera 123 (18 of 153), 1059 of 1088 used\n",
      "adding camera 56 (19 of 153), 973 of 993 used\n",
      "adding 14980 points, 18 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.433318 -> 0.317632\n",
      "adding 7 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.322778 -> 0.322278\n",
      "adding 0 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.314635 seconds\n",
      "adding camera 141 (20 of 153), 2453 of 2486 used\n",
      "adding camera 144 (21 of 153), 2209 of 2228 used\n",
      "adding camera 53 (22 of 153), 2045 of 2071 used\n",
      "adding camera 94 (23 of 153), 1789 of 1833 used\n",
      "adding camera 87 (24 of 153), 1701 of 1736 used\n",
      "adding camera 57 (25 of 153), 1656 of 1704 used\n",
      "adding camera 63 (26 of 153), 1559 of 1582 used\n",
      "adding camera 122 (27 of 153), 1500 of 1523 used\n",
      "adding camera 127 (28 of 153), 1250 of 1284 used\n",
      "adding camera 145 (29 of 153), 1159 of 1181 used\n",
      "adding camera 58 (30 of 153), 1053 of 1092 used\n",
      "adding camera 140 (31 of 153), 1003 of 1040 used\n",
      "adding 17072 points, 33 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.387337 -> 0.376225\n",
      "adding 17 points, 0 far ((-, -) threshold), 1 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.381934 -> 0.376926\n",
      "adding 1 points, 0 far ((-, -) threshold), 1 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.724321 seconds\n",
      "adding camera 95 (32 of 153), 1997 of 2058 used\n",
      "adding camera 86 (33 of 153), 1766 of 1845 used\n",
      "adding camera 64 (34 of 153), 1753 of 1811 used\n",
      "adding camera 52 (35 of 153), 1675 of 1726 used\n",
      "adding camera 139 (36 of 153), 1600 of 1647 used\n",
      "adding camera 121 (37 of 153), 1549 of 1635 used\n",
      "adding camera 128 (38 of 153), 1544 of 1582 used\n",
      "adding camera 146 (39 of 153), 1411 of 1440 used\n",
      "adding camera 96 (40 of 153), 1245 of 1300 used\n",
      "adding camera 105 (41 of 153), 1080 of 1138 used\n",
      "adding camera 18 (42 of 153), 1067 of 1137 used\n",
      "adding camera 51 (43 of 153), 1057 of 1088 used\n",
      "adding 14134 points, 70 far ((-, -) threshold), 1 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.419794 -> 0.333899\n",
      "adding 23 points, 3 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.338679 -> 0.306798\n",
      "adding 4 points, 2 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.308463 -> 0.307732\n",
      "adding 2 points, 2 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 1.17522 seconds\n",
      "adding camera 65 (44 of 153), 2058 of 2102 used\n",
      "adding camera 85 (45 of 153), 2040 of 2086 used\n",
      "adding camera 138 (46 of 153), 1912 of 1964 used\n",
      "adding camera 120 (47 of 153), 1715 of 1772 used\n",
      "adding camera 129 (48 of 153), 1674 of 1716 used\n",
      "adding camera 147 (49 of 153), 1653 of 1682 used\n",
      "adding camera 50 (50 of 153), 1558 of 1575 used\n",
      "adding camera 97 (51 of 153), 1230 of 1258 used\n",
      "adding camera 19 (52 of 153), 1169 of 1214 used\n",
      "adding camera 106 (53 of 153), 1084 of 1136 used\n",
      "adding camera 119 (54 of 153), 1020 of 1076 used\n",
      "adding camera 20 (55 of 153), 1017 of 1058 used\n",
      "adding 15522 points, 54 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.339534 -> 0.314294\n",
      "adding 20 points, 7 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.316341 -> 0.315915\n",
      "adding 5 points, 1 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.317979 -> 0.317492\n",
      "adding 1 points, 5 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 1.011 seconds\n",
      "adding camera 84 (56 of 153), 1771 of 1823 used\n",
      "adding camera 137 (57 of 153), 1732 of 1780 used\n",
      "adding camera 21 (58 of 153), 1671 of 1704 used\n",
      "adding camera 130 (59 of 153), 1635 of 1691 used\n",
      "adding camera 66 (60 of 153), 1620 of 1648 used\n",
      "adding camera 107 (61 of 153), 1587 of 1652 used\n",
      "adding camera 49 (62 of 153), 1374 of 1399 used\n",
      "adding camera 148 (63 of 153), 1309 of 1346 used\n",
      "adding camera 118 (64 of 153), 1268 of 1312 used\n",
      "adding camera 17 (65 of 153), 1203 of 1258 used\n",
      "adding camera 98 (66 of 153), 1116 of 1146 used\n",
      "adding camera 22 (67 of 153), 1085 of 1131 used\n",
      "adding camera 16 (68 of 153), 1048 of 1090 used\n",
      "adding camera 149 (69 of 153), 1001 of 1046 used\n",
      "adding camera 83 (70 of 153), 976 of 1023 used\n",
      "adding camera 108 (71 of 153), 962 of 1009 used\n",
      "adding camera 67 (72 of 153), 932 of 963 used\n",
      "adding 20098 points, 66 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.343114 -> 0.317319\n",
      "adding 25 points, 5 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.321478 -> 0.321165\n",
      "adding 7 points, 2 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.322466 -> 0.322048\n",
      "adding 3 points, 4 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.71559 seconds\n",
      "adding camera 15 (73 of 153), 1979 of 2046 used\n",
      "adding camera 150 (74 of 153), 1750 of 1791 used\n",
      "adding camera 23 (75 of 153), 1641 of 1688 used\n",
      "adding camera 82 (76 of 153), 1627 of 1664 used\n",
      "adding camera 48 (77 of 153), 1621 of 1647 used\n",
      "adding camera 131 (78 of 153), 1506 of 1543 used\n",
      "adding camera 117 (79 of 153), 1460 of 1500 used\n",
      "adding camera 14 (80 of 153), 1435 of 1506 used\n",
      "adding camera 136 (81 of 153), 1311 of 1343 used\n",
      "adding camera 99 (82 of 153), 1301 of 1336 used\n",
      "adding camera 109 (83 of 153), 1259 of 1296 used\n",
      "adding camera 68 (84 of 153), 1180 of 1205 used\n",
      "adding camera 24 (85 of 153), 1114 of 1165 used\n",
      "adding 16765 points, 62 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.338582 -> 0.321213\n",
      "adding 25 points, 6 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.325012 -> 0.324649\n",
      "adding 7 points, 3 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx- 0.325373 -> 0.325007\n",
      "adding 4 points, 5 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 2.08936 seconds\n",
      "adding camera 13 (86 of 153), 2638 of 2717 used\n",
      "adding camera 12 (87 of 153), 1929 of 1990 used\n",
      "adding camera 25 (88 of 153), 1851 of 1903 used\n",
      "adding camera 47 (89 of 153), 1782 of 1808 used\n",
      "adding camera 81 (90 of 153), 1718 of 1754 used\n",
      "adding camera 100 (91 of 153), 1602 of 1633 used\n",
      "adding camera 11 (92 of 153), 1471 of 1525 used\n",
      "adding camera 69 (93 of 153), 1413 of 1436 used\n",
      "adding camera 151 (94 of 153), 1372 of 1414 used\n",
      "adding camera 116 (95 of 153), 1344 of 1380 used\n",
      "adding camera 110 (96 of 153), 1275 of 1307 used\n",
      "adding camera 132 (97 of 153), 1102 of 1122 used\n",
      "adding 15340 points, 50 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.337983 -> 0.323321\n",
      "adding 24 points, 11 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.323787 -> 0.323649\n",
      "adding 11 points, 0 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.326414 -> 0.325906\n",
      "adding 1 points, 9 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 2.30061 seconds\n",
      "adding camera 46 (98 of 153), 2088 of 2128 used\n",
      "adding camera 101 (99 of 153), 1974 of 2011 used\n",
      "adding camera 80 (100 of 153), 1965 of 1994 used\n",
      "adding camera 71 (101 of 153), 1931 of 1962 used\n",
      "adding camera 26 (102 of 153), 1902 of 1968 used\n",
      "adding camera 10 (103 of 153), 1844 of 1926 used\n",
      "adding camera 111 (104 of 153), 1299 of 1340 used\n",
      "adding camera 45 (105 of 153), 1210 of 1242 used\n",
      "adding camera 70 (106 of 153), 1193 of 1214 used\n",
      "adding camera 27 (107 of 153), 1170 of 1227 used\n",
      "adding camera 152 (108 of 153), 1090 of 1138 used\n",
      "adding camera 102 (109 of 153), 1088 of 1113 used\n",
      "adding camera 115 (110 of 153), 1073 of 1091 used\n",
      "adding camera 135 (111 of 153), 1055 of 1083 used\n",
      "adding 16398 points, 58 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.338958 -> 0.324702\n",
      "adding 23 points, 7 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.325653 -> 0.32536\n",
      "adding 9 points, 2 far ((-, -) threshold), 0 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.326914 -> 0.326501\n",
      "adding 3 points, 7 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 2.72402 seconds\n",
      "adding camera 79 (112 of 153), 2199 of 2235 used\n",
      "adding camera 44 (113 of 153), 2190 of 2235 used\n",
      "adding camera 72 (114 of 153), 1846 of 1873 used\n",
      "adding camera 103 (115 of 153), 1792 of 1817 used\n",
      "adding camera 28 (116 of 153), 1629 of 1693 used\n",
      "adding camera 9 (117 of 153), 1621 of 1695 used\n",
      "adding camera 104 (118 of 153), 1527 of 1552 used\n",
      "adding camera 78 (119 of 153), 1232 of 1247 used\n",
      "adding camera 112 (120 of 153), 1198 of 1225 used\n",
      "adding camera 29 (121 of 153), 1034 of 1105 used\n",
      "adding camera 8 (122 of 153), 1021 of 1081 used\n",
      "adding 15255 points, 50 far ((-, -) threshold), 1 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.335333 -> 0.324115\n",
      "adding 21 points, 10 far ((-, -) threshold), 5 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.323695 -> 0.323559\n",
      "adding 14 points, 0 far ((-, -) threshold), 4 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.325497 -> 0.325072\n",
      "adding 5 points, 8 far ((-, -) threshold), 5 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 2.81822 seconds\n",
      "adding camera 43 (123 of 153), 2212 of 2262 used\n",
      "adding camera 73 (124 of 153), 2159 of 2194 used\n",
      "adding camera 30 (125 of 153), 1814 of 1872 used\n",
      "adding camera 77 (126 of 153), 1725 of 1759 used\n",
      "adding camera 7 (127 of 153), 1678 of 1742 used\n",
      "adding camera 6 (128 of 153), 1222 of 1280 used\n",
      "adding camera 42 (129 of 153), 1185 of 1228 used\n",
      "adding camera 74 (130 of 153), 1152 of 1178 used\n",
      "adding camera 31 (131 of 153), 1038 of 1092 used\n",
      "adding 11106 points, 37 far ((-, -) threshold), 4 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.335834 -> 0.325345\n",
      "adding 22 points, 8 far ((-, -) threshold), 5 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.325757 -> 0.325636\n",
      "adding 14 points, 1 far ((-, -) threshold), 4 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.327061 -> 0.326667\n",
      "adding 6 points, 8 far ((-, -) threshold), 5 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 2.96991 seconds\n",
      "adding camera 41 (132 of 153), 2121 of 2178 used\n",
      "adding camera 33 (133 of 153), 1976 of 2053 used\n",
      "adding camera 5 (134 of 153), 1904 of 1947 used\n",
      "adding camera 75 (135 of 153), 1707 of 1747 used\n",
      "adding camera 76 (136 of 153), 1378 of 1420 used\n",
      "adding camera 32 (137 of 153), 1221 of 1283 used\n",
      "adding camera 4 (138 of 153), 1136 of 1177 used\n",
      "adding 10741 points, 37 far ((-, -) threshold), 56 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.333767 -> 0.326657\n",
      "adding 69 points, 10 far ((-, -) threshold), 113 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.16121 seconds\n",
      "adding camera 40 (139 of 153), 2388 of 2645 used\n",
      "adding camera 34 (140 of 153), 1536 of 1588 used\n",
      "adding camera 3 (141 of 153), 1433 of 1481 used\n",
      "adding camera 39 (142 of 153), 1185 of 1355 used\n",
      "adding 4143 points, 72 far ((-, -) threshold), 102 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.336977 -> 0.32633\n",
      "adding 163 points, 9 far ((-, -) threshold), 110 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.325922 -> 0.325719\n",
      "adding 120 points, 1 far ((-, -) threshold), 112 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.327299 -> 0.326964\n",
      "adding 114 points, 9 far ((-, -) threshold), 114 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 3.16631 seconds\n",
      "adding camera 35 (143 of 153), 1553 of 1586 used\n",
      "adding camera 2 (144 of 153), 1031 of 1055 used\n",
      "adding camera 36 (145 of 153), 946 of 969 used\n",
      "adding camera 133 (146 of 153), 840 of 858 used\n",
      "adding 3879 points, 12 far ((-, -) threshold), 110 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.330084 -> 0.327636\n",
      "adding 117 points, 10 far ((-, -) threshold), 117 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.20476 seconds\n",
      "adding camera 37 (147 of 153), 1186 of 1229 used\n",
      "adding camera 38 (148 of 153), 995 of 1033 used\n",
      "adding camera 114 (149 of 153), 827 of 847 used\n",
      "adding camera 1 (150 of 153), 712 of 738 used\n",
      "adding camera 134 (151 of 153), 705 of 732 used\n",
      "adding camera 113 (152 of 153), 622 of 638 used\n",
      "adding 7468 points, 18 far ((-, -) threshold), 136 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.33175 -> 0.328332\n",
      "adding 143 points, 14 far ((-, -) threshold), 203 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.24904 seconds\n",
      "adding camera 0 (153 of 153), 600 of 649 used\n",
      "adding 818 points, 12 far ((-, -) threshold), 193 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.330107 -> 0.328845\n",
      "adding 201 points, 15 far ((-, -) threshold), 209 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.2527 seconds\n",
      "3 sigma filtering...\n",
      "adjusting: xxxxxxxxxxxxx 0.326707 -> 0.326665\n",
      "point variance: (0.345847, -) threshold: (1.03754, -)\n",
      "adding 206 points, 4433 far ((1.03754, -) threshold), 214 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxxxxxxxxxxxx 0.210355 -> 0.19627\n",
      "point variance: (0.207085, -) threshold: (0.621255, -)\n",
      "adding 294 points, 5229 far ((0.621255, -) threshold), 262 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxxxxx 0.17583 -> 0.175767\n",
      "point variance: (0.184413, -) threshold: (0.553238, -)\n",
      "adding 279 points, 2478 far ((0.553238, -) threshold), 262 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxxxx 0.170328 -> 0.170304\n",
      "point variance: (0.178024, -) threshold: (0.534072, -)\n",
      "adding 439 points, 882 far ((0.534072, -) threshold), 266 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.168948 -> 0.168922\n",
      "point variance: (0.176381, -) threshold: (0.529142, -)\n",
      "adding 479 points, 441 far ((0.529142, -) threshold), 267 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 9.10554 seconds\n",
      "f 2773.5, cx -6.57429, cy -2.32227, k1 0.0936891, k2 -0.149226, k3 0.102954\n",
      "finished sfm in 37.5843 seconds\n",
      "loaded projections in 0.011366 sec\n",
      "tracks initialized in 0.060582 sec\n",
      "adding 194901 points, 0 far ((-, -) threshold), 271 inaccurate, 1 invisible, 0 weak\n",
      "adding camera 193 (154 of 309), 1718 of 1765 used\n",
      "adding camera 190 (155 of 309), 1255 of 1283 used\n",
      "adding camera 176 (156 of 309), 1092 of 1148 used\n",
      "adding camera 177 (157 of 309), 1085 of 1139 used\n",
      "adding camera 270 (158 of 309), 1057 of 1084 used\n",
      "adding camera 175 (159 of 309), 954 of 1003 used\n",
      "adding 7032 points, 31 far ((-, -) threshold), 271 inaccurate, 1 invisible, 0 weak\n",
      "adding camera 178 (160 of 309), 1667 of 1726 used\n",
      "adding camera 173 (161 of 309), 1591 of 1667 used\n",
      "adding camera 168 (162 of 309), 1455 of 1531 used\n",
      "adding camera 167 (163 of 309), 1283 of 1356 used\n",
      "adding camera 191 (164 of 309), 1220 of 1246 used\n",
      "adding camera 192 (165 of 309), 1199 of 1255 used\n",
      "adding camera 169 (166 of 309), 1128 of 1184 used\n",
      "adding camera 166 (167 of 309), 913 of 968 used\n",
      "adding camera 271 (168 of 309), 908 of 945 used\n",
      "adding camera 174 (169 of 309), 906 of 948 used\n",
      "adding camera 237 (170 of 309), 884 of 933 used\n",
      "adding camera 179 (171 of 309), 860 of 909 used\n",
      "adding 14950 points, 56 far ((-, -) threshold), 271 inaccurate, 1 invisible, 0 weak\n",
      "loaded camera partition in 3.3e-05 sec\n",
      "processing block: 88 photos\n",
      "pair 48 and 49: 3141 robust from 3156\n",
      "pair 74 and 75: 3106 robust from 3136\n",
      "pair 85 and 86: 3401 robust from 3421\n",
      "pair 53 and 54: 2995 robust from 3027\n",
      "pair 47 and 48: 3154 robust from 3185\n",
      "pair 80 and 82: 2984 robust from 3005\n",
      "pair 49 and 51: 2981 robust from 3003\n",
      "pair 83 and 84: 3071 robust from 3093\n",
      "pair 82 and 83: 3150 robust from 3167\n",
      "pair 49 and 50: 3766 robust from 3789\n",
      "pair 50 and 51: 382 robust from 7013\n",
      "pair 86 and 87: 2347 robust from 6050\n",
      "evaluating initial pair...\n",
      "initial pair evaluated in 0.244042 sec.\n",
      "initial pair score: n_aligned: 3, n_points_tier: 1, accuracy_tier: 1, reprojection_error: 0.234079, accuracy: 0.00547105, n_points: 2864, ids: [49, 50]\n",
      "initial pair stable\n",
      "pair 49 and 50: 3766 robust\n",
      "adding 3787 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.301216 -> 0.294999\n",
      "adding 0 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.009472 seconds\n",
      "adding camera 51 (3 of 88), 2852 of 2864 used\n",
      "adding camera 48 (4 of 88), 1487 of 1501 used\n",
      "adding 5909 points, 0 far ((-, -) threshold), 2033 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.3615 -> 0.281443\n",
      "adding 2033 points, 0 far ((-, -) threshold), 2091 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.036287 seconds\n",
      "adding camera 19 (5 of 88), 1399 of 1544 used\n",
      "adding camera 47 (6 of 88), 1395 of 1424 used\n",
      "adding camera 20 (7 of 88), 1109 of 1173 used\n",
      "adding camera 53 (8 of 88), 951 of 1034 used\n",
      "adding camera 54 (9 of 88), 865 of 960 used\n",
      "adding 8999 points, 30 far ((-, -) threshold), 1728 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.545889 -> 0.352886\n",
      "adding 1749 points, 0 far ((-, -) threshold), 1732 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.37023 -> 0.367596\n",
      "adding 1732 points, 0 far ((-, -) threshold), 1747 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.107456 seconds\n",
      "adding camera 21 (10 of 88), 1867 of 1920 used\n",
      "adding camera 55 (11 of 88), 1861 of 1922 used\n",
      "adding camera 83 (12 of 88), 1703 of 1761 used\n",
      "adding camera 52 (13 of 88), 1664 of 1713 used\n",
      "adding camera 46 (14 of 88), 1525 of 1566 used\n",
      "adding camera 84 (15 of 88), 1413 of 1464 used\n",
      "adding camera 82 (16 of 88), 1281 of 1335 used\n",
      "adding camera 56 (17 of 88), 1035 of 1083 used\n",
      "adding 13124 points, 45 far ((-, -) threshold), 1584 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.454203 -> 0.368396\n",
      "adding 1599 points, 0 far ((-, -) threshold), 1591 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.37716 -> 0.374792\n",
      "adding 1590 points, 1 far ((-, -) threshold), 1531 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.373352 -> 0.369172\n",
      "adding 1531 points, 0 far ((-, -) threshold), 1489 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.369093 -> 0.354101\n",
      "adding 1490 points, 1 far ((-, -) threshold), 1427 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.353781 -> 0.331026\n",
      "adding 1428 points, 0 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.909754 seconds\n",
      "adding camera 80 (18 of 88), 2537 of 2583 used\n",
      "adding camera 85 (19 of 88), 2093 of 2139 used\n",
      "adding camera 22 (20 of 88), 1933 of 1982 used\n",
      "adding camera 57 (21 of 88), 1643 of 1687 used\n",
      "adding camera 81 (22 of 88), 1445 of 1481 used\n",
      "adding camera 45 (23 of 88), 1431 of 1476 used\n",
      "adding camera 23 (24 of 88), 1099 of 1142 used\n",
      "adding camera 86 (25 of 88), 1080 of 1123 used\n",
      "adding 14034 points, 24 far ((-, -) threshold), 1510 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.355763 -> 0.323663\n",
      "adding 1523 points, 1 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.330476 -> 0.330005\n",
      "adding 1514 points, 1 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.275315 seconds\n",
      "adding camera 87 (26 of 88), 2840 of 2865 used\n",
      "adding camera 79 (27 of 88), 2117 of 2183 used\n",
      "adding camera 58 (28 of 88), 1976 of 2049 used\n",
      "adding camera 44 (29 of 88), 1870 of 1924 used\n",
      "adding camera 24 (30 of 88), 1728 of 1755 used\n",
      "adding camera 0 (31 of 88), 1506 of 1544 used\n",
      "adding 11272 points, 31 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.344236 -> 0.325145\n",
      "adding 1525 points, 2 far ((-, -) threshold), 1515 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.328913 -> 0.327814\n",
      "adding 1517 points, 0 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.329722 -> 0.329609\n",
      "adding 1513 points, 2 far ((-, -) threshold), 1515 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.476844 seconds\n",
      "adding camera 78 (32 of 88), 1996 of 2081 used\n",
      "adding camera 43 (33 of 88), 1879 of 1914 used\n",
      "adding camera 59 (34 of 88), 1810 of 1883 used\n",
      "adding camera 25 (35 of 88), 1630 of 1673 used\n",
      "adding camera 1 (36 of 88), 1297 of 1395 used\n",
      "adding 8300 points, 27 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.351388 -> 0.327644\n",
      "adding 1524 points, 1 far ((-, -) threshold), 1515 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.3301 -> 0.329731\n",
      "adding 1516 points, 0 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.330653 -> 0.330574\n",
      "adding 1513 points, 1 far ((-, -) threshold), 1515 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.53557 seconds\n",
      "adding camera 77 (37 of 88), 2060 of 2122 used\n",
      "adding camera 42 (38 of 88), 1829 of 1885 used\n",
      "adding camera 60 (39 of 88), 1758 of 1823 used\n",
      "adding camera 26 (40 of 88), 1571 of 1617 used\n",
      "adding camera 3 (41 of 88), 1084 of 1124 used\n",
      "adding 8684 points, 24 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.347387 -> 0.331807\n",
      "adding 1524 points, 2 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.332984 -> 0.332783\n",
      "adding 1513 points, 0 far ((-, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.333591 -> 0.333521\n",
      "adding 1511 points, 1 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.587184 seconds\n",
      "adding camera 41 (42 of 88), 1938 of 1996 used\n",
      "adding camera 76 (43 of 88), 1879 of 1950 used\n",
      "adding camera 61 (44 of 88), 1847 of 1933 used\n",
      "adding camera 27 (45 of 88), 1681 of 1725 used\n",
      "adding camera 2 (46 of 88), 1191 of 1227 used\n",
      "adding camera 40 (47 of 88), 1076 of 1139 used\n",
      "adding 9664 points, 33 far ((-, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.347601 -> 0.331924\n",
      "adding 1523 points, 1 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.33329 -> 0.333069\n",
      "adding 1513 points, 0 far ((-, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.333777 -> 0.333716\n",
      "adding 1511 points, 1 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.630253 seconds\n",
      "adding camera 62 (48 of 88), 2021 of 2085 used\n",
      "adding camera 28 (49 of 88), 1989 of 2029 used\n",
      "adding camera 75 (50 of 88), 1977 of 2047 used\n",
      "adding camera 39 (51 of 88), 1365 of 1404 used\n",
      "adding camera 63 (52 of 88), 1267 of 1329 used\n",
      "adding camera 74 (53 of 88), 1202 of 1253 used\n",
      "adding 9227 points, 20 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.345827 -> 0.33352\n",
      "adding 1518 points, 2 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxx 0.333595 -> 0.333556\n",
      "adding 1514 points, 0 far ((-, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.334585 -> 0.33452\n",
      "adding 1511 points, 2 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.667862 seconds\n",
      "adding camera 73 (54 of 88), 1969 of 2038 used\n",
      "adding camera 64 (55 of 88), 1901 of 1967 used\n",
      "adding camera 29 (56 of 88), 1396 of 1434 used\n",
      "adding 5042 points, 17 far ((-, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.342836 -> 0.336385\n",
      "adding 1520 points, 2 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.336221 -> 0.336184\n",
      "adding 1514 points, 0 far ((-, -) threshold), 1510 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.337248 -> 0.337138\n",
      "adding 1510 points, 2 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.756741 seconds\n",
      "adding camera 72 (57 of 88), 1415 of 1450 used\n",
      "adding camera 65 (58 of 88), 1225 of 1253 used\n",
      "adding camera 38 (59 of 88), 1152 of 1181 used\n",
      "adding camera 4 (60 of 88), 994 of 1014 used\n",
      "adding camera 18 (61 of 88), 974 of 1011 used\n",
      "adding camera 30 (62 of 88), 942 of 949 used\n",
      "adding camera 17 (63 of 88), 875 of 914 used\n",
      "adding camera 16 (64 of 88), 749 of 783 used\n",
      "adding 10369 points, 17 far ((-, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.34656 -> 0.334313\n",
      "adding 1518 points, 2 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.334796 -> 0.334745\n",
      "adding 1514 points, 1 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.334996 -> 0.334949\n",
      "adding 1513 points, 1 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.863201 seconds\n",
      "adding camera 15 (65 of 88), 1661 of 1686 used\n",
      "adding camera 36 (66 of 88), 1165 of 1184 used\n",
      "adding camera 71 (67 of 88), 1039 of 1060 used\n",
      "adding camera 31 (68 of 88), 993 of 1004 used\n",
      "adding camera 66 (69 of 88), 950 of 962 used\n",
      "adding camera 14 (70 of 88), 933 of 953 used\n",
      "adding 7774 points, 10 far ((-, -) threshold), 1512 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.338238 -> 0.332356\n",
      "adding 1516 points, 2 far ((-, -) threshold), 1515 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.336553 seconds\n",
      "adding camera 13 (71 of 88), 1359 of 1379 used\n",
      "adding camera 37 (72 of 88), 1311 of 1337 used\n",
      "adding camera 32 (73 of 88), 1052 of 1066 used\n",
      "adding camera 12 (74 of 88), 971 of 1001 used\n",
      "adding camera 11 (75 of 88), 777 of 821 used\n",
      "adding camera 33 (76 of 88), 757 of 764 used\n",
      "adding 7949 points, 21 far ((-, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.337526 -> 0.329101\n",
      "adding 1519 points, 2 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.329571 -> 0.329453\n",
      "adding 1518 points, 1 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.329902 -> 0.329836\n",
      "adding 1515 points, 2 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.857322 seconds\n",
      "adding camera 10 (77 of 88), 1641 of 1675 used\n",
      "adding camera 35 (78 of 88), 967 of 978 used\n",
      "adding camera 8 (79 of 88), 923 of 976 used\n",
      "adding 4188 points, 19 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.335054 -> 0.330075\n",
      "adding 1525 points, 3 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.330908 -> 0.330771\n",
      "adding 1519 points, 0 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.331835 -> 0.331747\n",
      "adding 1514 points, 3 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 1.04273 seconds\n",
      "adding camera 9 (80 of 88), 1347 of 1370 used\n",
      "adding camera 7 (81 of 88), 980 of 1007 used\n",
      "adding camera 67 (82 of 88), 723 of 736 used\n",
      "adding 4299 points, 9 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.339344 -> 0.334699\n",
      "adding 1518 points, 4 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.342372 seconds\n",
      "adding camera 70 (83 of 88), 793 of 812 used\n",
      "adding camera 5 (84 of 88), 690 of 710 used\n",
      "adding 3164 points, 4 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.336926 -> 0.335367\n",
      "adding 1515 points, 5 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.352316 seconds\n",
      "adding camera 6 (85 of 88), 515 of 534 used\n",
      "adding camera 68 (86 of 88), 427 of 446 used\n",
      "adding camera 69 (87 of 88), 421 of 430 used\n",
      "adding 3434 points, 4 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.336446 -> 0.335004\n",
      "adding 1514 points, 5 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.36505 seconds\n",
      "adding camera 34 (88 of 88), 270 of 271 used\n",
      "adding 1636 points, 0 far ((-, -) threshold), 1514 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.335054 -> 0.334826\n",
      "adding 1514 points, 5 far ((-, -) threshold), 1516 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.365038 seconds\n",
      "3 sigma filtering...\n",
      "adjusting: xxxxx 0.333157 -> 0.333147\n",
      "point variance: (0.348589, -) threshold: (1.04577, -)\n",
      "adding 1514 points, 2764 far ((1.04577, -) threshold), 1513 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.216547 -> 0.214787\n",
      "point variance: (0.223907, -) threshold: (0.671722, -)\n",
      "adding 1511 points, 3090 far ((0.671722, -) threshold), 1508 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.191835 -> 0.18037\n",
      "point variance: (0.186848, -) threshold: (0.560545, -)\n",
      "adding 1915 points, 1940 far ((0.560545, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.171655 -> 0.17147\n",
      "point variance: (0.177051, -) threshold: (0.531152, -)\n",
      "adding 1580 points, 843 far ((0.531152, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.168531 -> 0.168469\n",
      "point variance: (0.173597, -) threshold: (0.520791, -)\n",
      "adding 1633 points, 375 far ((0.520791, -) threshold), 1511 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 2.45208 seconds\n",
      "f 2773.5, cx -1.60748, cy -2.45895, k1 0.0911487, k2 -0.151312, k3 0.103823\n",
      "finished sfm in 13.9173 seconds\n",
      "loaded projections in 0.004944 sec\n",
      "tracks initialized in 0.035755 sec\n",
      "adding 114067 points, 0 far ((-, -) threshold), 1516 inaccurate, 1 invisible, 0 weak\n",
      "adding camera 131 (89 of 175), 1404 of 1481 used\n",
      "adding camera 139 (90 of 175), 1116 of 1182 used\n",
      "adding camera 132 (91 of 175), 1076 of 1151 used\n",
      "adding camera 137 (92 of 175), 1054 of 1118 used\n",
      "adding camera 101 (93 of 175), 1008 of 1068 used\n",
      "adding camera 138 (94 of 175), 978 of 1044 used\n",
      "adding camera 100 (95 of 175), 973 of 1041 used\n",
      "adding camera 140 (96 of 175), 963 of 1043 used\n",
      "adding camera 142 (97 of 175), 945 of 1020 used\n",
      "adding camera 136 (98 of 175), 934 of 986 used\n",
      "adding camera 103 (99 of 175), 911 of 980 used\n",
      "adding camera 143 (100 of 175), 837 of 888 used\n",
      "adding camera 102 (101 of 175), 817 of 871 used\n",
      "adding camera 99 (102 of 175), 812 of 868 used\n",
      "adding camera 133 (103 of 175), 809 of 868 used\n",
      "adding camera 141 (104 of 175), 781 of 851 used\n",
      "adding 24034 points, 89 far ((-, -) threshold), 1516 inaccurate, 1 invisible, 0 weak\n",
      "adding camera 104 (105 of 175), 2850 of 2950 used\n",
      "adding camera 162 (106 of 175), 2626 of 2733 used\n",
      "adding camera 163 (107 of 175), 2353 of 2474 used\n",
      "adding camera 161 (108 of 175), 2310 of 2420 used\n",
      "adding camera 134 (109 of 175), 2286 of 2389 used\n",
      "adding camera 135 (110 of 175), 2196 of 2269 used\n",
      "adding camera 160 (111 of 175), 2099 of 2195 used\n",
      "adding camera 167 (112 of 175), 1721 of 1837 used\n",
      "adding camera 159 (113 of 175), 1704 of 1819 used\n",
      "adding camera 164 (114 of 175), 1691 of 1787 used\n",
      "adding camera 166 (115 of 175), 1644 of 1748 used\n",
      "adding camera 168 (116 of 175), 1643 of 1752 used\n",
      "adding camera 109 (117 of 175), 1637 of 1752 used\n",
      "adding camera 157 (118 of 175), 1600 of 1702 used\n",
      "adding camera 110 (119 of 175), 1562 of 1650 used\n",
      "adding camera 108 (120 of 175), 1529 of 1642 used\n",
      "adding camera 98 (121 of 175), 1524 of 1609 used\n",
      "adding camera 144 (122 of 175), 1516 of 1559 used\n",
      "adding camera 158 (123 of 175), 1515 of 1607 used\n",
      "adding camera 165 (124 of 175), 1498 of 1588 used\n",
      "adding camera 107 (125 of 175), 1354 of 1474 used\n",
      "adding camera 112 (126 of 175), 1293 of 1362 used\n",
      "adding camera 156 (127 of 175), 1146 of 1210 used\n",
      "adding 35250 points, 144 far ((-, -) threshold), 1565 inaccurate, 1 invisible, 0 weak\n",
      "loaded camera partition in 3.5e-05 sec\n",
      "processing block: 114 photos\n",
      "pair 49 and 50: 2753 robust from 2772\n",
      "pair 45 and 46: 2772 robust from 2804\n",
      "pair 50 and 51: 2693 robust from 2717\n",
      "pair 7 and 8: 2849 robust from 2874\n",
      "pair 8 and 9: 2773 robust from 2798\n",
      "pair 44 and 45: 2867 robust from 2898\n",
      "pair 67 and 68: 2898 robust from 2918\n",
      "pair 33 and 34: 3222 robust from 3248\n",
      "pair 11 and 12: 1436 robust from 4252\n",
      "pair 34 and 35: 0 robust from 5547\n",
      "pair 32 and 33: 2987 robust from 3018\n",
      "pair 66 and 67: 2943 robust from 2961\n",
      "evaluating initial pair...\n",
      "initial pair evaluated in 0.278339 sec.\n",
      "initial pair score: n_aligned: 3, n_points_tier: 1, accuracy_tier: 1, reprojection_error: 0.298265, accuracy: 0.00421863, n_points: 2281, ids: [33, 34]\n",
      "initial pair stable\n",
      "pair 33 and 34: 3222 robust\n",
      "adding 3245 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxx 0.394462 -> 0.389816\n",
      "adding 0 points, 0 far ((-, -) threshold), 0 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.006284 seconds\n",
      "adding camera 35 (3 of 114), 2271 of 2282 used\n",
      "adding camera 32 (4 of 114), 1361 of 1392 used\n",
      "adding camera 46 (5 of 114), 1332 of 1382 used\n",
      "adding camera 45 (6 of 114), 1310 of 1356 used\n",
      "adding 7588 points, 6 far ((-, -) threshold), 762 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxx 0.442735 -> 0.357286\n",
      "adding 763 points, 0 far ((-, -) threshold), 856 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.04236 seconds\n",
      "adding camera 44 (7 of 114), 2477 of 2557 used\n",
      "adding camera 31 (8 of 114), 1467 of 1529 used\n",
      "adding camera 43 (9 of 114), 1026 of 1090 used\n",
      "adding 4917 points, 10 far ((-, -) threshold), 854 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.424777 -> 0.359813\n",
      "adding 860 points, 0 far ((-, -) threshold), 860 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.049225 seconds\n",
      "adding camera 42 (10 of 114), 1605 of 1654 used\n",
      "adding camera 30 (11 of 114), 1554 of 1591 used\n",
      "adding camera 49 (12 of 114), 1077 of 1149 used\n",
      "adding camera 14 (13 of 114), 979 of 1088 used\n",
      "adding camera 15 (14 of 114), 884 of 968 used\n",
      "adding 5226 points, 38 far ((-, -) threshold), 770 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxx 0.443163 -> 0.369996\n",
      "adding 791 points, 0 far ((-, -) threshold), 792 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.057779 seconds\n",
      "adding camera 28 (15 of 114), 1466 of 1504 used\n",
      "adding camera 41 (16 of 114), 1402 of 1441 used\n",
      "adding camera 16 (17 of 114), 1140 of 1183 used\n",
      "adding camera 51 (18 of 114), 1046 of 1106 used\n",
      "adding camera 13 (19 of 114), 1012 of 1070 used\n",
      "adding camera 50 (20 of 114), 999 of 1040 used\n",
      "adding camera 48 (21 of 114), 887 of 930 used\n",
      "adding 9872 points, 29 far ((-, -) threshold), 776 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.434472 -> 0.422245\n",
      "adding 787 points, 1 far ((-, -) threshold), 597 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.424814 -> 0.3418\n",
      "adding 599 points, 0 far ((-, -) threshold), 423 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.344025 -> 0.343959\n",
      "adding 423 points, 0 far ((-, -) threshold), 420 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxx 0.343847 -> 0.343846\n",
      "adding 420 points, 0 far ((-, -) threshold), 423 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.658007 seconds\n",
      "adding camera 67 (22 of 114), 1750 of 1862 used\n",
      "adding camera 68 (23 of 114), 1567 of 1658 used\n",
      "adding camera 52 (24 of 114), 1516 of 1568 used\n",
      "adding camera 66 (25 of 114), 1397 of 1477 used\n",
      "adding camera 39 (26 of 114), 1289 of 1336 used\n",
      "adding camera 47 (27 of 114), 1285 of 1330 used\n",
      "adding camera 29 (28 of 114), 1214 of 1261 used\n",
      "adding camera 17 (29 of 114), 1111 of 1156 used\n",
      "adding camera 69 (30 of 114), 1102 of 1159 used\n",
      "adding camera 64 (31 of 114), 1002 of 1054 used\n",
      "adding camera 53 (32 of 114), 923 of 969 used\n",
      "adding 13302 points, 43 far ((-, -) threshold), 421 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.399176 -> 0.348833\n",
      "adding 437 points, 0 far ((-, -) threshold), 392 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.355087 -> 0.354831\n",
      "adding 392 points, 1 far ((-, -) threshold), 396 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.519689 seconds\n",
      "adding camera 65 (33 of 114), 1736 of 1795 used\n",
      "adding camera 70 (34 of 114), 1588 of 1635 used\n",
      "adding camera 40 (35 of 114), 1290 of 1332 used\n",
      "adding camera 54 (36 of 114), 1222 of 1274 used\n",
      "adding camera 18 (37 of 114), 1162 of 1205 used\n",
      "adding camera 27 (38 of 114), 1132 of 1160 used\n",
      "adding camera 63 (39 of 114), 895 of 959 used\n",
      "adding camera 77 (40 of 114), 894 of 964 used\n",
      "adding 9119 points, 27 far ((-, -) threshold), 391 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.378264 -> 0.354843\n",
      "adding 408 points, 0 far ((-, -) threshold), 397 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.360333 -> 0.35978\n",
      "adding 397 points, 0 far ((-, -) threshold), 398 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.601485 seconds\n",
      "adding camera 38 (41 of 114), 1633 of 1698 used\n",
      "adding camera 26 (42 of 114), 1508 of 1559 used\n",
      "adding camera 71 (43 of 114), 1346 of 1380 used\n",
      "adding camera 55 (44 of 114), 1230 of 1286 used\n",
      "adding camera 62 (45 of 114), 1127 of 1172 used\n",
      "adding camera 76 (46 of 114), 1067 of 1095 used\n",
      "adding camera 19 (47 of 114), 1060 of 1099 used\n",
      "adding camera 75 (48 of 114), 978 of 1014 used\n",
      "adding camera 78 (49 of 114), 934 of 966 used\n",
      "adding 10237 points, 38 far ((-, -) threshold), 398 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.376527 -> 0.355179\n",
      "adding 412 points, 1 far ((-, -) threshold), 396 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxx 0.358169 -> 0.357991\n",
      "adding 397 points, 0 far ((-, -) threshold), 398 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.572429 seconds\n",
      "adding camera 37 (50 of 114), 1612 of 1663 used\n",
      "adding camera 25 (51 of 114), 1511 of 1559 used\n",
      "adding camera 56 (52 of 114), 1428 of 1495 used\n",
      "adding camera 74 (53 of 114), 1402 of 1428 used\n",
      "adding camera 79 (54 of 114), 1339 of 1379 used\n",
      "adding camera 61 (55 of 114), 1050 of 1077 used\n",
      "adding camera 73 (56 of 114), 986 of 1013 used\n",
      "adding camera 80 (57 of 114), 909 of 942 used\n",
      "adding camera 36 (58 of 114), 862 of 900 used\n",
      "adding 9705 points, 25 far ((-, -) threshold), 397 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.37399 -> 0.356002\n",
      "adding 408 points, 0 far ((-, -) threshold), 400 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.359064 -> 0.358923\n",
      "adding 400 points, 0 far ((-, -) threshold), 402 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.86286 seconds\n",
      "adding camera 24 (59 of 114), 1632 of 1671 used\n",
      "adding camera 57 (60 of 114), 1474 of 1522 used\n",
      "adding camera 81 (61 of 114), 1138 of 1171 used\n",
      "adding camera 60 (62 of 114), 1125 of 1160 used\n",
      "adding camera 72 (63 of 114), 1074 of 1087 used\n",
      "adding camera 58 (64 of 114), 913 of 970 used\n",
      "adding 5726 points, 22 far ((-, -) threshold), 401 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.368522 -> 0.358624\n",
      "adding 412 points, 0 far ((-, -) threshold), 402 inaccurate, 0 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.360411 -> 0.360382\n",
      "adding 402 points, 0 far ((-, -) threshold), 404 inaccurate, 0 invisible, 0 weak\n",
      "optimized in 0.921687 seconds\n",
      "adding camera 82 (65 of 114), 1067 of 1091 used\n",
      "adding camera 59 (66 of 114), 982 of 1011 used\n",
      "adding camera 7 (67 of 114), 830 of 883 used\n",
      "adding camera 20 (68 of 114), 778 of 800 used\n",
      "adding camera 8 (69 of 114), 749 of 784 used\n",
      "adding camera 21 (70 of 114), 679 of 718 used\n",
      "adding camera 9 (71 of 114), 652 of 695 used\n",
      "adding camera 22 (72 of 114), 639 of 671 used\n",
      "adding camera 6 (73 of 114), 630 of 676 used\n",
      "adding camera 83 (74 of 114), 580 of 605 used\n",
      "adding camera 23 (75 of 114), 560 of 591 used\n",
      "adding 11388 points, 40 far ((-, -) threshold), 402 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.377296 -> 0.361405\n",
      "adding 415 points, 2 far ((-, -) threshold), 405 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.362642 -> 0.362497\n",
      "adding 408 points, 0 far ((-, -) threshold), 410 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.07081 seconds\n",
      "adding camera 10 (76 of 114), 1432 of 1454 used\n",
      "adding camera 5 (77 of 114), 1060 of 1090 used\n",
      "adding camera 84 (78 of 114), 888 of 910 used\n",
      "adding 3771 points, 12 far ((-, -) threshold), 405 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.364582 -> 0.36079\n",
      "adding 410 points, 2 far ((-, -) threshold), 411 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.549626 seconds\n",
      "adding camera 4 (79 of 114), 1098 of 1124 used\n",
      "adding camera 85 (80 of 114), 972 of 988 used\n",
      "adding camera 11 (81 of 114), 953 of 971 used\n",
      "adding camera 12 (82 of 114), 703 of 720 used\n",
      "adding 6828 points, 11 far ((-, -) threshold), 405 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.360905 -> 0.357206\n",
      "adding 410 points, 1 far ((-, -) threshold), 408 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.570871 seconds\n",
      "adding camera 86 (83 of 114), 834 of 858 used\n",
      "adding camera 3 (84 of 114), 815 of 837 used\n",
      "adding 2673 points, 5 far ((-, -) threshold), 404 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.358979 -> 0.357134\n",
      "adding 407 points, 1 far ((-, -) threshold), 411 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.572195 seconds\n",
      "adding camera 87 (85 of 114), 786 of 820 used\n",
      "adding camera 2 (86 of 114), 769 of 785 used\n",
      "adding camera 1 (87 of 114), 468 of 482 used\n",
      "adding 3298 points, 4 far ((-, -) threshold), 405 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.359155 -> 0.356531\n",
      "adding 406 points, 2 far ((-, -) threshold), 412 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.600027 seconds\n",
      "adding camera 0 (88 of 114), 676 of 690 used\n",
      "adding camera 88 (89 of 114), 549 of 567 used\n",
      "adding camera 105 (90 of 114), 396 of 422 used\n",
      "adding camera 99 (91 of 114), 378 of 399 used\n",
      "adding camera 98 (92 of 114), 369 of 387 used\n",
      "adding 4416 points, 13 far ((-, -) threshold), 406 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.358829 -> 0.355717\n",
      "adding 412 points, 2 far ((-, -) threshold), 408 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.356211 -> 0.356065\n",
      "adding 411 points, 1 far ((-, -) threshold), 409 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.24062 seconds\n",
      "adding camera 97 (93 of 114), 1236 of 1275 used\n",
      "adding camera 100 (94 of 114), 928 of 956 used\n",
      "adding camera 96 (95 of 114), 707 of 733 used\n",
      "adding camera 89 (96 of 114), 673 of 687 used\n",
      "adding 4952 points, 5 far ((-, -) threshold), 408 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.359021 -> 0.355185\n",
      "adding 411 points, 4 far ((-, -) threshold), 403 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxx 0.354105 -> 0.354068\n",
      "adding 408 points, 0 far ((-, -) threshold), 411 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 1.1761 seconds\n",
      "adding camera 95 (97 of 114), 1273 of 1312 used\n",
      "adding camera 101 (98 of 114), 721 of 741 used\n",
      "adding 2384 points, 3 far ((-, -) threshold), 405 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.356602 -> 0.354637\n",
      "adding 407 points, 4 far ((-, -) threshold), 408 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.636781 seconds\n",
      "adding camera 94 (99 of 114), 1005 of 1031 used\n",
      "adding camera 102 (100 of 114), 767 of 792 used\n",
      "adding camera 90 (101 of 114), 616 of 646 used\n",
      "adding 3085 points, 6 far ((-, -) threshold), 404 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.35628 -> 0.354064\n",
      "adding 408 points, 4 far ((-, -) threshold), 405 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.656185 seconds\n",
      "adding camera 103 (102 of 114), 691 of 714 used\n",
      "adding camera 93 (103 of 114), 587 of 603 used\n",
      "adding camera 104 (104 of 114), 580 of 602 used\n",
      "adding camera 91 (105 of 114), 540 of 564 used\n",
      "adding camera 106 (106 of 114), 465 of 488 used\n",
      "adding 5333 points, 11 far ((-, -) threshold), 402 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.35731 -> 0.354516\n",
      "adding 406 points, 3 far ((-, -) threshold), 406 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.688771 seconds\n",
      "adding camera 107 (107 of 114), 652 of 690 used\n",
      "adding camera 109 (108 of 114), 369 of 405 used\n",
      "adding 1906 points, 9 far ((-, -) threshold), 402 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxxx 0.356187 -> 0.35468\n",
      "adding 406 points, 3 far ((-, -) threshold), 407 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.688445 seconds\n",
      "adding camera 108 (109 of 114), 503 of 527 used\n",
      "adding 1066 points, 2 far ((-, -) threshold), 402 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxxxxx 0.355611 -> 0.354888\n",
      "adding 404 points, 3 far ((-, -) threshold), 406 inaccurate, 1 invisible, 0 weak\n",
      "optimized in 0.639621 seconds\n",
      "adding camera 110 (110 of 114), 412 of 432 used\n",
      "adding camera 111 (111 of 114), 301 of 327 used\n",
      "adding 2133 points, 9 far ((-, -) threshold), 402 inaccurate, 1 invisible, 0 weak\n",
      "adjusting: xxxxxx"
     ]
    }
   ],
   "source": [
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if 'process_orthomosaic' not in locals() or 'PhotoMatchQuality' not in locals() or 'DepthMapQuality' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        process_orthomosaic,\n",
    "        PhotoMatchQuality,\n",
    "        DepthMapQuality\n",
    "    )\n",
    "\n",
    "if 'photos_dir' not in locals():\n",
    "    photos_dir = Path(\"input/images\")\n",
    "\n",
    "# Setup paths for processing\n",
    "intermediate_dir = output_dir / \"intermediate\"\n",
    "ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "\n",
    "# Process orthomosaic WITHOUT GCPs\n",
    "# Note: clean_intermediate_files=False will reuse existing processing steps\n",
    "# Set to True to start fresh and delete previous work\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing orthomosaic WITHOUT GCPs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_path_no_gcps = intermediate_dir / \"orthomosaic_no_gcps.psx\"\n",
    "\n",
    "stats_no_gcps = process_orthomosaic(\n",
    "    photos_dir=photos_dir,\n",
    "    output_path=ortho_output_dir,\n",
    "    project_path=project_path_no_gcps,\n",
    "    product_id=\"orthomosaic_no_gcps\",\n",
    "    clean_intermediate_files=False,  # Reuse existing processing if available\n",
    "    photo_match_quality=PhotoMatchQuality.MediumQuality,\n",
    "    depth_map_quality=DepthMapQuality.MediumQuality,\n",
    "    tiepoint_limit=10000,\n",
    "    use_gcps=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Orthomosaic processing (without GCPs) complete!\")\n",
    "print(f\"  Number of photos: {stats_no_gcps['num_photos']}\")\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "ortho_path_no_gcps = Path(stats_no_gcps['ortho_path'])\n",
    "if ortho_path_no_gcps.exists():\n",
    "    file_size_mb = ortho_path_no_gcps.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  ‚úì Orthomosaic GeoTIFF: {ortho_path_no_gcps.absolute()}\")\n",
    "    print(f\"    Size: {file_size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"  ‚úó Orthomosaic GeoTIFF NOT FOUND at: {ortho_path_no_gcps.absolute()}\")\n",
    "    print(f\"    Expected location: {ortho_path_no_gcps}\")\n",
    "    print(f\"    Output directory exists: {ortho_path_no_gcps.parent.exists()}\")\n",
    "if 'log_file_path' in stats_no_gcps:\n",
    "    print(f\"  üìù Log file: {stats_no_gcps['log_file_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Process Orthomosaic WITH GCPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process orthomosaic WITH GCPs\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if 'process_orthomosaic' not in locals() or 'PhotoMatchQuality' not in locals() or 'DepthMapQuality' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        process_orthomosaic,\n",
    "        PhotoMatchQuality,\n",
    "        DepthMapQuality\n",
    "    )\n",
    "\n",
    "if 'photos_dir' not in locals():\n",
    "    photos_dir = Path(\"input/images\")\n",
    "\n",
    "# Setup paths for processing\n",
    "intermediate_dir = output_dir / \"intermediate\"\n",
    "ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "\n",
    "# Note: clean_intermediate_files=False will reuse existing processing steps\n",
    "# Set to True to start fresh and delete previous work\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing orthomosaic WITH GCPs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_path_with_gcps = intermediate_dir / \"orthomosaic_with_gcps.psx\"\n",
    "\n",
    "# Use XML file (MetaShape's native format) - defined in Step 4\n",
    "gcp_file_for_processing = output_dir / \"gcps_metashape.xml\"\n",
    "\n",
    "stats_with_gcps = process_orthomosaic(\n",
    "    photos_dir=photos_dir,\n",
    "    output_path=ortho_output_dir,\n",
    "    project_path=project_path_with_gcps,\n",
    "    gcp_file=gcp_file_for_processing,  # Use XML file (MetaShape's native format)\n",
    "    product_id=\"orthomosaic_with_gcps\",\n",
    "    clean_intermediate_files=False,  # Reuse existing processing if available\n",
    "    photo_match_quality=PhotoMatchQuality.MediumQuality,\n",
    "    depth_map_quality=DepthMapQuality.MediumQuality,\n",
    "    tiepoint_limit=10000,\n",
    "    use_gcps=True,\n",
    "    gcp_accuracy=0.05,  # High accuracy (5cm) for high weight in bundle adjustment\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Orthomosaic processing (with GCPs) complete!\")\n",
    "print(f\"  Number of photos: {stats_with_gcps['num_photos']}\")\n",
    "print(f\"  Number of markers: {stats_with_gcps.get('num_markers', 0)}\")\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "ortho_path_with_gcps = Path(stats_with_gcps['ortho_path'])\n",
    "if ortho_path_with_gcps.exists():\n",
    "    file_size_mb = ortho_path_with_gcps.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  ‚úì Orthomosaic GeoTIFF: {ortho_path_with_gcps.absolute()}\")\n",
    "    print(f\"    Size: {file_size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"  ‚úó Orthomosaic GeoTIFF NOT FOUND at: {ortho_path_with_gcps.absolute()}\")\n",
    "    print(f\"    Expected location: {ortho_path_with_gcps}\")\n",
    "    print(f\"    Output directory exists: {ortho_path_with_gcps.parent.exists()}\")\n",
    "if 'log_file_path' in stats_with_gcps:\n",
    "    print(f\"  üìù Log file: {stats_with_gcps['log_file_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Orthomosaics to Reference Basemaps\n",
    "\n",
    "### Comparison Methodology\n",
    "\n",
    "The orthomosaics are compared to reference basemaps (ESRI World Imagery and OpenStreetMap) using a comprehensive methodology:\n",
    "\n",
    "#### 1. **Reprojection and Alignment**\n",
    "   - The orthomosaic is reprojected to match the reference basemap's coordinate reference system (CRS) and spatial extent\n",
    "   - Bilinear resampling is used to ensure pixel-level alignment\n",
    "   - Both rasters are normalized to the same spatial resolution\n",
    "\n",
    "#### 2. **Pixel-level Error Metrics**\n",
    "   - **RMSE (Root Mean Square Error)**: Measures overall pixel intensity differences between orthomosaic and reference\n",
    "   - **MAE (Mean Absolute Error)**: Measures average absolute pixel differences\n",
    "   - **Structural Similarity**: Correlation-based measure indicating how well the orthomosaic structure matches the reference\n",
    "\n",
    "#### 3. **2D Spatial Error (Feature Matching)**\n",
    "   - Feature-based matching (SIFT, ORB, or phase correlation) identifies corresponding points between orthomosaic and reference\n",
    "   - Computes X and Y pixel offsets, providing 2D spatial error measurements\n",
    "   - This identifies systematic shifts, rotations, or misalignments that pixel-level metrics might miss\n",
    "   - The method automatically selects the best available algorithm (SIFT > ORB > phase correlation > template matching)\n",
    "\n",
    "#### 4. **Seamline Detection**\n",
    "   - Gradient-based analysis detects potential seamline artifacts\n",
    "   - Identifies high-gradient regions that may indicate stitching errors or discontinuities\n",
    "   - Reports percentage of pixels flagged as potential seamlines\n",
    "\n",
    "#### 5. **Comparison Process**\n",
    "   - Both orthomosaics (with and without GCPs) are compared against the same reference basemap\n",
    "   - Metrics are computed for each band and averaged for overall statistics\n",
    "   - Results are saved to JSON files for persistence and later analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Orthomosaics to Reference Basemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against ESRI basemap\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import compare_orthomosaic_to_basemap\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing orthomosaics to ESRI World Imagery basemap...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_dir = output_dir / \"comparisons\"\n",
    "\n",
    "# Ensure basemap paths are defined (from Step 2)\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Determine orthomosaic paths - use stats if available, otherwise find files directly\n",
    "if 'stats_no_gcps' in locals() and 'ortho_path' in stats_no_gcps:\n",
    "    ortho_no_gcps_path = Path(stats_no_gcps['ortho_path'])\n",
    "else:\n",
    "    # Try to find the orthomosaic file directly\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "    if not ortho_no_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found at: {ortho_no_gcps_path.absolute()}\\n\"\n",
    "                               f\"Please run Step 5 first, or ensure the file exists at this location.\")\n",
    "\n",
    "if 'stats_with_gcps' in locals() and 'ortho_path' in stats_with_gcps:\n",
    "    ortho_with_gcps_path = Path(stats_with_gcps['ortho_path'])\n",
    "else:\n",
    "    # Try to find the orthomosaic file directly\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "    if not ortho_with_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found at: {ortho_with_gcps_path.absolute()}\\n\"\n",
    "                               f\"Please run Step 6 first, or ensure the file exists at this location.\")\n",
    "\n",
    "print(f\"Using orthomosaic (no GCPs): {ortho_no_gcps_path}\")\n",
    "print(f\"Using orthomosaic (with GCPs): {ortho_with_gcps_path}\")\n",
    "\n",
    "# Compare without GCPs\n",
    "print(\"\\nComparing orthomosaic (without GCPs) to ESRI basemap...\")\n",
    "metrics_no_gcps_esri = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_no_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare with GCPs\n",
    "print(\"\\nComparing orthomosaic (with GCPs) to ESRI basemap...\")\n",
    "metrics_with_gcps_esri = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_with_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì ESRI comparison complete!\")\n",
    "\n",
    "# Save metrics to JSON files for later use\n",
    "import json\n",
    "from qualicum_beach_gcp_analysis.report_generator import convert_to_json_serializable\n",
    "\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save ESRI metrics\n",
    "metrics_no_gcps_esri_serializable = convert_to_json_serializable(metrics_no_gcps_esri)\n",
    "metrics_with_gcps_esri_serializable = convert_to_json_serializable(metrics_with_gcps_esri)\n",
    "\n",
    "with open(metrics_dir / \"metrics_no_gcps_esri.json\", 'w') as f:\n",
    "    json.dump(metrics_no_gcps_esri_serializable, f, indent=2)\n",
    "with open(metrics_dir / \"metrics_with_gcps_esri.json\", 'w') as f:\n",
    "    json.dump(metrics_with_gcps_esri_serializable, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Metrics saved to: {metrics_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.5: Apply 2D Shift Alignment and Re-analyze\n",
    "\n",
    "After the initial comparison, we apply 2D shifts to align the orthomosaics with the ESRI basemap using feature matching, then re-analyze accuracy and seamlines to see if alignment improves the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.5: Apply 2D Shift Alignment and Re-analyze\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'apply_2d_shift_to_orthomosaic' not in locals() or 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        apply_2d_shift_to_orthomosaic,\n",
    "        compare_orthomosaic_to_basemap\n",
    "    )\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Ensure orthomosaic paths are defined\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 7.5: Apply 2D Shift Alignment and Re-analyze\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create directory for shifted orthomosaics\n",
    "shifted_dir = output_dir / \"orthomosaics_shifted\"\n",
    "shifted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Apply 2D shift to orthomosaic without GCPs\n",
    "print(\"\\n1. Applying 2D shift to orthomosaic (without GCPs)...\")\n",
    "shifted_no_gcps_path = shifted_dir / \"orthomosaic_no_gcps_shifted.tif\"\n",
    "_, shift_info_no_gcps = apply_2d_shift_to_orthomosaic(\n",
    "    ortho_path=Path(ortho_no_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    output_path=shifted_no_gcps_path\n",
    ")\n",
    "print(f\"   Shift applied: X={shift_info_no_gcps['shift_x_pixels']:.2f} px, Y={shift_info_no_gcps['shift_y_pixels']:.2f} px\")\n",
    "\n",
    "# Apply 2D shift to orthomosaic with GCPs\n",
    "print(\"\\n2. Applying 2D shift to orthomosaic (with GCPs)...\")\n",
    "shifted_with_gcps_path = shifted_dir / \"orthomosaic_with_gcps_shifted.tif\"\n",
    "_, shift_info_with_gcps = apply_2d_shift_to_orthomosaic(\n",
    "    ortho_path=Path(ortho_with_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    output_path=shifted_with_gcps_path\n",
    ")\n",
    "print(f\"   Shift applied: X={shift_info_with_gcps['shift_x_pixels']:.2f} px, Y={shift_info_with_gcps['shift_y_pixels']:.2f} px\")\n",
    "\n",
    "# Re-analyze shifted orthomosaics\n",
    "print(\"\\n3. Re-analyzing shifted orthomosaics against ESRI basemap...\")\n",
    "\n",
    "# Compare shifted orthomosaic (without GCPs)\n",
    "print(\"\\n   Analyzing shifted orthomosaic (without GCPs)...\")\n",
    "metrics_shifted_no_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=shifted_no_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare shifted orthomosaic (with GCPs)\n",
    "print(\"\\n   Analyzing shifted orthomosaic (with GCPs)...\")\n",
    "metrics_shifted_with_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=shifted_with_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Save shifted metrics\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shifted_metrics_file_no_gcps = metrics_dir / \"metrics_shifted_no_gcps_esri.json\"\n",
    "shifted_metrics_file_with_gcps = metrics_dir / \"metrics_shifted_with_gcps_esri.json\"\n",
    "\n",
    "with open(shifted_metrics_file_no_gcps, 'w') as f:\n",
    "    json.dump(metrics_shifted_no_gcps, f, indent=2, default=str)\n",
    "with open(shifted_metrics_file_with_gcps, 'w') as f:\n",
    "    json.dump(metrics_shifted_with_gcps, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úì Shifted metrics saved to: {metrics_dir}\")\n",
    "\n",
    "# Compare initial vs shifted results\n",
    "print(\"\\n4. Comparing initial vs. shifted results...\")\n",
    "\n",
    "# Load initial metrics if not available\n",
    "if 'metrics_no_gcps_esri' not in locals() or 'metrics_with_gcps_esri' not in locals():\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_esri.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_esri.json\"\n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_esri = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_esri = json.load(f)\n",
    "    else:\n",
    "        raise NameError(\"Initial metrics not found. Please run Step 7 first.\")\n",
    "\n",
    "# Calculate improvements from shifting\n",
    "initial_no_gcps = metrics_no_gcps_esri.get('overall', {})\n",
    "shifted_no_gcps = metrics_shifted_no_gcps.get('overall', {})\n",
    "initial_with_gcps = metrics_with_gcps_esri.get('overall', {})\n",
    "shifted_with_gcps = metrics_shifted_with_gcps.get('overall', {})\n",
    "\n",
    "print(\"\\n   Without GCPs:\")\n",
    "if initial_no_gcps.get('rmse') and shifted_no_gcps.get('rmse'):\n",
    "    rmse_improvement = ((initial_no_gcps['rmse'] - shifted_no_gcps['rmse']) / initial_no_gcps['rmse']) * 100\n",
    "    print(f\"     RMSE: {initial_no_gcps['rmse']:.4f} ‚Üí {shifted_no_gcps['rmse']:.4f} ({rmse_improvement:+.2f}%)\")\n",
    "if initial_no_gcps.get('seamline_percentage') and shifted_no_gcps.get('seamline_percentage'):\n",
    "    seamline_improvement = initial_no_gcps['seamline_percentage'] - shifted_no_gcps['seamline_percentage']\n",
    "    print(f\"     Seamlines: {initial_no_gcps['seamline_percentage']:.2f}% ‚Üí {shifted_no_gcps['seamline_percentage']:.2f}% ({seamline_improvement:+.2f}%)\")\n",
    "\n",
    "print(\"\\n   With GCPs:\")\n",
    "if initial_with_gcps.get('rmse') and shifted_with_gcps.get('rmse'):\n",
    "    rmse_improvement = ((initial_with_gcps['rmse'] - shifted_with_gcps['rmse']) / initial_with_gcps['rmse']) * 100\n",
    "    print(f\"     RMSE: {initial_with_gcps['rmse']:.4f} ‚Üí {shifted_with_gcps['rmse']:.4f} ({rmse_improvement:+.2f}%)\")\n",
    "if initial_with_gcps.get('seamline_percentage') and shifted_with_gcps.get('seamline_percentage'):\n",
    "    seamline_improvement = initial_with_gcps['seamline_percentage'] - shifted_with_gcps['seamline_percentage']\n",
    "    print(f\"     Seamlines: {initial_with_gcps['seamline_percentage']:.2f}% ‚Üí {shifted_with_gcps['seamline_percentage']:.2f}% ({seamline_improvement:+.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úì Step 7.5 complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.6: Align Orthomosaics to Ground Control Points and Re-analyze\n",
    "\n",
    "In addition to feature-matching alignment, we also align the orthomosaics directly to the ground control points (GCPs) using their known coordinates. This provides an alternative alignment method that can be compared against feature-matching alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.6: Align Orthomosaics to Ground Control Points and Re-analyze\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'align_orthomosaic_to_gcps' not in locals() or 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        align_orthomosaic_to_gcps,\n",
    "        compare_orthomosaic_to_basemap\n",
    "    )\n",
    "\n",
    "if 'load_gcps_from_kmz' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import load_gcps_from_kmz\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Ensure orthomosaic paths are defined\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Load GCPs if not already loaded\n",
    "if 'gcps' not in locals():\n",
    "    # Try to find KMZ file\n",
    "    kmz_path = Path(\"input\") / \"QualicumBeach_AOI.kmz\"\n",
    "    if not kmz_path.exists():\n",
    "        # Try alternative location\n",
    "        kmz_path = Path(\"/Users/mauriciohessflores/Documents/Code/Data/Qualicum Beach GCPs/Spexi_Survey_Points/Spexi_Drone_Survey/QualicumBeach_AOI.kmz\")\n",
    "    \n",
    "    if kmz_path.exists():\n",
    "        gcps = load_gcps_from_kmz(str(kmz_path))\n",
    "        print(f\"Loaded {len(gcps)} GCPs from {kmz_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Could not find GCP KMZ file. Tried: {kmz_path}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 7.6: Align Orthomosaics to Ground Control Points\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create directory for GCP-aligned orthomosaics\n",
    "gcp_aligned_dir = output_dir / \"orthomosaics_gcp_aligned\"\n",
    "gcp_aligned_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Align orthomosaic without GCPs to GCPs\n",
    "print(\"\\n1. Aligning orthomosaic (without GCPs) to GCPs...\")\n",
    "gcp_aligned_no_gcps_path = gcp_aligned_dir / \"orthomosaic_no_gcps_gcp_aligned.tif\"\n",
    "_, alignment_info_no_gcps = align_orthomosaic_to_gcps(\n",
    "    ortho_path=Path(ortho_no_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    gcps=gcps,\n",
    "    output_path=gcp_aligned_no_gcps_path\n",
    ")\n",
    "print(f\"   Alignment RMSE: {alignment_info_no_gcps['rmse_total_pixels']:.2f} pixels\")\n",
    "print(f\"   Used {alignment_info_no_gcps['num_gcps_used']} GCPs\")\n",
    "\n",
    "# Align orthomosaic with GCPs to GCPs\n",
    "print(\"\\n2. Aligning orthomosaic (with GCPs) to GCPs...\")\n",
    "gcp_aligned_with_gcps_path = gcp_aligned_dir / \"orthomosaic_with_gcps_gcp_aligned.tif\"\n",
    "_, alignment_info_with_gcps = align_orthomosaic_to_gcps(\n",
    "    ortho_path=Path(ortho_with_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    gcps=gcps,\n",
    "    output_path=gcp_aligned_with_gcps_path\n",
    ")\n",
    "print(f\"   Alignment RMSE: {alignment_info_with_gcps['rmse_total_pixels']:.2f} pixels\")\n",
    "print(f\"   Used {alignment_info_with_gcps['num_gcps_used']} GCPs\")\n",
    "\n",
    "# Re-analyze GCP-aligned orthomosaics\n",
    "print(\"\\n3. Re-analyzing GCP-aligned orthomosaics against ESRI basemap...\")\n",
    "\n",
    "# Compare GCP-aligned orthomosaic (without GCPs)\n",
    "print(\"\\n   Analyzing GCP-aligned orthomosaic (without GCPs)...\")\n",
    "metrics_gcp_aligned_no_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=gcp_aligned_no_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare GCP-aligned orthomosaic (with GCPs)\n",
    "print(\"\\n   Analyzing GCP-aligned orthomosaic (with GCPs)...\")\n",
    "metrics_gcp_aligned_with_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=gcp_aligned_with_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Save GCP-aligned metrics\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gcp_aligned_metrics_file_no_gcps = metrics_dir / \"metrics_gcp_aligned_no_gcps_esri.json\"\n",
    "gcp_aligned_metrics_file_with_gcps = metrics_dir / \"metrics_gcp_aligned_with_gcps_esri.json\"\n",
    "\n",
    "with open(gcp_aligned_metrics_file_no_gcps, 'w') as f:\n",
    "    json.dump(metrics_gcp_aligned_no_gcps, f, indent=2, default=str)\n",
    "with open(gcp_aligned_metrics_file_with_gcps, 'w') as f:\n",
    "    json.dump(metrics_gcp_aligned_with_gcps, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úì GCP-aligned metrics saved to: {metrics_dir}\")\n",
    "\n",
    "# Compare alignment methods\n",
    "print(\"\\n4. Comparing alignment methods...\")\n",
    "\n",
    "# Load initial and shifted metrics if available\n",
    "if 'metrics_no_gcps_esri' not in locals() or 'metrics_with_gcps_esri' not in locals():\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_esri.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_esri.json\"\n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_esri = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_esri = json.load(f)\n",
    "\n",
    "# Load shifted metrics if available\n",
    "shifted_metrics_file_no_gcps = metrics_dir / \"metrics_shifted_no_gcps_esri.json\"\n",
    "shifted_metrics_file_with_gcps = metrics_dir / \"metrics_shifted_with_gcps_esri.json\"\n",
    "metrics_shifted_no_gcps = None\n",
    "metrics_shifted_with_gcps = None\n",
    "if shifted_metrics_file_no_gcps.exists() and shifted_metrics_file_with_gcps.exists():\n",
    "    with open(shifted_metrics_file_no_gcps, 'r') as f:\n",
    "        metrics_shifted_no_gcps = json.load(f)\n",
    "    with open(shifted_metrics_file_with_gcps, 'r') as f:\n",
    "        metrics_shifted_with_gcps = json.load(f)\n",
    "\n",
    "print(\"\\n   Without GCPs - RMSE comparison:\")\n",
    "initial_no = metrics_no_gcps_esri.get('overall', {}) if 'metrics_no_gcps_esri' in locals() else {}\n",
    "shifted_no = metrics_shifted_no_gcps.get('overall', {}) if metrics_shifted_no_gcps else {}\n",
    "gcp_aligned_no = metrics_gcp_aligned_no_gcps.get('overall', {})\n",
    "\n",
    "if initial_no.get('rmse'):\n",
    "    print(f\"     Initial:        {initial_no['rmse']:.4f}\")\n",
    "if shifted_no.get('rmse'):\n",
    "    print(f\"     Feature-matched: {shifted_no['rmse']:.4f}\")\n",
    "if gcp_aligned_no.get('rmse'):\n",
    "    print(f\"     GCP-aligned:     {gcp_aligned_no['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\n   With GCPs - RMSE comparison:\")\n",
    "initial_with = metrics_with_gcps_esri.get('overall', {}) if 'metrics_with_gcps_esri' in locals() else {}\n",
    "shifted_with = metrics_shifted_with_gcps.get('overall', {}) if metrics_shifted_with_gcps else {}\n",
    "gcp_aligned_with = metrics_gcp_aligned_with_gcps.get('overall', {})\n",
    "\n",
    "if initial_with.get('rmse'):\n",
    "    print(f\"     Initial:        {initial_with['rmse']:.4f}\")\n",
    "if shifted_with.get('rmse'):\n",
    "    print(f\"     Feature-matched: {shifted_with['rmse']:.4f}\")\n",
    "if gcp_aligned_with.get('rmse'):\n",
    "    print(f\"     GCP-aligned:     {gcp_aligned_with['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\n‚úì Step 7.6 complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against OpenStreetMap basemap\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import compare_orthomosaic_to_basemap\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "if 'basemap_osm_path' not in locals():\n",
    "    basemap_osm_path = str(output_dir / \"qualicum_beach_basemap_osm.tif\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing orthomosaics to OpenStreetMap basemap...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Determine orthomosaic paths - use stats if available, otherwise find files directly\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    if 'stats_no_gcps' in locals() and 'ortho_path' in stats_no_gcps:\n",
    "        ortho_no_gcps_path = Path(stats_no_gcps['ortho_path'])\n",
    "    else:\n",
    "        ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "        ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "        if not ortho_no_gcps_path.exists():\n",
    "            raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found at: {ortho_no_gcps_path.absolute()}\")\n",
    "\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    if 'stats_with_gcps' in locals() and 'ortho_path' in stats_with_gcps:\n",
    "        ortho_with_gcps_path = Path(stats_with_gcps['ortho_path'])\n",
    "    else:\n",
    "        ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "        ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "        if not ortho_with_gcps_path.exists():\n",
    "            raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found at: {ortho_with_gcps_path.absolute()}\")\n",
    "\n",
    "# Compare without GCPs\n",
    "print(\"\\nComparing orthomosaic (without GCPs) to OpenStreetMap basemap...\")\n",
    "metrics_no_gcps_osm = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_no_gcps_path,\n",
    "    basemap_path=Path(basemap_osm_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare with GCPs\n",
    "print(\"\\nComparing orthomosaic (with GCPs) to OpenStreetMap basemap...\")\n",
    "metrics_with_gcps_osm = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_with_gcps_path,\n",
    "    basemap_path=Path(basemap_osm_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì OpenStreetMap comparison complete!\")\n",
    "\n",
    "# Save metrics to JSON files for later use\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "if 'convert_to_json_serializable' not in locals():\n",
    "    from qualicum_beach_gcp_analysis.report_generator import convert_to_json_serializable\n",
    "\n",
    "if 'metrics_dir' not in locals():\n",
    "    metrics_dir = comparison_dir / \"metrics\"\n",
    "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save OpenStreetMap metrics\n",
    "metrics_no_gcps_osm_serializable = convert_to_json_serializable(metrics_no_gcps_osm)\n",
    "metrics_with_gcps_osm_serializable = convert_to_json_serializable(metrics_with_gcps_osm)\n",
    "\n",
    "with open(metrics_dir / \"metrics_no_gcps_osm.json\", 'w') as f:\n",
    "    json.dump(metrics_no_gcps_osm_serializable, f, indent=2)\n",
    "with open(metrics_dir / \"metrics_with_gcps_osm.json\", 'w') as f:\n",
    "    json.dump(metrics_with_gcps_osm_serializable, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Metrics saved to: {metrics_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Quality Reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report for ESRI comparison\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "# Import report generation functions\n",
    "if 'generate_comparison_report' not in locals() or 'generate_markdown_report' not in locals() or 'generate_latex_report' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        generate_comparison_report,\n",
    "        generate_markdown_report,\n",
    "        generate_latex_report\n",
    "    )\n",
    "\n",
    "# Import visualization functions separately to ensure they're always available\n",
    "if 'create_error_visualization' not in locals() or 'create_seamline_visualization' not in locals() or 'create_comparison_side_by_side' not in locals() or 'create_metrics_summary_plot' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        create_error_visualization,\n",
    "        create_seamline_visualization,\n",
    "        create_comparison_side_by_side,\n",
    "        create_metrics_summary_plot\n",
    "    )\n",
    "    \n",
    "if 'numpy' not in locals():\n",
    "    import numpy as np\n",
    "if 'rasterio' not in locals():\n",
    "    import rasterio\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "\n",
    "# Load metrics from Step 7 if available, otherwise check for saved files\n",
    "if 'metrics_no_gcps_esri' not in locals() or 'metrics_with_gcps_esri' not in locals():\n",
    "    # Try to load from saved JSON files\n",
    "    metrics_dir = comparison_dir / \"metrics\"\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_esri.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_esri.json\"\n",
    "    \n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        print(f\"Loading saved metrics from: {metrics_dir}\")\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_esri = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_esri = json.load(f)\n",
    "        print(\"‚úì Loaded saved ESRI comparison metrics\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            f\"metrics_no_gcps_esri and metrics_with_gcps_esri must be defined. \"\n",
    "            f\"Please run Step 7 first, or ensure saved metrics exist at:\\n\"\n",
    "            f\"  {metrics_file_no_gcps}\\n\"\n",
    "            f\"  {metrics_file_with_gcps}\"\n",
    "        )\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Generating quality reports...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ESRI report\n",
    "report_json_esri = output_dir / \"quality_report_esri.json\"\n",
    "report_md_esri = output_dir / \"quality_report_esri.md\"\n",
    "\n",
    "generate_comparison_report(\n",
    "    metrics_with_gcps=metrics_with_gcps_esri,\n",
    "    metrics_without_gcps=metrics_no_gcps_esri,\n",
    "    output_path=report_json_esri,\n",
    "    basemap_source=\"ESRI World Imagery\"\n",
    ")\n",
    "\n",
    "generate_markdown_report(\n",
    "    json_report_path=report_json_esri,\n",
    "    output_path=report_md_esri\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì ESRI report saved:\")\n",
    "print(f\"  JSON: {report_json_esri}\")\n",
    "print(f\"  Markdown: {report_md_esri}\")\n",
    "\n",
    "# Ensure orthomosaic paths are defined\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "    if not ortho_no_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found at: {ortho_no_gcps_path.absolute()}\")\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "    if not ortho_with_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found at: {ortho_with_gcps_path.absolute()}\")\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Generate visualizations for ESRI comparison\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "vis_dir = output_dir / \"visualizations\" / \"esri\"\n",
    "vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load orthomosaics and reference for visualization at reduced resolution to save memory\n",
    "# Use downsampling to reduce memory usage (load every Nth pixel)\n",
    "print(\"  Loading orthomosaics and reference basemap (downsampled for memory efficiency)...\")\n",
    "downsample_factor = 4  # Load every 4th pixel (16x less memory)\n",
    "\n",
    "def load_downsampled(src_path, downsample=downsample_factor):\n",
    "    \"\"\"Load image at reduced resolution to save memory.\"\"\"\n",
    "    with rasterio.open(src_path) as src:\n",
    "        # Read at reduced resolution using windowed reading\n",
    "        height, width = src.height, src.width\n",
    "        new_height, new_width = height // downsample, width // downsample\n",
    "        # Use windowed read with decimation\n",
    "        window = rasterio.windows.Window(0, 0, width, height)\n",
    "        data = src.read(1, window=window, out_shape=(new_height, new_width), resampling=rasterio.enums.Resampling.bilinear)\n",
    "        return data\n",
    "\n",
    "# Load images one at a time and process visualizations to minimize memory usage\n",
    "ortho_no_gcps = load_downsampled(ortho_no_gcps_path)\n",
    "print(f\"    Loaded ortho_no_gcps: {ortho_no_gcps.shape} (downsampled from full resolution)\")\n",
    "\n",
    "ortho_with_gcps = load_downsampled(ortho_with_gcps_path)\n",
    "print(f\"    Loaded ortho_with_gcps: {ortho_with_gcps.shape} (downsampled from full resolution)\")\n",
    "\n",
    "reference_esri = load_downsampled(basemap_esri_path)\n",
    "print(f\"    Loaded reference_esri: {reference_esri.shape} (downsampled from full resolution)\")\n",
    "\n",
    "# Create visualizations one at a time and clear memory after each\n",
    "print(\"  Creating comparison visualizations...\")\n",
    "create_comparison_side_by_side(\n",
    "    ortho_no_gcps, ortho_with_gcps, reference_esri,\n",
    "    vis_dir / \"comparison_side_by_side.png\",\n",
    "    title=\"ESRI Basemap Comparison\"\n",
    ")\n",
    "del ortho_no_gcps, ortho_with_gcps, reference_esri  # Free memory\n",
    "\n",
    "# Metrics plot doesn't need images\n",
    "create_metrics_summary_plot(\n",
    "    metrics_no_gcps_esri, metrics_with_gcps_esri,\n",
    "    vis_dir / \"metrics_summary.png\",\n",
    "    title=\"ESRI Basemap Quality Metrics\"\n",
    ")\n",
    "\n",
    "# Reload images for remaining visualizations (one at a time)\n",
    "print(\"  Creating seamline visualizations...\")\n",
    "ortho_no_gcps = load_downsampled(ortho_no_gcps_path)\n",
    "create_seamline_visualization(\n",
    "    ortho_no_gcps,\n",
    "    vis_dir / \"seamlines_no_gcps.png\",\n",
    "    title=\"Seamlines - Without GCPs\"\n",
    ")\n",
    "del ortho_no_gcps\n",
    "\n",
    "ortho_with_gcps = load_downsampled(ortho_with_gcps_path)\n",
    "create_seamline_visualization(\n",
    "    ortho_with_gcps,\n",
    "    vis_dir / \"seamlines_with_gcps.png\",\n",
    "    title=\"Seamlines - With GCPs\"\n",
    ")\n",
    "del ortho_with_gcps\n",
    "\n",
    "# Reload for error visualizations\n",
    "print(\"  Creating error visualizations...\")\n",
    "ortho_no_gcps = load_downsampled(ortho_no_gcps_path)\n",
    "reference_esri = load_downsampled(basemap_esri_path)\n",
    "create_error_visualization(\n",
    "    ortho_no_gcps, reference_esri,\n",
    "    vis_dir / \"error_no_gcps.png\",\n",
    "    title=\"Error Map - Without GCPs\"\n",
    ")\n",
    "del ortho_no_gcps\n",
    "\n",
    "ortho_with_gcps = load_downsampled(ortho_with_gcps_path)\n",
    "create_error_visualization(\n",
    "    ortho_with_gcps, reference_esri,\n",
    "    vis_dir / \"error_with_gcps.png\",\n",
    "    title=\"Error Map - With GCPs\"\n",
    ")\n",
    "del ortho_with_gcps, reference_esri\n",
    "\n",
    "print(f\"‚úì Visualizations saved to: {vis_dir}\")\n",
    "\n",
    "\n",
    "# OpenStreetMap report\n",
    "# Load metrics from Step 7 if available, otherwise check for saved files\n",
    "if 'metrics_no_gcps_osm' not in locals() or 'metrics_with_gcps_osm' not in locals():\n",
    "    # Try to load from saved JSON files\n",
    "    if 'metrics_dir' not in locals():\n",
    "        metrics_dir = comparison_dir / \"metrics\"\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_osm.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_osm.json\"\n",
    "    \n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        print(f\"Loading saved metrics from: {metrics_dir}\")\n",
    "        if 'json' not in locals():\n",
    "            import json\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_osm = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_osm = json.load(f)\n",
    "        print(\"‚úì Loaded saved OpenStreetMap comparison metrics\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            f\"metrics_no_gcps_osm and metrics_with_gcps_osm must be defined. \"\n",
    "            f\"Please run Step 7 first, or ensure saved metrics exist at:\\n\"\n",
    "            f\"  {metrics_file_no_gcps}\\n\"\n",
    "            f\"  {metrics_file_with_gcps}\"\n",
    "        )\n",
    "\n",
    "report_json_osm = output_dir / \"quality_report_osm.json\"\n",
    "report_md_osm = output_dir / \"quality_report_osm.md\"\n",
    "\n",
    "generate_comparison_report(\n",
    "    metrics_with_gcps=metrics_with_gcps_osm,\n",
    "    metrics_without_gcps=metrics_no_gcps_osm,\n",
    "    output_path=report_json_osm,\n",
    "    basemap_source=\"OpenStreetMap\"\n",
    ")\n",
    "\n",
    "generate_markdown_report(\n",
    "    json_report_path=report_json_osm,\n",
    "    output_path=report_md_osm\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì OpenStreetMap report saved:\")\n",
    "print(f\"  JSON: {report_json_osm}\")\n",
    "print(f\"  Markdown: {report_md_osm}\")\n",
    "\n",
    "# Generate visualizations for OpenStreetMap comparison\n",
    "print(\"\\nGenerating visualizations for OpenStreetMap...\")\n",
    "vis_dir_osm = output_dir / \"visualizations\" / \"osm\"\n",
    "vis_dir_osm.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure basemap path is defined\n",
    "if 'basemap_osm_path' not in locals():\n",
    "    basemap_osm_path = str(output_dir / \"qualicum_beach_basemap_osm.tif\")\n",
    "\n",
    "# Load reference basemap for visualization\n",
    "print(\"  Loading reference basemap...\")\n",
    "with rasterio.open(basemap_osm_path) as src:\n",
    "    reference_osm = src.read(1)  # First band\n",
    "\n",
    "# Load images at reduced resolution for OpenStreetMap visualizations\n",
    "print(\"  Loading orthomosaics for OpenStreetMap visualizations (downsampled)...\")\n",
    "# Reuse the load_downsampled function defined above\n",
    "ortho_no_gcps = load_downsampled(ortho_no_gcps_path)\n",
    "ortho_with_gcps = load_downsampled(ortho_with_gcps_path)\n",
    "\n",
    "# Create visualizations one at a time\n",
    "print(\"  Creating comparison visualizations...\")\n",
    "create_comparison_side_by_side(\n",
    "    ortho_no_gcps, ortho_with_gcps, reference_osm,\n",
    "    vis_dir_osm / \"comparison_side_by_side.png\",\n",
    "    title=\"OpenStreetMap Basemap Comparison\"\n",
    ")\n",
    "del ortho_no_gcps, ortho_with_gcps  # Free memory\n",
    "\n",
    "# Metrics plot doesn't need images\n",
    "create_metrics_summary_plot(\n",
    "    metrics_no_gcps_osm, metrics_with_gcps_osm,\n",
    "    vis_dir_osm / \"metrics_summary.png\",\n",
    "    title=\"OpenStreetMap Basemap Quality Metrics\"\n",
    ")\n",
    "\n",
    "# Reload for seamline visualizations\n",
    "print(\"  Creating seamline visualizations...\")\n",
    "ortho_no_gcps = load_downsampled(ortho_no_gcps_path)\n",
    "create_seamline_visualization(\n",
    "    ortho_no_gcps,\n",
    "    vis_dir_osm / \"seamlines_no_gcps.png\",\n",
    "    title=\"Seamlines - Without GCPs\"\n",
    ")\n",
    "del ortho_no_gcps\n",
    "\n",
    "ortho_with_gcps = load_downsampled(ortho_with_gcps_path)\n",
    "create_seamline_visualization(\n",
    "    ortho_with_gcps,\n",
    "    vis_dir_osm / \"seamlines_with_gcps.png\",\n",
    "    title=\"Seamlines - With GCPs\"\n",
    ")\n",
    "del ortho_with_gcps\n",
    "\n",
    "# Reload for error visualizations\n",
    "print(\"  Creating error visualizations...\")\n",
    "ortho_no_gcps = load_downsampled(ortho_no_gcps_path)\n",
    "create_error_visualization(\n",
    "    ortho_no_gcps, reference_osm,\n",
    "    vis_dir_osm / \"error_no_gcps.png\",\n",
    "    title=\"Error Map - Without GCPs\"\n",
    ")\n",
    "del ortho_no_gcps\n",
    "\n",
    "ortho_with_gcps = load_downsampled(ortho_with_gcps_path)\n",
    "create_error_visualization(\n",
    "    ortho_with_gcps, reference_osm,\n",
    "    vis_dir_osm / \"error_with_gcps.png\",\n",
    "    title=\"Error Map - With GCPs\"\n",
    ")\n",
    "del ortho_with_gcps, reference_osm\n",
    "\n",
    "print(f\"‚úì Visualizations saved to: {vis_dir_osm}\")\n",
    "\n",
    "# Generate comprehensive LaTeX/PDF report with both ESRI and OSM\n",
    "# Check for shifted metrics (from Step 7.5) and GCP-aligned metrics (from Step 7.6)\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "shifted_metrics_no_gcps_path = metrics_dir / \"metrics_shifted_no_gcps_esri.json\"\n",
    "shifted_metrics_with_gcps_path = metrics_dir / \"metrics_shifted_with_gcps_esri.json\"\n",
    "gcp_aligned_metrics_no_gcps_path = metrics_dir / \"metrics_gcp_aligned_no_gcps_esri.json\"\n",
    "gcp_aligned_metrics_with_gcps_path = metrics_dir / \"metrics_gcp_aligned_with_gcps_esri.json\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Generating comprehensive LaTeX/PDF report (ESRI + OSM)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report_latex_final = output_dir / \"quality_report_final\"\n",
    "latex_result_final = generate_latex_report(\n",
    "    json_report_path=report_json_esri,\n",
    "    output_path=report_latex_final,\n",
    "    visualization_dir=vis_dir,\n",
    "    json_report_path_osm=report_json_osm,\n",
    "    visualization_dir_osm=vis_dir_osm,\n",
    "    shifted_metrics_no_gcps_path=shifted_metrics_no_gcps_path if shifted_metrics_no_gcps_path.exists() else None,\n",
    "    shifted_metrics_with_gcps_path=shifted_metrics_with_gcps_path if shifted_metrics_with_gcps_path.exists() else None,\n",
    "    gcp_aligned_metrics_no_gcps_path=gcp_aligned_metrics_no_gcps_path if gcp_aligned_metrics_no_gcps_path.exists() else None,\n",
    "    gcp_aligned_metrics_with_gcps_path=gcp_aligned_metrics_with_gcps_path if gcp_aligned_metrics_with_gcps_path.exists() else None\n",
    ")\n",
    "\n",
    "if latex_result_final.suffix == '.pdf':\n",
    "    print(f\"\\n‚úì PDF report generated: {latex_result_final}\")\n",
    "else:\n",
    "    print(f\"\\n‚úì LaTeX file generated: {latex_result_final}\")\n",
    "    print(\"  (Install LaTeX and run: pdflatex quality_report_final.tex to generate PDF)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Display Report Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary from ESRI report\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "\n",
    "# Define report paths\n",
    "report_json_esri = output_dir / \"quality_report_esri.json\"\n",
    "report_json_osm = output_dir / \"quality_report_osm.json\"\n",
    "report_md_esri = output_dir / \"quality_report_esri.md\"\n",
    "report_md_osm = output_dir / \"quality_report_osm.md\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"QUALITY COMPARISON SUMMARY (ESRI World Imagery)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with open(report_json_esri, 'r') as f:\n",
    "    report_esri = json.load(f)\n",
    "\n",
    "comparison = report_esri.get('comparison', {})\n",
    "\n",
    "if comparison.get('rmse_improvement'):\n",
    "    rmse = comparison['rmse_improvement']\n",
    "    print(f\"\\nRMSE Improvement: {rmse['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {rmse['without_gcps']:.4f}\")\n",
    "    print(f\"  With GCPs:    {rmse['with_gcps']:.4f}\")\n",
    "\n",
    "if comparison.get('mae_improvement'):\n",
    "    mae = comparison['mae_improvement']\n",
    "    print(f\"\\nMAE Improvement: {mae['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {mae['without_gcps']:.4f}\")\n",
    "    print(f\"  With GCPs:    {mae['with_gcps']:.4f}\")\n",
    "\n",
    "if comparison.get('similarity_improvement'):\n",
    "    sim = comparison['similarity_improvement']\n",
    "    print(f\"\\nSimilarity Improvement: {sim['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {sim['without_gcps']:.4f}\")\n",
    "    print(f\"  With GCPs:    {sim['with_gcps']:.4f}\")\n",
    "\n",
    "if comparison.get('seamline_reduction'):\n",
    "    seam = comparison['seamline_reduction']\n",
    "    print(f\"\\nSeamline Reduction: {seam['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {seam['without_gcps']:.2f}%\")\n",
    "    print(f\"  With GCPs:    {seam['with_gcps']:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Full reports available at:\")\n",
    "print(f\"  {report_md_esri}\")\n",
    "print(f\"  {report_md_osm}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
