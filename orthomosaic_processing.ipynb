{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualicum Beach Orthomosaic Processing with GCPs\n",
    "\n",
    "This notebook processes drone imagery to create orthomosaics using Agisoft Metashape, comparing results with and without ground control points (GCPs).\n",
    "\n",
    "## Workflow:\n",
    "1. Load GCPs from KMZ file\n",
    "2. Download drone imagery from S3 (all 12 cells)\n",
    "3. Process orthomosaic WITHOUT GCPs\n",
    "4. Process orthomosaic WITH GCPs\n",
    "5. Compare both orthomosaics against ESRI and OpenStreetMap basemaps\n",
    "6. Generate comprehensive quality report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Add package to path\n",
    "package_dir = Path.cwd()\n",
    "sys.path.insert(0, str(package_dir))\n",
    "\n",
    "from qualicum_beach_gcp_analysis import (\n",
    "    load_gcps_from_kmz,\n",
    "    download_basemap,\n",
    "    visualize_gcps_on_basemap,\n",
    "    calculate_gcp_bbox,\n",
    "    download_all_images_from_input_dir,\n",
    "    export_to_metashape_csv,\n",
    "    export_to_metashape_xml,\n",
    "    process_orthomosaic,\n",
    "    PhotoMatchQuality,\n",
    "    DepthMapQuality,\n",
    "    compare_orthomosaic_to_basemap,\n",
    "    generate_comparison_report,\n",
    "    generate_markdown_report,\n",
    ")\n",
    "\n",
    "print(\"\u2713 Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Ground Control Points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GCPs from: /Users/mauriciohessflores/Documents/Code/Data/Qualicum Beach GCPs/Spexi_Survey_Points/Spexi_Drone_Survey/QualicumBeach_AOI.kmz\n",
      "Found 1 KML file(s) in KMZ\n",
      "Attempting to fix namespace issues...\n",
      "\u2713 Fixed namespace issues in KML file\n",
      "Found 12 placemarks in KMZ file (namespace: http://www.opengis.net/kml/2.2)\n",
      "Successfully parsed 12 GCPs from KMZ file\n",
      "\n",
      "\u2713 Loaded 12 ground control points\n",
      "\n",
      "GCPs:\n",
      "   1. 8928d89ac03ffff     : (49.352544, -124.407904, z=0.00)\n",
      "   2. 8928d89ac0bffff     : (49.354342, -124.404136, z=0.00)\n",
      "   3. 8928d89ac1bffff     : (49.351585, -124.403857, z=0.00)\n",
      "   4. 8928d89ac43ffff     : (49.355182, -124.396319, z=0.00)\n",
      "   5. 8928d89ac47ffff     : (49.356141, -124.400367, z=0.00)\n",
      "   6. 8928d89ac53ffff     : (49.352425, -124.396040, z=0.00)\n",
      "   7. 8928d89ac57ffff     : (49.353384, -124.400088, z=0.00)\n",
      "   8. 8928d89ac5bffff     : (49.354224, -124.392271, z=0.00)\n",
      "   9. 8928d89ac73ffff     : (49.357100, -124.404415, z=0.00)\n",
      "  10. 8928d89acc7ffff     : (49.348828, -124.403577, z=0.00)\n",
      "  11. 8928d89accbffff     : (49.349668, -124.395761, z=0.00)\n",
      "  12. 8928d89accfffff     : (49.350626, -124.399809, z=0.00)\n"
     ]
    }
   ],
   "source": [
    "# Path to the KMZ file\n",
    "kmz_path = \"/Users/mauriciohessflores/Documents/Code/Data/Qualicum Beach GCPs/Spexi_Survey_Points/Spexi_Drone_Survey/QualicumBeach_AOI.kmz\"\n",
    "\n",
    "# Load GCPs\n",
    "gcps = load_gcps_from_kmz(kmz_path)\n",
    "\n",
    "print(f\"\\n\u2713 Loaded {len(gcps)} ground control points\")\n",
    "\n",
    "# Display all GCPs\n",
    "if gcps:\n",
    "    print(\"\\nGCPs:\")\n",
    "    for i, gcp in enumerate(gcps):\n",
    "        print(f\"  {i+1:2d}. {gcp.get('id', 'Unknown'):20s}: ({gcp['lat']:.6f}, {gcp['lon']:.6f}, z={gcp.get('z', 0):.2f})\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  No GCPs found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Bounding Box and Download Reference Basemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box:\n",
      "  Latitude: 49.338828 to 49.367100\n",
      "  Longitude: -124.417904 to -124.382271\n",
      "\n",
      "Downloading ESRI World Imagery basemap...\n",
      "Downloading basemap at zoom level 13...\n",
      "Tile range: X [1264, 1265], Y [2800, 2801]\n",
      "Basemap saved to outputs/qualicum_beach_basemap_esri.tif\n",
      "\u2713 ESRI basemap saved to: outputs/qualicum_beach_basemap_esri.tif\n",
      "\n",
      "Downloading OpenStreetMap basemap...\n",
      "Downloading basemap at zoom level 13...\n",
      "Tile range: X [1264, 1265], Y [2800, 2801]\n",
      "Basemap saved to outputs/qualicum_beach_basemap_osm.tif\n",
      "\u2713 OpenStreetMap basemap saved to: outputs/qualicum_beach_basemap_osm.tif\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Calculate bounding box\n",
    "bbox = calculate_gcp_bbox(gcps, padding=0.01)\n",
    "min_lat, min_lon, max_lat, max_lon = bbox\n",
    "\n",
    "print(f\"Bounding box:\")\n",
    "print(f\"  Latitude: {min_lat:.6f} to {max_lat:.6f}\")\n",
    "print(f\"  Longitude: {min_lon:.6f} to {max_lon:.6f}\")\n",
    "\n",
    "# Download ESRI World Imagery basemap (for comparison)\n",
    "basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "print(\"\\nDownloading ESRI World Imagery basemap...\")\n",
    "basemap_esri_path = download_basemap(\n",
    "    bbox=bbox,\n",
    "    output_path=basemap_esri_path,\n",
    "    source=\"esri_world_imagery\",\n",
    "    zoom=None\n",
    ")\n",
    "print(f\"\u2713 ESRI basemap saved to: {basemap_esri_path}\")\n",
    "\n",
    "# Download OpenStreetMap basemap (for comparison)\n",
    "basemap_osm_path = str(output_dir / \"qualicum_beach_basemap_osm.tif\")\n",
    "print(\"\\nDownloading OpenStreetMap basemap...\")\n",
    "basemap_osm_path = download_basemap(\n",
    "    bbox=bbox,\n",
    "    output_path=basemap_osm_path,\n",
    "    source=\"openstreetmap\",\n",
    "    zoom=None\n",
    ")\n",
    "print(f\"\u2713 OpenStreetMap basemap saved to: {basemap_osm_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Drone Imagery from S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 15:17:12,237 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Found 12 manifest files\n",
      "2025-12-01 15:17:12,354 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172543.txt\n",
      "2025-12-01 15:17:12,354 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,354 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac53ffff/172543/\n",
      "2025-12-01 15:17:12,355 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 152\n",
      "2025-12-01 15:17:12,356 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 152 skipped, 0 failed\n",
      "2025-12-01 15:17:12,361 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172547.txt\n",
      "2025-12-01 15:17:12,362 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,362 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89accbffff/172547/\n",
      "2025-12-01 15:17:12,362 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 151\n",
      "2025-12-01 15:17:12,364 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 151 skipped, 0 failed\n",
      "2025-12-01 15:17:12,366 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172550.txt\n",
      "2025-12-01 15:17:12,367 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,367 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac57ffff/172550/\n",
      "2025-12-01 15:17:12,367 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 155\n",
      "2025-12-01 15:17:12,369 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 155 skipped, 0 failed\n",
      "2025-12-01 15:17:12,371 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172553.txt\n",
      "2025-12-01 15:17:12,371 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,371 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89accfffff/172553/\n",
      "2025-12-01 15:17:12,372 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 153\n",
      "2025-12-01 15:17:12,373 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 153 skipped, 0 failed\n",
      "2025-12-01 15:17:12,376 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172555.txt\n",
      "2025-12-01 15:17:12,376 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,376 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac0bffff/172555/\n",
      "2025-12-01 15:17:12,377 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-01 15:17:12,378 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-01 15:17:12,381 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172562.txt\n",
      "2025-12-01 15:17:12,382 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,382 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac73ffff/172562/\n",
      "2025-12-01 15:17:12,382 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-01 15:17:12,384 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-01 15:17:12,387 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172565.txt\n",
      "2025-12-01 15:17:12,388 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,388 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac47ffff/172565/\n",
      "2025-12-01 15:17:12,388 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 152\n",
      "2025-12-01 15:17:12,390 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 152 skipped, 0 failed\n",
      "2025-12-01 15:17:12,392 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172568.txt\n",
      "2025-12-01 15:17:12,393 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,393 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac43ffff/172568/\n",
      "2025-12-01 15:17:12,393 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 152\n",
      "2025-12-01 15:17:12,394 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 152 skipped, 0 failed\n",
      "2025-12-01 15:17:12,398 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_172571.txt\n",
      "2025-12-01 15:17:12,398 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,398 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac5bffff/172571/\n",
      "2025-12-01 15:17:12,398 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-01 15:17:12,400 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-01 15:17:12,402 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_183538.txt\n",
      "2025-12-01 15:17:12,402 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,402 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89acc7ffff/183538/\n",
      "2025-12-01 15:17:12,403 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 155\n",
      "2025-12-01 15:17:12,404 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 155 skipped, 0 failed\n",
      "2025-12-01 15:17:12,406 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_183544.txt\n",
      "2025-12-01 15:17:12,407 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,407 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac1bffff/183544/\n",
      "2025-12-01 15:17:12,407 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 155\n",
      "2025-12-01 15:17:12,408 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 155 skipped, 0 failed\n",
      "2025-12-01 15:17:12,411 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Processing manifest: input-file_183548.txt\n",
      "2025-12-01 15:17:12,411 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Bucket: spexi-data-domain-assets-production-ca-central-1\n",
      "2025-12-01 15:17:12,411 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   S3 prefix: standardized-images/8928d89ac03ffff/183548/\n",
      "2025-12-01 15:17:12,411 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Total images: 154\n",
      "2025-12-01 15:17:12,413 - qualicum_beach_gcp_analysis.s3_downloader - INFO -   Completed: 0 downloaded, 154 skipped, 0 failed\n",
      "2025-12-01 15:17:12,413 - qualicum_beach_gcp_analysis.s3_downloader - INFO - \n",
      "============================================================\n",
      "2025-12-01 15:17:12,413 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Download Summary\n",
      "2025-12-01 15:17:12,413 - qualicum_beach_gcp_analysis.s3_downloader - INFO - ============================================================\n",
      "2025-12-01 15:17:12,413 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Total manifest files: 12\n",
      "2025-12-01 15:17:12,413 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Total images: 1841\n",
      "2025-12-01 15:17:12,414 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Downloaded: 0\n",
      "2025-12-01 15:17:12,414 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Skipped (already exist): 1841\n",
      "2025-12-01 15:17:12,414 - qualicum_beach_gcp_analysis.s3_downloader - INFO - Failed: 0\n",
      "2025-12-01 15:17:12,414 - qualicum_beach_gcp_analysis.s3_downloader - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images from S3...\n",
      "============================================================\n",
      "============================================================\n",
      "\u2713 Image download complete\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "input_dir = Path(\"input\")\n",
    "photos_dir = Path(\"input/images\")\n",
    "\n",
    "# Download all images from input manifest files\n",
    "print(\"Downloading images from S3...\")\n",
    "print(\"=\" * 60)\n",
    "download_stats = download_all_images_from_input_dir(\n",
    "    input_dir=input_dir,\n",
    "    photos_dir=photos_dir,\n",
    "    skip_existing=True  # Don't re-download if images already exist\n",
    ")\n",
    "print(\"=\" * 60)\n",
    "print(\"\u2713 Image download complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Export GCPs for MetaShape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 12 GCPs to MetaShape XML: outputs/gcps_metashape.xml\n",
      "\u2713 GCPs exported to XML: outputs/gcps_metashape.xml\n",
      "Exported 12 GCPs to MetaShape CSV: outputs/gcps_metashape.csv\n",
      "\u2713 GCPs also exported to CSV: outputs/gcps_metashape.csv\n"
     ]
    }
   ],
   "source": [
    "# Export GCPs to MetaShape XML format (preferred by MetaShape)\n",
    "gcp_xml_path = output_dir / \"gcps_metashape.xml\"\n",
    "export_to_metashape_xml(gcps, str(gcp_xml_path))\n",
    "print(f\"\u2713 GCPs exported to XML: {gcp_xml_path}\")\n",
    "\n",
    "# Also export CSV for reference\n",
    "gcp_csv_path = output_dir / \"gcps_metashape.csv\"\n",
    "export_to_metashape_csv(gcps, str(gcp_csv_path))\n",
    "print(f\"\u2713 GCPs also exported to CSV: {gcp_csv_path}\")\n",
    "\n",
    "# Use XML file for processing (MetaShape's native format)\n",
    "gcp_file_path = gcp_xml_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Process Orthomosaic WITHOUT GCPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 15:17:22,390 - qualicum_beach_gcp_analysis.metashape_processor - INFO - \ud83d\udcdd MetaShape verbose output will be saved to: outputs/intermediate/logs/orthomosaic_no_gcps_metashape.log\n",
      "2025-12-01 15:17:22,391 - qualicum_beach_gcp_analysis.metashape_processor - INFO - \ud83d\udcc2 Loading existing project: outputs/intermediate/orthomosaic_no_gcps.psx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing orthomosaic WITHOUT GCPs...\n",
      "============================================================\n",
      "LoadProject: path = outputs/intermediate/orthomosaic_no_gcps.psx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document.open(): The document is opened in read-only mode because it is already in use.\n",
      "2025-12-01 15:17:22,735 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Found existing chunk with 1841 cameras\n",
      "2025-12-01 15:17:22,804 - qualicum_beach_gcp_analysis.metashape_processor - INFO - Processing status:\n",
      "2025-12-01 15:17:22,804 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Photos added: True\n",
      "2025-12-01 15:17:22,804 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Photos matched: True\n",
      "2025-12-01 15:17:22,804 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Cameras aligned: True\n",
      "2025-12-01 15:17:22,805 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Depth maps built: True\n",
      "2025-12-01 15:17:22,805 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Model built: True\n",
      "2025-12-01 15:17:22,805 - qualicum_beach_gcp_analysis.metashape_processor - INFO -   Orthomosaic built: True\n",
      "2025-12-01 15:17:22,805 - qualicum_beach_gcp_analysis.metashape_processor - INFO - \u2713 Photos already added (1841 cameras)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded project in 0.001425 sec\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metashape.Metashape.Camera' object has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     12\u001b[0m project_path_no_gcps \u001b[38;5;241m=\u001b[39m intermediate_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morthomosaic_no_gcps.psx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m stats_no_gcps \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_orthomosaic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphotos_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphotos_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mortho_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_path_no_gcps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduct_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morthomosaic_no_gcps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_intermediate_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reuse existing processing if available\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphoto_match_quality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPhotoMatchQuality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMediumQuality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth_map_quality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDepthMapQuality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMediumQuality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtiepoint_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_gcps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\u2713 Orthomosaic processing (without GCPs) complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Number of photos: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats_no_gcps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_photos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Code/MyCode/research-qualicum_beach_gcp_analysis/qualicum_beach_gcp_analysis/metashape_processor.py:315\u001b[0m, in \u001b[0;36mprocess_orthomosaic\u001b[0;34m(photos_dir, output_path, project_path, gcps, gcp_file, product_id, clean_intermediate_files, photo_match_quality, depth_map_quality, tiepoint_limit, use_gcps, gcp_accuracy)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2713 Photos already added (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mcameras)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cameras)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 315\u001b[0m     photos \u001b[38;5;241m=\u001b[39m [cam\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mfor\u001b[39;00m cam \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcameras \u001b[38;5;28;01mif\u001b[39;00m cam\u001b[38;5;241m.\u001b[39mpath]\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# Add GCPs if requested (only if not already added)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gcps:\n",
      "File \u001b[0;32m~/Documents/Code/MyCode/research-qualicum_beach_gcp_analysis/qualicum_beach_gcp_analysis/metashape_processor.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2713 Photos already added (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mcameras)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cameras)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 315\u001b[0m     photos \u001b[38;5;241m=\u001b[39m [cam\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mfor\u001b[39;00m cam \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcameras \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m]\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# Add GCPs if requested (only if not already added)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gcps:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Metashape.Metashape.Camera' object has no attribute 'path'"
     ]
    }
   ],
   "source": [
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if 'process_orthomosaic' not in locals() or 'PhotoMatchQuality' not in locals() or 'DepthMapQuality' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        process_orthomosaic,\n",
    "        PhotoMatchQuality,\n",
    "        DepthMapQuality\n",
    "    )\n",
    "\n",
    "if 'photos_dir' not in locals():\n",
    "    photos_dir = Path(\"input/images\")\n",
    "\n",
    "# Setup paths for processing\n",
    "intermediate_dir = output_dir / \"intermediate\"\n",
    "ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "\n",
    "# Process orthomosaic WITHOUT GCPs\n",
    "# Note: clean_intermediate_files=False will reuse existing processing steps\n",
    "# Set to True to start fresh and delete previous work\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing orthomosaic WITHOUT GCPs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_path_no_gcps = intermediate_dir / \"orthomosaic_no_gcps.psx\"\n",
    "\n",
    "stats_no_gcps = process_orthomosaic(\n",
    "    photos_dir=photos_dir,\n",
    "    output_path=ortho_output_dir,\n",
    "    project_path=project_path_no_gcps,\n",
    "    product_id=\"orthomosaic_no_gcps\",\n",
    "    clean_intermediate_files=False,  # Reuse existing processing if available\n",
    "    photo_match_quality=PhotoMatchQuality.MediumQuality,\n",
    "    depth_map_quality=DepthMapQuality.MediumQuality,\n",
    "    tiepoint_limit=10000,\n",
    "    use_gcps=False\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Orthomosaic processing (without GCPs) complete!\")\n",
    "print(f\"  Number of photos: {stats_no_gcps['num_photos']}\")\n",
    "print(f\"\\n\ud83d\udcc1 Output Files:\")\n",
    "ortho_path_no_gcps = Path(stats_no_gcps['ortho_path'])\n",
    "if ortho_path_no_gcps.exists():\n",
    "    file_size_mb = ortho_path_no_gcps.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  \u2713 Orthomosaic GeoTIFF: {ortho_path_no_gcps.absolute()}\")\n",
    "    print(f\"    Size: {file_size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"  \u2717 Orthomosaic GeoTIFF NOT FOUND at: {ortho_path_no_gcps.absolute()}\")\n",
    "    print(f\"    Expected location: {ortho_path_no_gcps}\")\n",
    "    print(f\"    Output directory exists: {ortho_path_no_gcps.parent.exists()}\")\n",
    "if 'log_file_path' in stats_no_gcps:\n",
    "    print(f\"  \ud83d\udcdd Log file: {stats_no_gcps['log_file_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Process Orthomosaic WITH GCPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process orthomosaic WITH GCPs\n",
    "# Note: clean_intermediate_files=False will reuse existing processing steps\n",
    "# Set to True to start fresh and delete previous work\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing orthomosaic WITH GCPs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_path_with_gcps = intermediate_dir / \"orthomosaic_with_gcps.psx\"\n",
    "\n",
    "# Use XML file (MetaShape's native format) - defined in Step 4\n",
    "gcp_file_for_processing = output_dir / \"gcps_metashape.xml\"\n",
    "\n",
    "stats_with_gcps = process_orthomosaic(\n",
    "    photos_dir=photos_dir,\n",
    "    output_path=ortho_output_dir,\n",
    "    project_path=project_path_with_gcps,\n",
    "    gcp_file=gcp_file_for_processing,  # Use XML file (MetaShape's native format)\n",
    "    product_id=\"orthomosaic_with_gcps\",\n",
    "    clean_intermediate_files=False,  # Reuse existing processing if available\n",
    "    photo_match_quality=PhotoMatchQuality.MediumQuality,\n",
    "    depth_map_quality=DepthMapQuality.MediumQuality,\n",
    "    tiepoint_limit=10000,\n",
    "    use_gcps=True\n",
    "    gcp_accuracy=0.05,  # High accuracy (5cm) for high weight in bundle adjustment\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Orthomosaic processing (with GCPs) complete!\")\n",
    "print(f\"  Number of photos: {stats_with_gcps['num_photos']}\")\n",
    "print(f\"  Number of markers: {stats_with_gcps.get('num_markers', 0)}\")\n",
    "print(f\"\\n\ud83d\udcc1 Output Files:\")\n",
    "ortho_path_with_gcps = Path(stats_with_gcps['ortho_path'])\n",
    "if ortho_path_with_gcps.exists():\n",
    "    file_size_mb = ortho_path_with_gcps.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  \u2713 Orthomosaic GeoTIFF: {ortho_path_with_gcps.absolute()}\")\n",
    "    print(f\"    Size: {file_size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"  \u2717 Orthomosaic GeoTIFF NOT FOUND at: {ortho_path_with_gcps.absolute()}\")\n",
    "    print(f\"    Expected location: {ortho_path_with_gcps}\")\n",
    "    print(f\"    Output directory exists: {ortho_path_with_gcps.parent.exists()}\")\n",
    "if 'log_file_path' in stats_with_gcps:\n",
    "    print(f\"  \ud83d\udcdd Log file: {stats_with_gcps['log_file_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Orthomosaics to Reference Basemaps\n",
    "\n",
    "### Comparison Methodology\n",
    "\n",
    "The orthomosaics are compared to reference basemaps (ESRI World Imagery and OpenStreetMap) using a comprehensive methodology:\n",
    "\n",
    "#### 1. **Reprojection and Alignment**\n",
    "   - The orthomosaic is reprojected to match the reference basemap's coordinate reference system (CRS) and spatial extent\n",
    "   - Bilinear resampling is used to ensure pixel-level alignment\n",
    "   - Both rasters are normalized to the same spatial resolution\n",
    "\n",
    "#### 2. **Pixel-level Error Metrics**\n",
    "   - **RMSE (Root Mean Square Error)**: Measures overall pixel intensity differences between orthomosaic and reference\n",
    "   - **MAE (Mean Absolute Error)**: Measures average absolute pixel differences\n",
    "   - **Structural Similarity**: Correlation-based measure indicating how well the orthomosaic structure matches the reference\n",
    "\n",
    "#### 3. **2D Spatial Error (Feature Matching)**\n",
    "   - Feature-based matching (SIFT, ORB, or phase correlation) identifies corresponding points between orthomosaic and reference\n",
    "   - Computes X and Y pixel offsets, providing 2D spatial error measurements\n",
    "   - This identifies systematic shifts, rotations, or misalignments that pixel-level metrics might miss\n",
    "   - The method automatically selects the best available algorithm (SIFT > ORB > phase correlation > template matching)\n",
    "\n",
    "#### 4. **Seamline Detection**\n",
    "   - Gradient-based analysis detects potential seamline artifacts\n",
    "   - Identifies high-gradient regions that may indicate stitching errors or discontinuities\n",
    "   - Reports percentage of pixels flagged as potential seamlines\n",
    "\n",
    "#### 5. **Comparison Process**\n",
    "   - Both orthomosaics (with and without GCPs) are compared against the same reference basemap\n",
    "   - Metrics are computed for each band and averaged for overall statistics\n",
    "   - Results are saved to JSON files for persistence and later analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Orthomosaics to Reference Basemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against ESRI basemap\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import compare_orthomosaic_to_basemap\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing orthomosaics to ESRI World Imagery basemap...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_dir = output_dir / \"comparisons\"\n",
    "\n",
    "# Ensure basemap paths are defined (from Step 2)\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Determine orthomosaic paths - use stats if available, otherwise find files directly\n",
    "if 'stats_no_gcps' in locals() and 'ortho_path' in stats_no_gcps:\n",
    "    ortho_no_gcps_path = Path(stats_no_gcps['ortho_path'])\n",
    "else:\n",
    "    # Try to find the orthomosaic file directly\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "    if not ortho_no_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found at: {ortho_no_gcps_path.absolute()}\\n\"\n",
    "                               f\"Please run Step 5 first, or ensure the file exists at this location.\")\n",
    "\n",
    "if 'stats_with_gcps' in locals() and 'ortho_path' in stats_with_gcps:\n",
    "    ortho_with_gcps_path = Path(stats_with_gcps['ortho_path'])\n",
    "else:\n",
    "    # Try to find the orthomosaic file directly\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "    if not ortho_with_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found at: {ortho_with_gcps_path.absolute()}\\n\"\n",
    "                               f\"Please run Step 6 first, or ensure the file exists at this location.\")\n",
    "\n",
    "print(f\"Using orthomosaic (no GCPs): {ortho_no_gcps_path}\")\n",
    "print(f\"Using orthomosaic (with GCPs): {ortho_with_gcps_path}\")\n",
    "\n",
    "# Compare without GCPs\n",
    "print(\"\\nComparing orthomosaic (without GCPs) to ESRI basemap...\")\n",
    "metrics_no_gcps_esri = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_no_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare with GCPs\n",
    "print(\"\\nComparing orthomosaic (with GCPs) to ESRI basemap...\")\n",
    "metrics_with_gcps_esri = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_with_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 ESRI comparison complete!\")\n",
    "\n",
    "# Save metrics to JSON files for later use\n",
    "import json\n",
    "from qualicum_beach_gcp_analysis.report_generator import convert_to_json_serializable\n",
    "\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save ESRI metrics\n",
    "metrics_no_gcps_esri_serializable = convert_to_json_serializable(metrics_no_gcps_esri)\n",
    "metrics_with_gcps_esri_serializable = convert_to_json_serializable(metrics_with_gcps_esri)\n",
    "\n",
    "with open(metrics_dir / \"metrics_no_gcps_esri.json\", 'w') as f:\n",
    "    json.dump(metrics_no_gcps_esri_serializable, f, indent=2)\n",
    "with open(metrics_dir / \"metrics_with_gcps_esri.json\", 'w') as f:\n",
    "    json.dump(metrics_with_gcps_esri_serializable, f, indent=2)\n",
    "\n",
    "print(f\"\u2713 Metrics saved to: {metrics_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.5: Apply 2D Shift Alignment and Re-analyze\n",
    "\n",
    "After the initial comparison, we apply 2D shifts to align the orthomosaics with the ESRI basemap using feature matching, then re-analyze accuracy and seamlines to see if alignment improves the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.5: Apply 2D Shift Alignment and Re-analyze\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'apply_2d_shift_to_orthomosaic' not in locals() or 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        apply_2d_shift_to_orthomosaic,\n",
    "        compare_orthomosaic_to_basemap\n",
    "    )\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Ensure orthomosaic paths are defined\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 7.5: Apply 2D Shift Alignment and Re-analyze\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create directory for shifted orthomosaics\n",
    "shifted_dir = output_dir / \"orthomosaics_shifted\"\n",
    "shifted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Apply 2D shift to orthomosaic without GCPs\n",
    "print(\"\\n1. Applying 2D shift to orthomosaic (without GCPs)...\")\n",
    "shifted_no_gcps_path = shifted_dir / \"orthomosaic_no_gcps_shifted.tif\"\n",
    "_, shift_info_no_gcps = apply_2d_shift_to_orthomosaic(\n",
    "    ortho_path=Path(ortho_no_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    output_path=shifted_no_gcps_path\n",
    ")\n",
    "print(f\"   Shift applied: X={shift_info_no_gcps['shift_x_pixels']:.2f} px, Y={shift_info_no_gcps['shift_y_pixels']:.2f} px\")\n",
    "\n",
    "# Apply 2D shift to orthomosaic with GCPs\n",
    "print(\"\\n2. Applying 2D shift to orthomosaic (with GCPs)...\")\n",
    "shifted_with_gcps_path = shifted_dir / \"orthomosaic_with_gcps_shifted.tif\"\n",
    "_, shift_info_with_gcps = apply_2d_shift_to_orthomosaic(\n",
    "    ortho_path=Path(ortho_with_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    output_path=shifted_with_gcps_path\n",
    ")\n",
    "print(f\"   Shift applied: X={shift_info_with_gcps['shift_x_pixels']:.2f} px, Y={shift_info_with_gcps['shift_y_pixels']:.2f} px\")\n",
    "\n",
    "# Re-analyze shifted orthomosaics\n",
    "print(\"\\n3. Re-analyzing shifted orthomosaics against ESRI basemap...\")\n",
    "\n",
    "# Compare shifted orthomosaic (without GCPs)\n",
    "print(\"\\n   Analyzing shifted orthomosaic (without GCPs)...\")\n",
    "metrics_shifted_no_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=shifted_no_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare shifted orthomosaic (with GCPs)\n",
    "print(\"\\n   Analyzing shifted orthomosaic (with GCPs)...\")\n",
    "metrics_shifted_with_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=shifted_with_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Save shifted metrics\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shifted_metrics_file_no_gcps = metrics_dir / \"metrics_shifted_no_gcps_esri.json\"\n",
    "shifted_metrics_file_with_gcps = metrics_dir / \"metrics_shifted_with_gcps_esri.json\"\n",
    "\n",
    "with open(shifted_metrics_file_no_gcps, 'w') as f:\n",
    "    json.dump(metrics_shifted_no_gcps, f, indent=2, default=str)\n",
    "with open(shifted_metrics_file_with_gcps, 'w') as f:\n",
    "    json.dump(metrics_shifted_with_gcps, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n\u2713 Shifted metrics saved to: {metrics_dir}\")\n",
    "\n",
    "# Compare initial vs shifted results\n",
    "print(\"\\n4. Comparing initial vs. shifted results...\")\n",
    "\n",
    "# Load initial metrics if not available\n",
    "if 'metrics_no_gcps_esri' not in locals() or 'metrics_with_gcps_esri' not in locals():\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_esri.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_esri.json\"\n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_esri = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_esri = json.load(f)\n",
    "    else:\n",
    "        raise NameError(\"Initial metrics not found. Please run Step 7 first.\")\n",
    "\n",
    "# Calculate improvements from shifting\n",
    "initial_no_gcps = metrics_no_gcps_esri.get('overall', {})\n",
    "shifted_no_gcps = metrics_shifted_no_gcps.get('overall', {})\n",
    "initial_with_gcps = metrics_with_gcps_esri.get('overall', {})\n",
    "shifted_with_gcps = metrics_shifted_with_gcps.get('overall', {})\n",
    "\n",
    "print(\"\\n   Without GCPs:\")\n",
    "if initial_no_gcps.get('rmse') and shifted_no_gcps.get('rmse'):\n",
    "    rmse_improvement = ((initial_no_gcps['rmse'] - shifted_no_gcps['rmse']) / initial_no_gcps['rmse']) * 100\n",
    "    print(f\"     RMSE: {initial_no_gcps['rmse']:.4f} \u2192 {shifted_no_gcps['rmse']:.4f} ({rmse_improvement:+.2f}%)\")\n",
    "if initial_no_gcps.get('seamline_percentage') and shifted_no_gcps.get('seamline_percentage'):\n",
    "    seamline_improvement = initial_no_gcps['seamline_percentage'] - shifted_no_gcps['seamline_percentage']\n",
    "    print(f\"     Seamlines: {initial_no_gcps['seamline_percentage']:.2f}% \u2192 {shifted_no_gcps['seamline_percentage']:.2f}% ({seamline_improvement:+.2f}%)\")\n",
    "\n",
    "print(\"\\n   With GCPs:\")\n",
    "if initial_with_gcps.get('rmse') and shifted_with_gcps.get('rmse'):\n",
    "    rmse_improvement = ((initial_with_gcps['rmse'] - shifted_with_gcps['rmse']) / initial_with_gcps['rmse']) * 100\n",
    "    print(f\"     RMSE: {initial_with_gcps['rmse']:.4f} \u2192 {shifted_with_gcps['rmse']:.4f} ({rmse_improvement:+.2f}%)\")\n",
    "if initial_with_gcps.get('seamline_percentage') and shifted_with_gcps.get('seamline_percentage'):\n",
    "    seamline_improvement = initial_with_gcps['seamline_percentage'] - shifted_with_gcps['seamline_percentage']\n",
    "    print(f\"     Seamlines: {initial_with_gcps['seamline_percentage']:.2f}% \u2192 {shifted_with_gcps['seamline_percentage']:.2f}% ({seamline_improvement:+.2f}%)\")\n",
    "\n",
    "print(\"\\n\u2713 Step 7.5 complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.6: Align Orthomosaics to Ground Control Points and Re-analyze\n",
    "\n",
    "In addition to feature-matching alignment, we also align the orthomosaics directly to the ground control points (GCPs) using their known coordinates. This provides an alternative alignment method that can be compared against feature-matching alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.6: Align Orthomosaics to Ground Control Points and Re-analyze\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'align_orthomosaic_to_gcps' not in locals() or 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        align_orthomosaic_to_gcps,\n",
    "        compare_orthomosaic_to_basemap\n",
    "    )\n",
    "\n",
    "if 'load_gcps_from_kmz' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import load_gcps_from_kmz\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Ensure orthomosaic paths are defined\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Load GCPs if not already loaded\n",
    "if 'gcps' not in locals():\n",
    "    # Try to find KMZ file\n",
    "    kmz_path = Path(\"input\") / \"QualicumBeach_AOI.kmz\"\n",
    "    if not kmz_path.exists():\n",
    "        # Try alternative location\n",
    "        kmz_path = Path(\"/Users/mauriciohessflores/Documents/Code/Data/Qualicum Beach GCPs/Spexi_Survey_Points/Spexi_Drone_Survey/QualicumBeach_AOI.kmz\")\n",
    "    \n",
    "    if kmz_path.exists():\n",
    "        gcps = load_gcps_from_kmz(str(kmz_path))\n",
    "        print(f\"Loaded {len(gcps)} GCPs from {kmz_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Could not find GCP KMZ file. Tried: {kmz_path}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 7.6: Align Orthomosaics to Ground Control Points\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create directory for GCP-aligned orthomosaics\n",
    "gcp_aligned_dir = output_dir / \"orthomosaics_gcp_aligned\"\n",
    "gcp_aligned_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Align orthomosaic without GCPs to GCPs\n",
    "print(\"\\n1. Aligning orthomosaic (without GCPs) to GCPs...\")\n",
    "gcp_aligned_no_gcps_path = gcp_aligned_dir / \"orthomosaic_no_gcps_gcp_aligned.tif\"\n",
    "_, alignment_info_no_gcps = align_orthomosaic_to_gcps(\n",
    "    ortho_path=Path(ortho_no_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    gcps=gcps,\n",
    "    output_path=gcp_aligned_no_gcps_path\n",
    ")\n",
    "print(f\"   Alignment RMSE: {alignment_info_no_gcps['rmse_total_pixels']:.2f} pixels\")\n",
    "print(f\"   Used {alignment_info_no_gcps['num_gcps_used']} GCPs\")\n",
    "\n",
    "# Align orthomosaic with GCPs to GCPs\n",
    "print(\"\\n2. Aligning orthomosaic (with GCPs) to GCPs...\")\n",
    "gcp_aligned_with_gcps_path = gcp_aligned_dir / \"orthomosaic_with_gcps_gcp_aligned.tif\"\n",
    "_, alignment_info_with_gcps = align_orthomosaic_to_gcps(\n",
    "    ortho_path=Path(ortho_with_gcps_path),\n",
    "    reference_path=Path(basemap_esri_path),\n",
    "    gcps=gcps,\n",
    "    output_path=gcp_aligned_with_gcps_path\n",
    ")\n",
    "print(f\"   Alignment RMSE: {alignment_info_with_gcps['rmse_total_pixels']:.2f} pixels\")\n",
    "print(f\"   Used {alignment_info_with_gcps['num_gcps_used']} GCPs\")\n",
    "\n",
    "# Re-analyze GCP-aligned orthomosaics\n",
    "print(\"\\n3. Re-analyzing GCP-aligned orthomosaics against ESRI basemap...\")\n",
    "\n",
    "# Compare GCP-aligned orthomosaic (without GCPs)\n",
    "print(\"\\n   Analyzing GCP-aligned orthomosaic (without GCPs)...\")\n",
    "metrics_gcp_aligned_no_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=gcp_aligned_no_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare GCP-aligned orthomosaic (with GCPs)\n",
    "print(\"\\n   Analyzing GCP-aligned orthomosaic (with GCPs)...\")\n",
    "metrics_gcp_aligned_with_gcps = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=gcp_aligned_with_gcps_path,\n",
    "    basemap_path=Path(basemap_esri_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Save GCP-aligned metrics\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gcp_aligned_metrics_file_no_gcps = metrics_dir / \"metrics_gcp_aligned_no_gcps_esri.json\"\n",
    "gcp_aligned_metrics_file_with_gcps = metrics_dir / \"metrics_gcp_aligned_with_gcps_esri.json\"\n",
    "\n",
    "with open(gcp_aligned_metrics_file_no_gcps, 'w') as f:\n",
    "    json.dump(metrics_gcp_aligned_no_gcps, f, indent=2, default=str)\n",
    "with open(gcp_aligned_metrics_file_with_gcps, 'w') as f:\n",
    "    json.dump(metrics_gcp_aligned_with_gcps, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n\u2713 GCP-aligned metrics saved to: {metrics_dir}\")\n",
    "\n",
    "# Compare alignment methods\n",
    "print(\"\\n4. Comparing alignment methods...\")\n",
    "\n",
    "# Load initial and shifted metrics if available\n",
    "if 'metrics_no_gcps_esri' not in locals() or 'metrics_with_gcps_esri' not in locals():\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_esri.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_esri.json\"\n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_esri = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_esri = json.load(f)\n",
    "\n",
    "# Load shifted metrics if available\n",
    "shifted_metrics_file_no_gcps = metrics_dir / \"metrics_shifted_no_gcps_esri.json\"\n",
    "shifted_metrics_file_with_gcps = metrics_dir / \"metrics_shifted_with_gcps_esri.json\"\n",
    "metrics_shifted_no_gcps = None\n",
    "metrics_shifted_with_gcps = None\n",
    "if shifted_metrics_file_no_gcps.exists() and shifted_metrics_file_with_gcps.exists():\n",
    "    with open(shifted_metrics_file_no_gcps, 'r') as f:\n",
    "        metrics_shifted_no_gcps = json.load(f)\n",
    "    with open(shifted_metrics_file_with_gcps, 'r') as f:\n",
    "        metrics_shifted_with_gcps = json.load(f)\n",
    "\n",
    "print(\"\\n   Without GCPs - RMSE comparison:\")\n",
    "initial_no = metrics_no_gcps_esri.get('overall', {}) if 'metrics_no_gcps_esri' in locals() else {}\n",
    "shifted_no = metrics_shifted_no_gcps.get('overall', {}) if metrics_shifted_no_gcps else {}\n",
    "gcp_aligned_no = metrics_gcp_aligned_no_gcps.get('overall', {})\n",
    "\n",
    "if initial_no.get('rmse'):\n",
    "    print(f\"     Initial:        {initial_no['rmse']:.4f}\")\n",
    "if shifted_no.get('rmse'):\n",
    "    print(f\"     Feature-matched: {shifted_no['rmse']:.4f}\")\n",
    "if gcp_aligned_no.get('rmse'):\n",
    "    print(f\"     GCP-aligned:     {gcp_aligned_no['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\n   With GCPs - RMSE comparison:\")\n",
    "initial_with = metrics_with_gcps_esri.get('overall', {}) if 'metrics_with_gcps_esri' in locals() else {}\n",
    "shifted_with = metrics_shifted_with_gcps.get('overall', {}) if metrics_shifted_with_gcps else {}\n",
    "gcp_aligned_with = metrics_gcp_aligned_with_gcps.get('overall', {})\n",
    "\n",
    "if initial_with.get('rmse'):\n",
    "    print(f\"     Initial:        {initial_with['rmse']:.4f}\")\n",
    "if shifted_with.get('rmse'):\n",
    "    print(f\"     Feature-matched: {shifted_with['rmse']:.4f}\")\n",
    "if gcp_aligned_with.get('rmse'):\n",
    "    print(f\"     GCP-aligned:     {gcp_aligned_with['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\n\u2713 Step 7.6 complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against OpenStreetMap basemap\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'compare_orthomosaic_to_basemap' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import compare_orthomosaic_to_basemap\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "if 'basemap_osm_path' not in locals():\n",
    "    basemap_osm_path = str(output_dir / \"qualicum_beach_basemap_osm.tif\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing orthomosaics to OpenStreetMap basemap...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Determine orthomosaic paths - use stats if available, otherwise find files directly\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    if 'stats_no_gcps' in locals() and 'ortho_path' in stats_no_gcps:\n",
    "        ortho_no_gcps_path = Path(stats_no_gcps['ortho_path'])\n",
    "    else:\n",
    "        ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "        ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "        if not ortho_no_gcps_path.exists():\n",
    "            raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found at: {ortho_no_gcps_path.absolute()}\")\n",
    "\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    if 'stats_with_gcps' in locals() and 'ortho_path' in stats_with_gcps:\n",
    "        ortho_with_gcps_path = Path(stats_with_gcps['ortho_path'])\n",
    "    else:\n",
    "        ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "        ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "        if not ortho_with_gcps_path.exists():\n",
    "            raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found at: {ortho_with_gcps_path.absolute()}\")\n",
    "\n",
    "# Compare without GCPs\n",
    "print(\"\\nComparing orthomosaic (without GCPs) to OpenStreetMap basemap...\")\n",
    "metrics_no_gcps_osm = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_no_gcps_path,\n",
    "    basemap_path=Path(basemap_osm_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "# Compare with GCPs\n",
    "print(\"\\nComparing orthomosaic (with GCPs) to OpenStreetMap basemap...\")\n",
    "metrics_with_gcps_osm = compare_orthomosaic_to_basemap(\n",
    "    ortho_path=ortho_with_gcps_path,\n",
    "    basemap_path=Path(basemap_osm_path),\n",
    "    output_dir=comparison_dir\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 OpenStreetMap comparison complete!\")\n",
    "\n",
    "# Save metrics to JSON files for later use\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "if 'convert_to_json_serializable' not in locals():\n",
    "    from qualicum_beach_gcp_analysis.report_generator import convert_to_json_serializable\n",
    "\n",
    "if 'metrics_dir' not in locals():\n",
    "    metrics_dir = comparison_dir / \"metrics\"\n",
    "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save OpenStreetMap metrics\n",
    "metrics_no_gcps_osm_serializable = convert_to_json_serializable(metrics_no_gcps_osm)\n",
    "metrics_with_gcps_osm_serializable = convert_to_json_serializable(metrics_with_gcps_osm)\n",
    "\n",
    "with open(metrics_dir / \"metrics_no_gcps_osm.json\", 'w') as f:\n",
    "    json.dump(metrics_no_gcps_osm_serializable, f, indent=2)\n",
    "with open(metrics_dir / \"metrics_with_gcps_osm.json\", 'w') as f:\n",
    "    json.dump(metrics_with_gcps_osm_serializable, f, indent=2)\n",
    "\n",
    "print(f\"\u2713 Metrics saved to: {metrics_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Quality Reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report for ESRI comparison\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "\n",
    "if 'generate_comparison_report' not in locals():\n",
    "    from qualicum_beach_gcp_analysis import (\n",
    "        generate_comparison_report, \n",
    "        generate_markdown_report,\n",
    "        generate_latex_report,\n",
    "        create_error_visualization,\n",
    "        create_seamline_visualization,\n",
    "        create_comparison_side_by_side,\n",
    "        create_metrics_summary_plot\n",
    "    )\n",
    "    \n",
    "if 'numpy' not in locals():\n",
    "    import numpy as np\n",
    "if 'rasterio' not in locals():\n",
    "    import rasterio\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "if 'comparison_dir' not in locals():\n",
    "    comparison_dir = output_dir / \"comparisons\"\n",
    "\n",
    "# Load metrics from Step 7 if available, otherwise check for saved files\n",
    "if 'metrics_no_gcps_esri' not in locals() or 'metrics_with_gcps_esri' not in locals():\n",
    "    # Try to load from saved JSON files\n",
    "    metrics_dir = comparison_dir / \"metrics\"\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_esri.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_esri.json\"\n",
    "    \n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        print(f\"Loading saved metrics from: {metrics_dir}\")\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_esri = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_esri = json.load(f)\n",
    "        print(\"\u2713 Loaded saved ESRI comparison metrics\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            f\"metrics_no_gcps_esri and metrics_with_gcps_esri must be defined. \"\n",
    "            f\"Please run Step 7 first, or ensure saved metrics exist at:\\n\"\n",
    "            f\"  {metrics_file_no_gcps}\\n\"\n",
    "            f\"  {metrics_file_with_gcps}\"\n",
    "        )\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Generating quality reports...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ESRI report\n",
    "report_json_esri = output_dir / \"quality_report_esri.json\"\n",
    "report_md_esri = output_dir / \"quality_report_esri.md\"\n",
    "\n",
    "generate_comparison_report(\n",
    "    metrics_with_gcps=metrics_with_gcps_esri,\n",
    "    metrics_without_gcps=metrics_no_gcps_esri,\n",
    "    output_path=report_json_esri,\n",
    "    basemap_source=\"ESRI World Imagery\"\n",
    ")\n",
    "\n",
    "generate_markdown_report(\n",
    "    json_report_path=report_json_esri,\n",
    "    output_path=report_md_esri\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 ESRI report saved:\")\n",
    "print(f\"  JSON: {report_json_esri}\")\n",
    "print(f\"  Markdown: {report_md_esri}\")\n",
    "\n",
    "# Ensure orthomosaic paths are defined\n",
    "if 'ortho_no_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_no_gcps_path = ortho_output_dir / \"orthomosaic_no_gcps.tif\"\n",
    "    if not ortho_no_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found at: {ortho_no_gcps_path.absolute()}\")\n",
    "if 'ortho_with_gcps_path' not in locals():\n",
    "    ortho_output_dir = output_dir / \"orthomosaics\"\n",
    "    ortho_with_gcps_path = ortho_output_dir / \"orthomosaic_with_gcps.tif\"\n",
    "    if not ortho_with_gcps_path.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found at: {ortho_with_gcps_path.absolute()}\")\n",
    "if 'basemap_esri_path' not in locals():\n",
    "    basemap_esri_path = str(output_dir / \"qualicum_beach_basemap_esri.tif\")\n",
    "\n",
    "# Generate visualizations for ESRI comparison\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "vis_dir = output_dir / \"visualizations\" / \"esri\"\n",
    "vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load orthomosaics and reference for visualization\n",
    "print(\"  Loading orthomosaics and reference basemap...\")\n",
    "with rasterio.open(ortho_no_gcps_path) as src:\n",
    "    ortho_no_gcps = src.read(1)  # First band\n",
    "with rasterio.open(ortho_with_gcps_path) as src:\n",
    "    ortho_with_gcps = src.read(1)  # First band\n",
    "with rasterio.open(basemap_esri_path) as src:\n",
    "    reference_esri = src.read(1)  # First band\n",
    "\n",
    "# Create visualizations\n",
    "print(\"  Creating comparison visualizations...\")\n",
    "create_comparison_side_by_side(\n",
    "    ortho_no_gcps, ortho_with_gcps, reference_esri,\n",
    "    vis_dir / \"comparison_side_by_side.png\",\n",
    "    title=\"ESRI Basemap Comparison\"\n",
    ")\n",
    "\n",
    "create_metrics_summary_plot(\n",
    "    metrics_no_gcps_esri, metrics_with_gcps_esri,\n",
    "    vis_dir / \"metrics_summary.png\",\n",
    "    title=\"ESRI Basemap Quality Metrics\"\n",
    ")\n",
    "\n",
    "create_seamline_visualization(\n",
    "    ortho_no_gcps,\n",
    "    vis_dir / \"seamlines_no_gcps.png\",\n",
    "    title=\"Seamlines - Without GCPs\"\n",
    ")\n",
    "\n",
    "create_seamline_visualization(\n",
    "    ortho_with_gcps,\n",
    "    vis_dir / \"seamlines_with_gcps.png\",\n",
    "    title=\"Seamlines - With GCPs\"\n",
    ")\n",
    "\n",
    "create_error_visualization(\n",
    "    ortho_no_gcps, reference_esri,\n",
    "    vis_dir / \"error_no_gcps.png\",\n",
    "    title=\"Error Map - Without GCPs\"\n",
    ")\n",
    "\n",
    "create_error_visualization(\n",
    "    ortho_with_gcps, reference_esri,\n",
    "    vis_dir / \"error_with_gcps.png\",\n",
    "    title=\"Error Map - With GCPs\"\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Visualizations saved to: {vis_dir}\")\n",
    "\n",
    "\n",
    "# OpenStreetMap report\n",
    "# Load metrics from Step 7 if available, otherwise check for saved files\n",
    "if 'metrics_no_gcps_osm' not in locals() or 'metrics_with_gcps_osm' not in locals():\n",
    "    # Try to load from saved JSON files\n",
    "    if 'metrics_dir' not in locals():\n",
    "        metrics_dir = comparison_dir / \"metrics\"\n",
    "    metrics_file_no_gcps = metrics_dir / \"metrics_no_gcps_osm.json\"\n",
    "    metrics_file_with_gcps = metrics_dir / \"metrics_with_gcps_osm.json\"\n",
    "    \n",
    "    if metrics_file_no_gcps.exists() and metrics_file_with_gcps.exists():\n",
    "        print(f\"Loading saved metrics from: {metrics_dir}\")\n",
    "        if 'json' not in locals():\n",
    "            import json\n",
    "        with open(metrics_file_no_gcps, 'r') as f:\n",
    "            metrics_no_gcps_osm = json.load(f)\n",
    "        with open(metrics_file_with_gcps, 'r') as f:\n",
    "            metrics_with_gcps_osm = json.load(f)\n",
    "        print(\"\u2713 Loaded saved OpenStreetMap comparison metrics\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            f\"metrics_no_gcps_osm and metrics_with_gcps_osm must be defined. \"\n",
    "            f\"Please run Step 7 first, or ensure saved metrics exist at:\\n\"\n",
    "            f\"  {metrics_file_no_gcps}\\n\"\n",
    "            f\"  {metrics_file_with_gcps}\"\n",
    "        )\n",
    "\n",
    "report_json_osm = output_dir / \"quality_report_osm.json\"\n",
    "report_md_osm = output_dir / \"quality_report_osm.md\"\n",
    "\n",
    "generate_comparison_report(\n",
    "    metrics_with_gcps=metrics_with_gcps_osm,\n",
    "    metrics_without_gcps=metrics_no_gcps_osm,\n",
    "    output_path=report_json_osm,\n",
    "    basemap_source=\"OpenStreetMap\"\n",
    ")\n",
    "\n",
    "generate_markdown_report(\n",
    "    json_report_path=report_json_osm,\n",
    "    output_path=report_md_osm\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 OpenStreetMap report saved:\")\n",
    "print(f\"  JSON: {report_json_osm}\")\n",
    "print(f\"  Markdown: {report_md_osm}\")\n",
    "\n",
    "# Generate visualizations for OpenStreetMap comparison\n",
    "print(\"\\nGenerating visualizations for OpenStreetMap...\")\n",
    "vis_dir_osm = output_dir / \"visualizations\" / \"osm\"\n",
    "vis_dir_osm.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure basemap path is defined\n",
    "if 'basemap_osm_path' not in locals():\n",
    "    basemap_osm_path = str(output_dir / \"qualicum_beach_basemap_osm.tif\")\n",
    "\n",
    "# Load reference basemap for visualization\n",
    "print(\"  Loading reference basemap...\")\n",
    "with rasterio.open(basemap_osm_path) as src:\n",
    "    reference_osm = src.read(1)  # First band\n",
    "\n",
    "# Reuse orthomosaics already loaded (or load if not available)\n",
    "if 'ortho_no_gcps' not in locals():\n",
    "    with rasterio.open(ortho_no_gcps_path) as src:\n",
    "        ortho_no_gcps = src.read(1)\n",
    "if 'ortho_with_gcps' not in locals():\n",
    "    with rasterio.open(ortho_with_gcps_path) as src:\n",
    "        ortho_with_gcps = src.read(1)\n",
    "\n",
    "# Create visualizations\n",
    "print(\"  Creating comparison visualizations...\")\n",
    "create_comparison_side_by_side(\n",
    "    ortho_no_gcps, ortho_with_gcps, reference_osm,\n",
    "    vis_dir_osm / \"comparison_side_by_side.png\",\n",
    "    title=\"OpenStreetMap Basemap Comparison\"\n",
    ")\n",
    "\n",
    "create_metrics_summary_plot(\n",
    "    metrics_no_gcps_osm, metrics_with_gcps_osm,\n",
    "    vis_dir_osm / \"metrics_summary.png\",\n",
    "    title=\"OpenStreetMap Basemap Quality Metrics\"\n",
    ")\n",
    "\n",
    "create_seamline_visualization(\n",
    "    ortho_no_gcps,\n",
    "    vis_dir_osm / \"seamlines_no_gcps.png\",\n",
    "    title=\"Seamlines - Without GCPs\"\n",
    ")\n",
    "\n",
    "create_seamline_visualization(\n",
    "    ortho_with_gcps,\n",
    "    vis_dir_osm / \"seamlines_with_gcps.png\",\n",
    "    title=\"Seamlines - With GCPs\"\n",
    ")\n",
    "\n",
    "create_error_visualization(\n",
    "    ortho_no_gcps, reference_osm,\n",
    "    vis_dir_osm / \"error_no_gcps.png\",\n",
    "    title=\"Error Map - Without GCPs\"\n",
    ")\n",
    "\n",
    "create_error_visualization(\n",
    "    ortho_with_gcps, reference_osm,\n",
    "    vis_dir_osm / \"error_with_gcps.png\",\n",
    "    title=\"Error Map - With GCPs\"\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Visualizations saved to: {vis_dir_osm}\")\n",
    "\n",
    "# Generate comprehensive LaTeX/PDF report with both ESRI and OSM\n",
    "# Check for shifted metrics (from Step 7.5) and GCP-aligned metrics (from Step 7.6)\n",
    "metrics_dir = comparison_dir / \"metrics\"\n",
    "shifted_metrics_no_gcps_path = metrics_dir / \"metrics_shifted_no_gcps_esri.json\"\n",
    "shifted_metrics_with_gcps_path = metrics_dir / \"metrics_shifted_with_gcps_esri.json\"\n",
    "gcp_aligned_metrics_no_gcps_path = metrics_dir / \"metrics_gcp_aligned_no_gcps_esri.json\"\n",
    "gcp_aligned_metrics_with_gcps_path = metrics_dir / \"metrics_gcp_aligned_with_gcps_esri.json\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Generating comprehensive LaTeX/PDF report (ESRI + OSM)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report_latex_final = output_dir / \"quality_report_final\"\n",
    "latex_result_final = generate_latex_report(\n",
    "    json_report_path=report_json_esri,\n",
    "    output_path=report_latex_final,\n",
    "    visualization_dir=vis_dir,\n",
    "    json_report_path_osm=report_json_osm,\n",
    "    visualization_dir_osm=vis_dir_osm,\n",
    "    shifted_metrics_no_gcps_path=shifted_metrics_no_gcps_path if shifted_metrics_no_gcps_path.exists() else None,\n",
    "    shifted_metrics_with_gcps_path=shifted_metrics_with_gcps_path if shifted_metrics_with_gcps_path.exists() else None,\n",
    "    gcp_aligned_metrics_no_gcps_path=gcp_aligned_metrics_no_gcps_path if gcp_aligned_metrics_no_gcps_path.exists() else None,\n",
    "    gcp_aligned_metrics_with_gcps_path=gcp_aligned_metrics_with_gcps_path if gcp_aligned_metrics_with_gcps_path.exists() else None\n",
    ")\n",
    "\n",
    "if latex_result_final.suffix == '.pdf':\n",
    "    print(f\"\\n\u2713 PDF report generated: {latex_result_final}\")\n",
    "else:\n",
    "    print(f\"\\n\u2713 LaTeX file generated: {latex_result_final}\")\n",
    "    print(\"  (Install LaTeX and run: pdflatex quality_report_final.tex to generate PDF)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Display Report Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary from ESRI report\n",
    "# Ensure imports and variables are defined\n",
    "if 'Path' not in locals():\n",
    "    from pathlib import Path\n",
    "if 'json' not in locals():\n",
    "    import json\n",
    "\n",
    "if 'output_dir' not in locals():\n",
    "    output_dir = Path(\"outputs\")\n",
    "\n",
    "# Define report paths\n",
    "report_json_esri = output_dir / \"quality_report_esri.json\"\n",
    "report_json_osm = output_dir / \"quality_report_osm.json\"\n",
    "report_md_esri = output_dir / \"quality_report_esri.md\"\n",
    "report_md_osm = output_dir / \"quality_report_osm.md\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"QUALITY COMPARISON SUMMARY (ESRI World Imagery)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with open(report_json_esri, 'r') as f:\n",
    "    report_esri = json.load(f)\n",
    "\n",
    "comparison = report_esri.get('comparison', {})\n",
    "\n",
    "if comparison.get('rmse_improvement'):\n",
    "    rmse = comparison['rmse_improvement']\n",
    "    print(f\"\\nRMSE Improvement: {rmse['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {rmse['without_gcps']:.4f}\")\n",
    "    print(f\"  With GCPs:    {rmse['with_gcps']:.4f}\")\n",
    "\n",
    "if comparison.get('mae_improvement'):\n",
    "    mae = comparison['mae_improvement']\n",
    "    print(f\"\\nMAE Improvement: {mae['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {mae['without_gcps']:.4f}\")\n",
    "    print(f\"  With GCPs:    {mae['with_gcps']:.4f}\")\n",
    "\n",
    "if comparison.get('similarity_improvement'):\n",
    "    sim = comparison['similarity_improvement']\n",
    "    print(f\"\\nSimilarity Improvement: {sim['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {sim['without_gcps']:.4f}\")\n",
    "    print(f\"  With GCPs:    {sim['with_gcps']:.4f}\")\n",
    "\n",
    "if comparison.get('seamline_reduction'):\n",
    "    seam = comparison['seamline_reduction']\n",
    "    print(f\"\\nSeamline Reduction: {seam['percentage']:+.2f}%\")\n",
    "    print(f\"  Without GCPs: {seam['without_gcps']:.2f}%\")\n",
    "    print(f\"  With GCPs:    {seam['with_gcps']:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Full reports available at:\")\n",
    "print(f\"  {report_md_esri}\")\n",
    "print(f\"  {report_md_osm}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}